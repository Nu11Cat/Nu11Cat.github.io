import{_ as o}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as n,a as t,o as s}from"./app-DjrNW2Lh.js";const g={};function a(l,r){return s(),n("div",null,r[0]||(r[0]=[t('<h1 id="消息队列" tabindex="-1"><a class="header-anchor" href="#消息队列"><span>消息队列</span></a></h1><p>消息队列是一种异步的进程间通信方式，主要用于解决分布式系统中的组件通信问题。它的核心模型是 <strong>‘生产者/消费者’模型</strong>：生产者发送消息到队列，消费者从队列中获取消息进行处理。双方不需要同时在线，也不需要知道彼此的存在。</p><h2 id="作用" tabindex="-1"><a class="header-anchor" href="#作用"><span>作用</span></a></h2><ol><li><strong>系统解耦</strong>：这是它最重要的作用。假设系统A需要调用系统B的接口。如果不使用消息队列，系统A和系统B是<strong>强耦合</strong>的，如果系统B宕机或接口变更，系统A会立刻受到影响。引入了消息队列后，系统A只需要把消息发送出去就算完成任务，完全不需要关心谁来处理、何时处理。系统B也只需要从队列里取消息，而不需要关心消息的来源。这样，两个系统就通过一个中间件<strong>解耦</strong>了，彼此的依赖性和影响降到了最低。</li><li><strong>异步处理</strong>：对于一些非核心的、耗时的操作（比如下单成功后发短信、发优惠券），主流程不需要等待它们完成，只需要发一个消息到队列就可以直接返回，极大地缩短了响应时间，提升了用户体验。</li><li><strong>削峰</strong>：在流量高峰时期（比如秒杀），大量的请求瞬间涌入，后端服务可能无法承受。消息队列可以作为一个<strong>缓冲区</strong>，将这些请求平稳地接收下来，后端服务可以按照自己能处理的速度慢慢消费，避免了系统被突发流量冲垮。</li></ol><hr><p>除此之外，还有：</p><p><strong>1. 实现最终一致性（分布式事务）</strong></p><p>这是消息队列在微服务架构中一个核心且经典的应用。它通过<strong>事务消息</strong>或<strong>本地事务表</strong>等模式，来解决分布式系统下的数据一致性问题。</p><ul><li><strong>场景</strong>：用户下单支付成功后，需要更新订单状态、扣减库存、增加积分。这三个操作分属不同服务，必须保证同时成功或失败。</li><li><strong>如何做</strong>：订单服务在本地数据库事务中，更新订单状态并<strong>向消息队列发送一条事务消息</strong>。消息队列保证这条消息最终一定能被投递。库存和积分服务消费这条消息，执行各自操作。通过<strong>重试机制</strong>，确保这些操作最终都会成功，从而实现所有系统数据的<strong>最终一致性</strong>。<strong>RocketMQ</strong> 提供了完整的事务消息方案。</li></ul><p><strong>2. 顺序保证</strong></p><p>在某些业务场景下，消息必须严格按照产生的顺序被处理。</p><ul><li><strong>场景</strong>：一个账户的“创建账户” -&gt; “存入100元” -&gt; “取出50元” 这三个操作必须按顺序执行，乱序会导致账户余额错误。</li><li><strong>如何做</strong>：在 <strong>Kafka</strong> 或 <strong>RocketMQ</strong> 中，通过将需要保证顺序的消息发送到同一个 <strong>Topic 的同一个 Partition</strong> 中。因为一个分区只能被一个消费者顺序消费，从而天然保证了消息的顺序性。</li></ul><p><strong>3.数据流处理（流平台）</strong></p><p>这是将消息队列能力发挥到极致的场景。此时它不再仅仅是“消息中间件”，而是一个<strong>实时的数据流平台</strong>，是大数据领域的基石。</p><ul><li><strong>场景</strong>：实时用户行为分析、实时监控告警、实时推荐系统。</li><li><strong>如何做</strong>：各种应用（如前端、后端服务）作为生产者，将日志、点击事件、监控指标等数据以流的形式持续写入 <strong>Kafka</strong>。下游的流处理框架（如 <strong>Flink、Spark Streaming</strong>）实时消费这些数据流，进行清洗、聚合、计算。结果可用于实时大屏或驱动业务逻辑。Kafka 的高吞吐和持久化特性使其成为<strong>事实上的流数据标准源</strong>。</li></ul><p><strong>4. 延时/定时调度</strong></p><p>消息队列可以作为一个分布式的、高可用的定时器。</p><ul><li><strong>场景</strong>：订单下单后30分钟未支付自动关闭；预约会议开始前15分钟发送提醒。</li><li><strong>如何做</strong>：<strong>RocketMQ</strong> 原生支持延迟消息，可在发送时指定延迟级别。<strong>RabbitMQ</strong> 可通过 <code>TTL</code>（消息存活时间）和 <code>死信队列</code>机制来实现。消息会在队列中等待指定时间后才被投递给消费者。</li></ul><p><strong>5. 系统重构与数据同步</strong></p><p>在系统重构或数据迁移期间，消息队列是保证业务平滑过渡和数据一致性的利器。</p><ul><li><strong>场景</strong>：将单体数据库拆分为多个微服务数据库，需要实时同步用户数据。</li><li><strong>如何做</strong>：旧系统在修改数据时，同时向消息队列发送一条数据变更消息。新系统订阅这些消息，从而在自己的数据库中维护一份相同的用户数据。这种方式对原有系统侵入性小，实现了数据的实时同步。</li></ul><hr><h2 id="可能带来哪些问题" tabindex="-1"><a class="header-anchor" href="#可能带来哪些问题"><span>可能带来哪些问题</span></a></h2><p><strong>系统可用性降低：</strong> 系统可用性在某种程度上降低，为什么这样说呢？在加入 MQ 之前，你不用考虑消息丢失或者说 MQ 挂掉等等的情况，但是，引入 MQ 之后你就需要去考虑了！</p><p><strong>系统复杂性提高：</strong> 加入 MQ 之后，你需要保证消息没有被重复消费、处理消息丢失的情况、保证消息传递的顺序性等等问题！</p><p><strong>一致性问题：</strong> 我上面讲了消息队列可以实现异步，消息队列带来的异步确实可以提高系统响应速度。但是，万一消息的真正消费者并没有正确消费消息怎么办？这样就会导致数据不一致的情况了</p><hr><h2 id="jms-和-amqp" tabindex="-1"><a class="header-anchor" href="#jms-和-amqp"><span>JMS 和 AMQP</span></a></h2><ul><li><strong>JMS</strong>：是一个 <strong>Java 平台的 API 规范/标准</strong>，它定义了如何编写Java代码来和消息中间件进行交互。它关心的是<strong>接口</strong>。</li><li><strong>AMQP</strong>：是一个<strong>跨语言的</strong>、<strong>线级的</strong> <strong>网络协议</strong>。它定义了数据在网络上的传输格式。它关心的是<strong>通信</strong>。</li></ul><hr><p>JMS 是 Java EE 的一部分，它只是一套接口，本身并不实现消息的收发。它的主要目的是，让 Java 开发者能够用一套统一的API来操作不同的消息中间件，从而实现<strong>解耦</strong>。</p><p><strong>JMS 两种消息模型</strong>：</p><ul><li><strong>点对点模型</strong>：消息发送到<strong>队列</strong>。一个消息只能被<strong>一个消费者</strong>消费。</li><li><strong>发布/订阅模型</strong>：消息发送到<strong>主题</strong>。一个消息会被<strong>所有订阅了该主题的消费者</strong>消费。</li></ul><hr><p>它的核心是更灵活的<strong>路由机制</strong>：</p><ul><li><strong>生产者</strong>将消息发送到 <strong>Exchange</strong>（交换机），并指定一个 <strong>Routing Key</strong>。</li><li><strong>Exchange</strong> 根据自身的<strong>类型</strong>和与 <strong>Queue</strong> 的 <strong>Binding</strong> 规则，将消息路由到一个或多个队列中。</li><li><strong>消费者</strong>从 <strong>Queue</strong> 中获取消息。</li></ul><hr><p><strong>AMQP提供了五种消息模型</strong>：①direct exchange；②fanout exchange；③topic change；④headers exchange；⑤system exchange。本质来讲，后四种和 JMS 的 pub/sub 模型没有太大差别，仅是在路由机制上做了更详细的划分；</p><hr><p><strong>二者区别:</strong></p><p>AMQP 为消息定义了线路层（wire-level protocol）的协议，而 JMS 所定义的是 API 规范。在 Java 体系中，多个 client 均可以通过 JMS 进行交互，不需要应用修改代码，但是其对跨平台的支持较差。而 AMQP 天然具有跨平台、跨语言特性。</p><p>JMS 支持 <code>TextMessage</code>、<code>MapMessage</code> 等复杂的消息类型；而 AMQP 仅支持 <code>byte[]</code> 消息类型（复杂的类型可序列化后发送）。</p><p>由于 Exchange 提供的路由算法，AMQP 可以提供多样化的路由方式来传递消息到消息队列，而 JMS 仅支持 队列 和 主题/订阅 方式两种。</p><hr><h2 id="rpc-vs-消息队列" tabindex="-1"><a class="header-anchor" href="#rpc-vs-消息队列"><span>RPC vs 消息队列</span></a></h2><ul><li><strong>从用途来看</strong>：RPC 主要用来解决两个服务的远程通信问题，不需要了解底层网络的通信机制。通过 RPC 可以帮助我们调用远程计算机上某个服务的方法，这个过程就像调用本地方法一样简单。消息队列主要用来降低系统耦合性、实现任务异步、有效地进行流量削峰。</li><li><strong>从通信方式来看</strong>：RPC 是双向直接网络通讯，消息队列是单向引入中间载体的网络通讯。</li><li><strong>从架构上来看</strong>：消息队列需要把消息存储起来，RPC 则没有这个要求，因为前面也说了 RPC 是双向直接网络通讯。</li><li><strong>从请求处理的时效性来看</strong>：通过 RPC 发出的调用一般会立即被处理，存放在消息队列中的消息并不一定会立即被处理。</li></ul><p>RPC 和消息队列本质上是网络通讯的两种不同的实现机制，两者的用途不同，万不可将两者混为一谈。</p><hr><h2 id="常见的消息队列" tabindex="-1"><a class="header-anchor" href="#常见的消息队列"><span>常见的消息队列</span></a></h2><p><strong>1. Apache Kafka</strong></p><ul><li><strong>定位</strong>：<strong>分布式流处理平台</strong>，主打高吞吐、高扩展性。</li><li><strong>特点</strong>： <ul><li><strong>极致性能</strong>：采用顺序写、页缓存、零拷贝等技术，吞吐量可达百万级/秒，在大数据领域是事实标准。</li><li><strong>持久化</strong>：消息会持久化到磁盘，并支持多副本，数据可靠性高。</li><li><strong>生态丰富</strong>：与 Flink、Spark、Storm 等流处理框架无缝集成。</li></ul></li><li><strong>典型场景</strong>：<strong>日志收集</strong>、<strong>用户行为跟踪</strong>、<strong>流式数据处理</strong>、<strong>Metrics 监控数据</strong>等海量数据且允许少量延迟的场景。</li></ul><p><strong>2. RabbitMQ</strong></p><ul><li><strong>定位</strong>：<strong>传统企业级消息代理</strong>，主打可靠性、灵活的路由和强大的管理界面。</li><li><strong>特点</strong>： <ul><li><strong>协议支持</strong>：率先支持 <strong>AMQP</strong> 协议，提供了灵活的消息路由机制（Exchange、Binding）。</li><li><strong>功能丰富</strong>：支持消息确认、持久化、死信队列、优先级队列等企业级特性。</li><li><strong>管理友好</strong>：提供非常完善和友好的 Web 管理界面。</li></ul></li><li><strong>典型场景</strong>：<strong>业务系统解耦</strong>、<strong>异步任务处理</strong>、<strong>订单系统</strong>等对消息可靠性要求高、业务逻辑复杂的场景。</li></ul><p><strong>3. Apache RocketMQ</strong></p><ul><li><strong>定位</strong>：<strong>金融级可靠</strong>的消息队列，是阿里开源的产品，在国内非常流行。</li><li><strong>特点</strong>： <ul><li><strong>金融级数据一致性</strong>：提供完整的<strong>事务消息</strong>解决方案，是其在电商、金融等领域的核心优势。</li><li><strong>海量消息堆积</strong>：支持万亿级消息堆积能力，处理慢消费场景能力强。</li><li><strong>功能全面</strong>：同时支持顺序消息、延迟消息、轨迹消息等。</li></ul></li><li><strong>典型场景</strong>：<strong>电商交易</strong>、<strong>金融支付</strong>等对事务一致性要求极高的核心业务系统。</li></ul><p><strong>4. Apache Pulsar</strong></p><ul><li><strong>定位</strong>：新一代<strong>云原生</strong>消息流平台，被誉为 Kafka 的有力竞争者。</li><li><strong>特点</strong>： <ul><li><strong>存算分离架构</strong>：采用计算（Broker）和存储（BookKeeper）分离的架构，使其扩展性极佳，故障恢复更快。</li><li><strong>多租户支持</strong>：原生支持多租户，非常适合云上部署和大公司内部平台化。</li><li><strong>一体化</strong>：同时支持队列和流两种语义，社区活跃。</li></ul></li><li><strong>典型场景</strong>：<strong>云原生环境</strong>、<strong>多租户SaaS平台</strong>、<strong>需要极致弹性的消息平台</strong>。</li></ul><p><strong>5. Redis</strong></p><ul><li><strong>定位</strong>：<strong>内存型</strong>数据结构存储，但其 Pub/Sub 和 List 结构可用于简单的消息队列场景。</li><li><strong>特点</strong>： <ul><li><strong>极致快</strong>：基于内存操作，延迟极低。</li><li><strong>功能简单</strong>：没有持久化（Pub/Sub）、没有ack机制、无高级特性，消息容易丢失。</li></ul></li><li><strong>典型场景</strong>：<strong>简单的发布订阅</strong>（如聊天室、服务发现）、<strong>实时性要求极高但允许消息丢失</strong>的业务。</li></ul><hr><h1 id="kafka" tabindex="-1"><a class="header-anchor" href="#kafka"><span>Kafka</span></a></h1><h2 id="基础" tabindex="-1"><a class="header-anchor" href="#基础"><span>基础</span></a></h2><p>Kafka本质上是一个<strong>分布式的、高吞吐量的、基于发布订阅模式的流处理平台</strong>，而不仅仅是一个传统的消息队列。它的设计目标就是处理海量的实时数据流。</p><hr><h3 id="特点" tabindex="-1"><a class="header-anchor" href="#特点"><span><strong>特点</strong></span></a></h3><p><strong>1. 高吞吐量与低延迟</strong></p><p>这是Kafka最广为人知的特点。它能在普通的硬件上支持每秒数十万甚至百万级的消息吞吐，同时保持毫秒级的延迟。这主要得益于其三大核心技术：</p><ul><li><strong>顺序读写磁盘</strong>：Kafka将消息持续追加到日志文件末尾，充分利用了磁盘顺序读写速度远快于随机读写的特性。</li><li><strong>零拷贝技术</strong>：消费者读取数据时，数据直接从磁盘文件通过DMA方式传输到网卡， bypass了应用程序和CPU的多次拷贝，极大减少了开销。</li><li><strong>页缓存与批量处理</strong>：大量利用操作系统页缓存，减少了JVM GC压力；同时生产者和消费者都支持批量操作，大幅提升了网络和I/O效率。</li></ul><p><strong>2. 可持久化与高可靠</strong></p><p>Kafka不像某些内存队列，它<strong>将所有消息持久化到磁盘</strong>，并且支持配置多副本机制。每个分区的数据都有多个副本，分布在不同Broker上，一旦主副本宕机，其他副本会迅速接管，保证了数据的可靠性和服务的可用性，消息不会丢失。</p><p><strong>3. 高可扩展性</strong></p><p>Kafka的扩展性极佳，体现在：</p><ul><li><strong>水平扩展</strong>：集群可以通过简单地增加Broker来提升整体性能。Topic可以划分为多个<strong>Partition</strong>，这些Partition可以分布在不同Broker上，实现了数据的分布式存储和并行处理。</li><li><strong>松耦合</strong>：生产者和消费者与集群是解耦的，客户端的增减不会影响Broker集群。</li></ul><p><strong>4. 丰富的生态系统</strong></p><p>Kafka不仅仅是一个消息队列，更是一个完整的<strong>流处理平台</strong>。其强大的<strong>Kafka Connect</strong>和<strong>Kafka Streams</strong>组件，使得它能够轻松地与各种数据源集成并实现复杂的流式数据处理，成为了大数据领域事实上的标准数据管道。</p><hr><h3 id="核心概念" tabindex="-1"><a class="header-anchor" href="#核心概念"><span><strong>核心概念</strong></span></a></h3><p>Kafka的核心架构围绕几个关键概念构建：</p><ul><li><strong>Producer &amp; Consumer</strong>：生产者和消费者，分别是数据的发送方和接收方。</li><li><strong>Broker</strong>：Kafka集群由多个服务器节点组成，每个节点就是一个Broker，负责接收、存储和投递消息。</li><li><strong>Topic</strong>：数据流的类别或主题，生产者向Topic发送消息，消费者订阅Topic消费消息。</li><li><strong>Partition</strong>：这是Kafka实现高并发和水平扩展的<strong>核心设计</strong>。每个Topic可以被分成多个Partition，分布在不同Broker上。消息以<strong>追加</strong>的形式写入Partition，保证了顺序性。</li><li><strong>Consumer Group</strong>：这是实现“发布-订阅”模式的关键。同一个Consumer Group内的多个消费者共同消费一个Topic，每条消息只会被组内的一个消费者消费，从而实现负载均衡。</li></ul><hr><h3 id="应用场景" tabindex="-1"><a class="header-anchor" href="#应用场景"><span><strong>应用场景</strong></span></a></h3><p>Kafka主要用在两大类场景：</p><ol><li><strong>消息系统</strong>：作为企业级的消息总线，进行系统解耦和异步通信。</li><li><strong>流处理平台</strong>：这是它更核心的定位。常用于<strong>实时日志收集</strong>、<strong>用户行为跟踪</strong>、<strong>运营指标监控</strong>等，作为大数据流处理管道（与Flink、Spark Streaming集成）的<strong>数据源</strong>。</li></ol><hr><h3 id="相比于其他消息队列的优势" tabindex="-1"><a class="header-anchor" href="#相比于其他消息队列的优势"><span>相比于其他消息队列的优势</span></a></h3><p>主要的优势如下：</p><ol><li><strong>极致的性能</strong>：基于 Scala 和 Java 语言开发，设计中大量使用了批量处理和异步的思想，最高可以每秒处理千万级别的消息。</li><li><strong>生态系统兼容性无可匹敌</strong>：Kafka 与周边生态系统的兼容性是最好的没有之一，尤其在大数据和流计算领域。</li></ol><hr><h3 id="消息模型" tabindex="-1"><a class="header-anchor" href="#消息模型"><span>消息模型</span></a></h3><p><strong>Kafka 的消息模型是基于发布-订阅模式的，其核心实现依赖于三个关键概念：主题（Topic）、分区（Partition）和消费者组（Consumer Group）。</strong></p><ol><li><strong>生产者（Producer）将消息发布到特定的主题（Topic）</strong>。主题是消息的类别或 feed 名称。</li><li><strong>每个主题可以被划分为多个分区（Partition）</strong>。分区是 Kafka 实现水平扩展和并行处理的基础。 <ul><li>消息在分区内以<strong>有序的、不可变序列</strong>方式存储，每条消息都有一个唯一的偏移量（Offset）。</li><li>生产者将消息发送到主题时，Kafka 会根据消息的 Key（或轮询策略）决定将其写入哪个分区。</li></ul></li><li><strong>消费者通过消费者组（Consumer Group）进行订阅和消费</strong>。 <ul><li>一个消费者组可以包含多个消费者实例。</li><li><strong>组内的所有消费者协同工作，共同消费一个主题的所有消息</strong>。每个分区在同一时间只能被组内的<strong>一个消费者</strong>消费。</li><li>这种设计实现了“负载均衡”和“扇出”两种模式： <ul><li><strong>负载均衡（竞争消费者模式）</strong>：所有消息被均衡地分配给组内的消费者实例处理。</li><li><strong>扇出（发布-订阅模式）</strong>：同一个主题可以被<strong>多个不同的消费者组</strong>订阅，每个组都会收到全部消息的副本。</li></ul></li></ul></li></ol><p><strong>总结来说，Kafka 的消息模型是通过“主题-分区-消费者组”的机制，将消息流进行分割（分区）并由多个消费者（组）并行处理，从而实现了高吞吐量和可扩展性。</strong></p><hr><h2 id="机制" tabindex="-1"><a class="header-anchor" href="#机制"><span>机制</span></a></h2><h3 id="多副本机制" tabindex="-1"><a class="header-anchor" href="#多副本机制"><span>多副本机制</span></a></h3><p>“Kafka的多副本机制是它保证数据不丢和服务高可用的核心设计。我了解它的核心思想是为同一份数据创建多个备份。</p><p><strong>1. 它是怎么工作的？</strong></p><ul><li>对于每个数据分片（Partition），Kafka都会创建多个副本，存放在不同的服务器上。</li><li>这些副本里，只有一个“老大”，叫做 <strong>Leader</strong>，负责处理所有的读写请求。</li><li>其他副本都是“小弟”，叫做 <strong>Follower</strong>。它们只做一件事：不停地从Leader那里拷贝数据，努力保持和Leader的数据一致。</li></ul><p><strong>2. 它带来了两大核心好处：</strong></p><ul><li><strong>第一，高可用，服务不停机。</strong> 这是最重要的好处。如果存放Leader的那台服务器宕机了，Kafka会立刻从那些数据同步得好的Follower里，自动选出一个新的Leader来顶替。这个切换过程非常快，用户几乎感觉不到，这样就保证了服务一直在线。</li><li><strong>第二，高可靠，数据不丢失。</strong> 因为同一份数据有好几个备份，即使坏掉一两台机器，数据依然安全地保存在其他机器的副本上，这样就保证了消息不会丢失。</li></ul><p><strong>3. 一个关键概念：ISR（同步副本集合）</strong></p><ul><li>不是所有Follower都能随时被选为Leader。只有那些和Leader数据差得不多的、处于“同步中”的Follower，才会被放在一个叫 <strong>ISR</strong> 的名单里。</li><li>一旦Leader宕机，只有在这个ISR名单里的Follower才有资格参加新Leader的选举。这样可以确保新Leader上的数据是最全的，避免数据错乱。</li></ul><p><strong>总结一下：</strong> Kafka通过让多个副本‘一主多从’分工协作的方式，用额外的机器和存储空间作为代价，换来了系统极高的可靠性和可用性。”</p><hr><h3 id="重试机制" tabindex="-1"><a class="header-anchor" href="#重试机制"><span>重试机制</span></a></h3><p>在消费过程中，当其中一个消息消费异常时，会进行重试，重试多次后会跳过当前消息，继续进行后续消息的消费，不会一直卡在当前消息。</p><p>默认配置下，会进行最多 10 次 的重试，每次重试的时间间隔为 0，即立即进行重试。如果在 10 次重试后仍然无法成功消费消息，则不再进行重试，消息将被视为消费失败。</p><hr><p><strong>自定义重试次数以及时间间隔</strong>，只需要在 <code>DefaultErrorHandler</code> 初始化的时候传入自定义的 <code>FixedBackOff</code> 即可。重新实现一个 <code>KafkaListenerContainerFactory</code> ，调用 <code>setCommonErrorHandler</code> 设置新的自定义的错误处理器就可以实现。</p><hr><p><strong>自定义重试失败后逻辑</strong>，需要手动实现，重写 <code>DefaultErrorHandler</code> 的 <code>handleRemaining</code> 函数，加上自定义的告警等操作。<code>DefaultErrorHandler</code> 只是默认的一个错误处理器，Spring Kafka 还提供了 <code>CommonErrorHandler</code> 接口。手动实现 <code>CommonErrorHandler</code> 就可以实现更多的自定义操作，有很高的灵活性。例如根据不同的错误类型，实现不同的重试逻辑以及业务逻辑等</p><hr><p><strong>重试失败的数据怎么处理</strong></p><p><strong>死信队列（Dead Letter Queue，简称 DLQ）</strong> 是消息中间件中的一种特殊队列。它主要用于处理无法被消费者正确处理的消息，通常是因为消息格式错误、处理失败、消费超时等情况导致的消息被&quot;丢弃&quot;或&quot;死亡&quot;的情况。当消息进入队列后，消费者会尝试处理它。如果处理失败，或者超过一定的重试次数仍无法被成功处理，消息可以发送到死信队列中，而不是被永久性地丢弃。在死信队列中，可以进一步分析、处理这些无法正常消费的消息，以便定位问题、修复错误，并采取适当的措施。</p><hr><h2 id="zookeeper" tabindex="-1"><a class="header-anchor" href="#zookeeper"><span>Zookeeper</span></a></h2><p><strong>ZooKeeper 是一个开源的分布式协调服务</strong>。它就像一个<strong>分布式系统的“大脑”或“总控中心”</strong>，为大型分布式应用提供<strong>统一配置管理、分布式锁、领导者选举</strong>和<strong>服务注册与发现</strong>等核心协同功能，保证集群中各个节点间的状态一致性与可靠协同。</p><p>它的数据模型类似于<strong>文件目录树</strong>，通过其提供的原语，开发人员可以轻松构建高可用的分布式应用。<strong>Kafka、Hadoop、HBase</strong> 等众多知名分布式系统都依赖它来实现协调管理。</p><hr><p>在 Kafka 2.8 之后，引入了基于 Raft 协议的 KRaft 模式，不再依赖 Zookeeper，大大简化了 Kafka 的架构。</p><hr><p><strong>作用</strong></p><p>ZooKeeper在早期的Kafka架构中，扮演着**‘分布式协调员’** 的核心角色，主要负责维护和管理整个Kafka集群的<strong>元数据</strong>和<strong>状态信息</strong>。它的作用主要体现在以下四个方面：</p><ol><li><strong>Broker管理：服务的注册与发现</strong><ul><li>Kafka的每个Broker（服务器）启动时，都会到ZooKeeper上的一个指定目录（如<code>/brokers/ids</code>）里<strong>注册</strong>一个临时节点，把自己的地址、端口等信息写上去。</li><li>这样，所有Broker和客户端（Producer、Consumer）都能从ZooKeeper上<strong>实时感知到</strong>当前有哪些Broker是存活在线的。这是实现服务发现的基础。</li></ul></li><li><strong>Topic与Partition的元数据管理</strong><ul><li>所有Topic的配置信息、它们被分成了几个Partition、每个Partition的副本存放在哪些Broker上……这些重要的<strong>元数据</strong>都存储在ZooKeeper中。</li><li>客户端需要知道去哪个Broker上找到某个Topic的某个Partition，就需要先查询ZooKeeper。</li></ul></li><li><strong>Controller的选举与脑裂避免</strong><ul><li>这是ZooKeeper<strong>最关键的作用</strong>。Kafka集群中需要有一个<strong>唯一的领导者</strong>，叫做Controller。</li><li>Controller负责管理分区和副本的状态，比如监控Broker故障并触发<strong>Leader副本的重新选举</strong>。</li><li>所有Broker都会尝试在ZooKeeper上抢占创建一个<strong>临时节点</strong>（比如<code>/controller</code>）。ZooKeeper能保证最终<strong>只有一个Broker能创建成功</strong>，这个Broker就成为Controller。这样就完美避免了“脑裂”（出现多个领导者）的问题。</li></ul></li><li><strong>消费者组的位移管理（老版本）</strong><ul><li>在比较老的Kafka版本中，Consumer消费到了哪个位置（Offset）这个信息也是提交到ZooKeeper来保存的。</li><li><strong>但需要特别说明的是</strong>，新版本的Kafka已经将消费位移的管理迁移到了Kafka内部一个叫做<code>__consumer_offsets</code>的特殊Topic中，不再依赖ZooKeeper，以此来提升性能和降低依赖。</li></ul></li></ol><p><strong>总结来说，ZooKeeper就像是Kafka集群的‘大脑’和‘信息公告板’，它不参与实际的数据传输，但负责维护集群里‘谁活着、谁是什么角色、数据在哪’这些最重要的元信息，保证了整个集群的协调一致和高可用。</strong></p><hr><h2 id="消费顺序、消息丢失、重复消费" tabindex="-1"><a class="header-anchor" href="#消费顺序、消息丢失、重复消费"><span>消费顺序、消息丢失、重复消费</span></a></h2><h3 id="如何保证消费顺序" tabindex="-1"><a class="header-anchor" href="#如何保证消费顺序"><span>如何保证消费顺序</span></a></h3><p>Kafka保证消息消费顺序的方式非常巧妙，它<strong>只在分区级别保证严格的消息顺序</strong>，而不是在主题级别。</p><p><strong>1. 核心机制：分区内的顺序性</strong></p><ul><li>Kafka的每个<strong>分区（Partition）</strong> 都是一个有序的、不可变的消息序列。</li><li>消息在写入分区时会获得一个唯一的<strong>偏移量（Offset）</strong>，这个偏移量就是它在分区中的顺序标识。</li><li>消费者实例在消费某个分区时，会按偏移量的顺序依次读取消息。这就保证了<strong>在单个分区内，消息的消费顺序与生产顺序是完全一致的</strong>。</li></ul><p><strong>2. 如何利用这一机制？</strong></p><p>如果业务上需要保证一组消息的顺序，我们必须确保这些消息都被发送到<strong>同一个分区</strong>。实现这一点最常见的方法是：</p><ul><li>在发送消息时，为消息指定一个<strong>Key</strong>。</li><li>Kafka的生产者客户端会根据这个Key的哈希值，计算出它应该被路由到哪个分区。</li><li>因此，<strong>所有具有相同Key的消息，都会被发送到同一个分区</strong>，从而保证了这些消息的顺序性。</li></ul><p><strong>举例说明：</strong></p><p>假设要保证同一个订单的所有状态变更消息（创建订单 -&gt; 付款 -&gt; 发货 -&gt; 完成）必须按顺序消费。我们可以在生产消息时，<strong>使用订单ID作为Key</strong>。这样，所有关于这个订单的消息都会进入同一个分区，并被消费者按顺序处理。</p><p><strong>3. 重要的限制与权衡</strong></p><ul><li><strong>全局顺序</strong>：如果需要保证整个Topic的全局顺序，只能将Topic设置为仅有<strong>1个分区</strong>。但这会严重限制Topic的吞吐量和并发能力，通常不建议这样做。</li><li><strong>消费者并发</strong>：要消费一个分区，一个消费者组内最多只能有一个消费者实例。如果分区数少于消费者数，会导致部分消费者空闲。</li></ul><p><strong>总结来说，Kafka通过‘分区内有序’的设计，配合‘让需要保序的消息拥有相同Key’的生产者策略，在提供高吞吐量的同时，满足了业务上局部的顺序性需求。</strong></p><hr><h3 id="如何保证消息不丢失" tabindex="-1"><a class="header-anchor" href="#如何保证消息不丢失"><span>如何保证消息不丢失</span></a></h3><p>Kafka为了保证消息不丢失，在其内部架构上做了几个核心的设计，这些设计共同构成了其高可靠性的基石。主要体现在以下三个方面：</p><p><strong>1. 冗余机制：多副本（Replication）</strong></p><p>这是最根本的机制。Kafka为每个分区的数据创建多个副本（例如3个），并将这些副本分散在不同的物理服务器（Broker）上。这样，单台机器的宕机或磁盘损坏不会导致数据永久丢失，因为其他副本仍然完好无损。</p><p><strong>2. 一致性协议：ISR（In-Sync Replicas）同步副本集与Leader选举</strong></p><p>光有副本还不够，必须保证副本之间的一致性。Kafka引入了ISR的概念。</p><ul><li><strong>ISR</strong>是一个动态集合，包含了所有与主副本（Leader）保持数据同步的副本。</li><li>生产者可以配置为只有当消息被ISR中的所有副本都成功接收后，才认为发送成功（对应<code>acks=all</code>）。<strong>这确保了在消息被确认时，已经在多个Broker上完成了持久化。</strong></li><li>当Leader副本失效时，Kafka的Controller组件会<strong>严格地从ISR集合中选举出新的Leader</strong>。这个机制至关重要，它防止了数据不一致的副本成为领导者，从而保证了已被生产者确认的消息绝不会因故障切换而丢失。</li></ul><p><strong>3. 持久化存储：顺序写入与日志段（Log Segment）</strong></p><ul><li>Kafka直接将消息<strong>追加（Append）写入到磁盘的日志文件</strong>中，而不是依赖内存缓存。这是一种顺序写操作，其性能非常高。</li><li>消息不会被立即删除，而是会根据配置的保留策略（例如保留7天）持久保存在磁盘上。这意味着在保留期内，即使消费者还没有消费，消息也始终安全地存在于磁盘上。</li></ul><p><strong>总结来说，Kafka自身通过‘数据多副本冗余’、‘基于ISR的一致性协议’和‘消息持久化到磁盘’这三项核心设计，从架构层面保证了消息在系统内部不会丢失。</strong></p><hr><h3 id="如何保证不重复消费" tabindex="-1"><a class="header-anchor" href="#如何保证不重复消费"><span>如何保证不重复消费</span></a></h3><p><strong>kafka 出现消息重复消费的原因：</strong></p><ul><li>服务端侧已经消费的数据没有成功提交 offset（根本原因）。</li><li>Kafka 侧 由于服务端处理业务时间长或者网络链接等等原因让 Kafka 认为服务假死，触发了分区 rebalance。</li></ul><p><strong>解决方案：</strong></p><ul><li><p>消费消息服务做幂等校验，比如 Redis 的 set、MySQL 的主键等天然的幂等功能。这种方法最有效。</p></li><li><p>将</p><p><code>enable.auto.commit</code></p><p>参数设置为 false，关闭自动提交，开发者在代码中手动提交 offset。那么这里会有个问题：</p><p>什么时候提交 offset 合适？</p><ul><li>处理完消息再提交：依旧有消息重复消费的风险，和自动提交一样</li><li>拉取到消息即提交：会有消息丢失的风险。允许消息延时的场景，一般会采用这种方式。然后，通过定时任务在业务不繁忙（比如凌晨）的时候做数据兜底。</li></ul></li></ul><hr><h1 id="rabbitmq" tabindex="-1"><a class="header-anchor" href="#rabbitmq"><span>RabbitMQ</span></a></h1><hr><h1 id="rocketmq" tabindex="-1"><a class="header-anchor" href="#rocketmq"><span>RocketMQ</span></a></h1>',160)]))}const p=o(g,[["render",a]]),h=JSON.parse('{"path":"/1.Note/3.Database_MQ/MQ.html","title":"MQ","lang":"en-US","frontmatter":{"title":"MQ","order":6},"git":{"createdTime":1756371078000,"updatedTime":1756371078000,"contributors":[{"name":"Nu11Cat","username":"Nu11Cat","email":"2111867383@qq.com","commits":1,"url":"https://github.com/Nu11Cat"}]},"readingTime":{"minutes":25.1,"words":7531},"filePathRelative":"1.Note/3.Database&MQ/MQ.md"}');export{p as comp,h as data};
