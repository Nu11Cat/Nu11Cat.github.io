<!doctype html>
<html lang="en-US" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.23" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.88" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme="dark"] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <script data-goatcounter="https://nu11cat.goatcounter.com/count" async src="//gc.zgo.at/count.js"></script><title>Redis | Nu11CatJava</title><meta name="description" content="一个Java学习者记录学习过程、积累知识、分享经验、陪伴同行者一起成长的网站">
    <link rel="preload" href="/assets/style-ClTTZfAw.css" as="style"><link rel="stylesheet" href="/assets/style-ClTTZfAw.css">
    <link rel="modulepreload" href="/assets/app-DjrNW2Lh.js"><link rel="modulepreload" href="/assets/Redis.html-LiU98JYQ.js"><link rel="modulepreload" href="/assets/plugin-vue_export-helper-DlAUqK2U.js">
    <link rel="prefetch" href="/assets/index.html-BOM55t9O.js" as="script"><link rel="prefetch" href="/assets/index.html-Dif9Urzg.js" as="script"><link rel="prefetch" href="/assets/index.html-o6WxPN_x.js" as="script"><link rel="prefetch" href="/assets/位运算.html-cLwjPneX.js" as="script"><link rel="prefetch" href="/assets/技巧_设计_语言特性.html-iH5FR_y6.js" as="script"><link rel="prefetch" href="/assets/index.html-SXRjMY1i.js" as="script"><link rel="prefetch" href="/assets/JVM.html-CpVGiEkE.js" as="script"><link rel="prefetch" href="/assets/Java IO.html-BXSkjydA.js" as="script"><link rel="prefetch" href="/assets/Java.html-Cp_V4BxM.js" as="script"><link rel="prefetch" href="/assets/Java多线程.html-eUO-3M8W.js" as="script"><link rel="prefetch" href="/assets/Java集合.html-VNrtLPuM.js" as="script"><link rel="prefetch" href="/assets/Linux _ Shell.html-BZZLesYD.js" as="script"><link rel="prefetch" href="/assets/操作系统.html-CI8Ona7u.js" as="script"><link rel="prefetch" href="/assets/计算机网络.html-DDbnigsI.js" as="script"><link rel="prefetch" href="/assets/设计模式.html-u-m9I08H.js" as="script"><link rel="prefetch" href="/assets/MyBatis.html-DP715oji.js" as="script"><link rel="prefetch" href="/assets/Netty.html-mSBvw95T.js" as="script"><link rel="prefetch" href="/assets/Nginx.html-C3fiAt3J.js" as="script"><link rel="prefetch" href="/assets/Spring Boot.html-DkEYnrW2.js" as="script"><link rel="prefetch" href="/assets/Spring Cloud.html-D7T9MHtD.js" as="script"><link rel="prefetch" href="/assets/Spring Framework.html--Lg7a56q.js" as="script"><link rel="prefetch" href="/assets/Elasticsearch.html-BLJtaiEY.js" as="script"><link rel="prefetch" href="/assets/MQ.html-DJfNywcZ.js" as="script"><link rel="prefetch" href="/assets/MongoDB.html-Cgko8Wtu.js" as="script"><link rel="prefetch" href="/assets/MySQL.html-DEW3d1-I.js" as="script"><link rel="prefetch" href="/assets/基础.html-DOzjb1v8.js" as="script"><link rel="prefetch" href="/assets/Docker.html-5sWgMLLZ.js" as="script"><link rel="prefetch" href="/assets/Git.html-1mKujBQX.js" as="script"><link rel="prefetch" href="/assets/Maven.html-Ceqk5TCE.js" as="script"><link rel="prefetch" href="/assets/k8s.html-BhyDuGPw.js" as="script"><link rel="prefetch" href="/assets/二分.html-B0xjUvnE.js" as="script"><link rel="prefetch" href="/assets/前缀和.html-DnGX-a5z.js" as="script"><link rel="prefetch" href="/assets/动态规划.html-BJNLYwCY.js" as="script"><link rel="prefetch" href="/assets/双指针.html-CAQcMEBv.js" as="script"><link rel="prefetch" href="/assets/回溯.html-CJxc0Jii.js" as="script"><link rel="prefetch" href="/assets/排序.html-DgOB3pPa.js" as="script"><link rel="prefetch" href="/assets/模拟.html-DWE-QHCR.js" as="script"><link rel="prefetch" href="/assets/贪心.html-rgiZY1W0.js" as="script"><link rel="prefetch" href="/assets/HASH.html-Bg3HE_q2.js" as="script"><link rel="prefetch" href="/assets/二叉树.html-ZY2PViMj.js" as="script"><link rel="prefetch" href="/assets/数组.html-DHuvVtkr.js" as="script"><link rel="prefetch" href="/assets/栈.html-DqXYqohh.js" as="script"><link rel="prefetch" href="/assets/矩阵.html-CEkSZ87n.js" as="script"><link rel="prefetch" href="/assets/链表.html-RZTssa5O.js" as="script"><link rel="prefetch" href="/assets/关于作者.html-BN8kJ9t7.js" as="script"><link rel="prefetch" href="/assets/Github操作.html-HJrkvGiC.js" as="script"><link rel="prefetch" href="/assets/工具网站.html-DOgvdBQl.js" as="script"><link rel="prefetch" href="/assets/404.html-t7UPdQtw.js" as="script"><link rel="prefetch" href="/assets/index.html-DT9SvfZI.js" as="script"><link rel="prefetch" href="/assets/index.html-DNWH8yxn.js" as="script"><link rel="prefetch" href="/assets/index.html-DXgkzZoG.js" as="script"><link rel="prefetch" href="/assets/index.html-lBfRzz-a.js" as="script"><link rel="prefetch" href="/assets/index.html-D8IPEz9s.js" as="script"><link rel="prefetch" href="/assets/index.html-D6_kweWL.js" as="script"><link rel="prefetch" href="/assets/index.html-BJVwiHyd.js" as="script"><link rel="prefetch" href="/assets/index.html--orMaZf_.js" as="script"><link rel="prefetch" href="/assets/index.html-D3SqBfLR.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-DXWKOczD.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">Skip to main content</a><!--]--><!--[--><div class="theme-container external-link-icon has-toc" vp-container><!--[--><header id="navbar" class="vp-navbar" vp-navbar><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><a class="route-link vp-brand" href="/" aria-label="Take me home"><!----><!----><span class="vp-site-name">Nu11CatJava</span></a><!--]--></div><div class="vp-navbar-center"><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/" aria-label="首页"><!---->首页<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/1.学习篇/" aria-label="学习篇"><!---->学习篇<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/2.面试篇/" aria-label="面试篇"><!---->面试篇<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/3.算法篇/" aria-label="算法篇"><!---->算法篇<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/4.项目篇/" aria-label="项目篇"><!---->项目篇<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/5.资源整理/" aria-label="资源整理"><!---->资源整理<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/6.关于我/" aria-label="关于我"><!---->关于我<!----></a></div></nav><!--]--></div><div class="vp-navbar-end"><!--[--><!----><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/Nu11Cat/Nu11Cat.github.io" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-color-mode-switch" id="color-mode-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" name="auto" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" name="dark" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" name="light" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar" vp-sidebar><!----><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/" aria-label="首页"><!---->首页<!----></a></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><span class="vp-sidebar-title">1. Note</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">1. Java &amp; CS</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">2. Spring&amp; Framework</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><span class="vp-sidebar-title">3. Database&amp; MQ</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/1.Note/3.Database_MQ/%E5%9F%BA%E7%A1%80.html" aria-label="数据库基础"><!---->数据库基础<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/1.Note/3.Database_MQ/MySQL.html" aria-label="MySQL"><!---->MySQL<!----></a></li><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/1.Note/3.Database_MQ/Redis.html" aria-label="Redis"><!---->Redis<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/1.Note/3.Database_MQ/Elasticsearch.html" aria-label="Elasticsearch"><!---->Elasticsearch<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/1.Note/3.Database_MQ/MongoDB.html" aria-label="MongoDB"><!---->MongoDB<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/1.Note/3.Database_MQ/MQ.html" aria-label="MQ"><!---->MQ<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">4. Tool</span><span class="vp-arrow end"></span></button><!----></section></li><li><a class="route-link auto-link vp-sidebar-link" href="/1.Note/" aria-label="Catalogue"><!---->Catalogue<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">2. Algorithm</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">3. Practice</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">4. Others</span><span class="vp-arrow end"></span></button><!----></section></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->Redis</h1><div class="page-info"><!----><!----><span class="page-date-info" aria-label="Writing Date📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span data-allow-mismatch="text">8/28/25</span><meta property="datePublished" content="2025-08-28T08:51:18.000Z"></span><!----><span class="page-reading-time-info" aria-label="Reading Time⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>About 79 min</span><meta property="timeRequired" content="PT79M"></span><!----><!----></div><hr></div><!----><div class="" vp-content><!----><div id="markdown-content"><h1 id="基础" tabindex="-1"><a class="header-anchor" href="#基础"><span>基础</span></a></h1><p>Redis 是一个基于内存的高性能 <strong>键值型 NoSQL 数据库</strong>，通常用作<strong>缓存、中间件、消息队列</strong>等。</p><h2 id="redis为什么快" tabindex="-1"><a class="header-anchor" href="#redis为什么快"><span>redis为什么快</span></a></h2><ul><li><p><strong>纯内存操作 (Memory-Based Storage)</strong> ：这是最主要的原因。Redis 数据读写操作都发生在内存中，访问速度是纳秒级别，而传统数据库频繁读写磁盘的速度是毫秒级别，两者相差数个数量级。</p></li><li><p><strong>高效的 I/O 模型 (I/O Multiplexing &amp; Single-Threaded Event Loop)</strong> ：Redis 使用单线程事件循环配合 I/O 多路复用技术，让单个线程可以同时处理多个网络连接上的 I/O 事件（如读写），避免了多线程模型中的上下文切换和锁竞争问题。虽然是单线程，但结合内存操作的高效性和 I/O 多路复用，使得 Redis 能轻松处理大量并发请求（Redis 线程模型会在后文中详细介绍到）。</p></li><li><p><strong>优化的内部数据结构 (Optimized Data Structures)</strong> ：Redis 提供多种数据类型（如 String, List, Hash, Set, Sorted Set 等），其内部实现采用高度优化的编码方式（如 ziplist, quicklist, skiplist, hashtable 等）。Redis 会根据数据大小和类型动态选择最合适的内部编码，以在性能和空间效率之间取得最佳平衡。</p></li><li><p><strong>简洁高效的通信协议 (Simple Protocol - RESP)</strong> ：Redis 使用的是自己设计的 RESP (REdis Serialization Protocol) 协议。这个协议实现简单、解析性能好，并且是二进制安全的。客户端和服务端之间通信的序列化/反序列化开销很小，有助于提升整体的交互速度。</p></li></ul><hr><h2 id="为什么比mysql快" tabindex="-1"><a class="header-anchor" href="#为什么比mysql快"><span>为什么比mysql快</span></a></h2><p><strong>内存存储</strong>：Redis 是基于内存存储的 NoSQL 数据库，而 MySQL 是基于磁盘存储的关系型数据库。由于内存存储速度快，Redis 能够更快地读取和写入数据，而无需像 MySQL 那样频繁进行磁盘 I/O 操作。</p><p><strong>简单数据结构</strong>：Redis 是基于键值对存储数据的，支持简单的数据结构（字符串、哈希、列表、集合、有序集合）。相比之下，MySQL 需要定义表结构、索引等复杂的关系型数据结构，因此在某些场景下 Redis 的数据操作更为简单高效，比如 Redis 用哈希表查询， 只需要O1 时间复杂度，而MySQL引擎的底层实现是B+Tree，时间复杂度是O(logn)</p><p><strong>线程模型</strong>：Redis 采用单线程模型可以避免了多线程之间的竞争，省去了多线程切换带来的时间和性能上的开销，而且也不会导致死锁问题。</p><hr><h2 id="为什么用redis" tabindex="-1"><a class="header-anchor" href="#为什么用redis"><span>为什么用redis</span></a></h2><p><strong>1、访问速度更快</strong></p><p>传统数据库数据保存在磁盘，而 Redis 基于内存，内存的访问速度比磁盘快很多。引入 Redis 之后，我们可以把一些高频访问的数据放到 Redis 中，这样下次就可以直接从内存中读取，速度可以提升几十倍甚至上百倍。</p><p><strong>2、高并发</strong></p><p>一般像 MySQL 这类的数据库的 QPS 大概都在 4k 左右（4 核 8g），但是使用 Redis 缓存之后很容易达到 5w+，甚至能达到 10w+（就单机 Redis 的情况，Redis 集群的话会更高）。</p><blockquote><p>QPS（Query Per Second）：服务器每秒可以执行的查询次数；</p></blockquote><p>由此可见，直接操作缓存能够承受的数据库请求数量是远远大于直接访问数据库的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。进而，我们也就提高了系统整体的并发。</p><p><strong>3、功能全面</strong></p><p>Redis 除了可以用作缓存之外，还可以用于分布式锁、限流、消息队列、延时队列等场景，功能强大！</p><hr><h2 id="为什么用redis不用本地缓存" tabindex="-1"><a class="header-anchor" href="#为什么用redis不用本地缓存"><span>为什么用redis不用本地缓存</span></a></h2><p>虽然本地缓存（如使用 Java 的 <code>Map</code> 或 <code>Guava</code> 缓存）访问速度更快，但在分布式系统中，本地缓存存在一些明显的局限，而 Redis 恰好可以解决这些问题。</p><p>首先，本地缓存是<strong>进程内存级别</strong>的，每个服务节点维护自己的缓存副本，数据无法共享，<strong>一致性难以保证</strong>。当一个节点更新了缓存，其他节点并不知情，容易出现脏读。而 Redis 作为一个独立的服务，<strong>可以作为全局缓存中心统一管理数据</strong>，避免这种一致性问题。</p><p>其次，本地缓存容量受限于单个服务实例的内存，<strong>无法支撑大规模缓存需求</strong>；而 Redis 是独立部署的，支持大内存、高并发，可以更灵活地扩展。</p><p>再者，Redis 支持<strong>丰富的数据结构和高级特性</strong>，如过期时间、LRU 淘汰策略、分布式锁、持久化、发布订阅等，这些功能是本地缓存很难实现的。</p><p>此外，在服务重启或扩缩容时，本地缓存会被清空，而 Redis 可以<strong>长期保存热点数据</strong>，避免缓存重新预热带来的性能抖动。</p><hr><h2 id="分布式缓存和本地缓存如何选择" tabindex="-1"><a class="header-anchor" href="#分布式缓存和本地缓存如何选择"><span>分布式缓存和本地缓存如何选择</span></a></h2><p><strong>本地缓存</strong>是指将数据存储在本地应用程序或服务器上，通常用于加速数据访问和提高响应速度。本地缓存通常使用内存作为存储介质，利用内存的高速读写特性来提高数据访问速度。</p><p><strong>本地缓存的优势：</strong></p><p>访问速度快：由于本地缓存存储在本地内存中，因此访问速度非常快，能够满足频繁访问和即时响应的需求。</p><p>减轻网络压力：本地缓存能够降低对远程服务器的访问次数，从而减轻网络压力，提高系统的可用性和稳定性。</p><p>低延迟：由于本地缓存位于本地设备上，因此能够提供低延迟的访问速度，适用于对实时性要求较高的应用场景。</p><p><strong>本地缓存的不足：</strong></p><p>可扩展性有限：本地缓存的可扩展性受到硬件资源的限制，无法支持大规模的数据存储和访问。</p><hr><p><strong>分布式缓存</strong>是指将数据存储在多个分布式节点上，通过协同工作来提供高性能的数据访问服务。分布式缓存通常使用集群方式进行部署，利用多台服务器来分担数据存储和访问的压力。</p><p><strong>分布式缓存的优势：</strong></p><p>可扩展性强：分布式缓存的节点可以动态扩展，能够支持大规模的数据存储和访问需求。</p><p>数据一致性高：通过分布式一致性协议，分布式缓存能够保证数据在多个节点之间的一致性，减少数据不一致的问题。</p><p>易于维护：分布式缓存通常采用自动化管理方式，能够降低维护成本和管理的复杂性。</p><p><strong>分布式缓存的不足：</strong></p><p>访问速度相对较慢：相对于本地缓存，分布式缓存的访问速度相对较慢，因为数据需要从多个节点进行访问和协同。</p><p>网络开销大：由于分布式缓存需要通过网络进行数据传输和协同操作，因此相对于本地缓存来说，网络开销较大。</p><hr><p><strong>如何选择</strong></p><p>数据大小：如果数据量较小，且对实时性要求较高，本地缓存更适合；如果数据量较大，且需要支持大规模的并发访问，分布式缓存更具优势。</p><p>网络状况：如果网络状况良好且稳定，分布式缓存能够更好地发挥其优势；如果网络状况较差或不稳定，本地缓存的访问速度和稳定性可能更有优势。</p><p>业务特点：对于实时性要求较高、访问模式比较固定的场景，本地缓存能提供极快的响应速度；而对于数据需要在多个服务之间共享、保证一致性的场景，分布式缓存会更合适。</p><p>一致性要求：本地缓存可能存在数据不一致的问题，如果业务对一致性要求不高，可以接受一定的延迟，那么本地缓存足够；但如果需要保证强一致性，就需要依赖分布式缓存。</p><p>扩展性：本地缓存受到单机资源的限制，扩展能力有限；分布式缓存则更适合水平扩展，应对高并发和海量数据的场景。</p><hr><h1 id="应用" tabindex="-1"><a class="header-anchor" href="#应用"><span>应用</span></a></h1><h2 id="redis能做什么" tabindex="-1"><a class="header-anchor" href="#redis能做什么"><span>redis能做什么</span></a></h2><p>redis用作<strong>数据缓存</strong>，这是最常见的用途，比如缓存用户信息、热点商品数据、页面渲染结果，减轻数据库压力，加快响应速度。</p><p>另外，Redis 可以用作<strong>分布式锁</strong>，利用其原子性操作保障多节点环境下对共享资源的互斥访问，常用于防止超卖、重复提交等问题。</p><p>其次，Redis 支持<strong>消息队列</strong>功能，可以通过 list、stream 或发布订阅机制实现简单的异步通信，用于系统解耦、异步处理等场景。</p><p>此外，Redis 常用于<strong>计数器和限流器</strong>，比如统计接口调用次数、用户行为次数，结合过期时间可以快速实现限流、频控等需求。</p><p>Redis 还常被用作<strong>会话存储（Session 共享）</strong>，在分布式系统中统一管理用户登录状态，避免单点服务丢失会话信息。</p><p>在业务层面，Redis 的有序集合结构适合实现<strong>排行榜、点赞数、活跃用户统计等功能</strong>，Geo 类型也可以支持<strong>地理位置存储与距离计算</strong>。</p><p>最后，Redis 还可用来实现<strong>延迟队列、任务调度、热点数据预加载</strong>等需求，充分发挥其高性能和多结构的特点。</p><h2 id="redis实现分布式锁" tabindex="-1"><a class="header-anchor" href="#redis实现分布式锁"><span>redis实现分布式锁</span></a></h2><p>基于 Redis 实现分布式锁的核心思路，是<strong>利用 Redis 提供的原子性命令 <code>SET key value NX EX</code></strong>。这个命令可以在 key 不存在时设置值，并指定过期时间，保证<strong>只有一个客户端能成功加锁</strong>，从而达到互斥的效果。</p><p>实现过程主要包括几个关键点：</p><ol><li><strong>加锁（互斥）</strong>：使用 <code>SET key value NX EX</code>，其中 NX 表示“仅当 key 不存在时设置”，EX 设置过期时间，避免死锁。</li><li><strong>锁唯一性</strong>：value 通常设置为<strong>唯一标识</strong>（比如 UUID），用于标记是哪一个客户端加的锁，防止误解锁。</li><li><strong>防止死锁</strong>：设置合理的过期时间，即使客户端异常宕机，锁也能自动释放。</li><li><strong>释放锁（安全解锁）</strong>：解锁时需要<strong>判断 value 是否一致</strong>，只有加锁的客户端才能释放对应的锁，避免误删其他线程的锁。这通常需要使用 Lua 脚本来实现 check-and-delete 的原子操作。</li></ol><p>除了单实例实现方式，Redis 官方也提供了分布式场景下更稳健的 <strong>Redlock 算法</strong>，它通过在多个 Redis 节点上同时加锁、获取多数派响应，以提高分布式环境下的容错能力和可用性。</p><hr><p><strong>什么场景使用分布式锁</strong></p><p>分布式锁主要用在<strong>多节点、多进程并发访问共享资源</strong>的场景，避免数据不一致或并发冲突。常见的应用场景有：</p><ol><li><strong>库存扣减</strong>：在电商秒杀场景中，多台应用服务器同时扣减库存，需要保证同一件商品不会被超卖。</li><li><strong>订单生成</strong>：防止同一个用户或同一个商品重复下单，保证幂等性。</li><li><strong>定时任务</strong>：在分布式系统中，多个节点可能同时触发相同的定时任务，需要通过分布式锁确保任务只执行一次。</li><li><strong>共享资源访问</strong>：如生成全局唯一编号、更新缓存数据、操作某些临界资源等，都需要通过分布式锁来保证互斥。</li></ol><hr><h2 id="redis做消息队列" tabindex="-1"><a class="header-anchor" href="#redis做消息队列"><span>redis做消息队列</span></a></h2><p><strong>Redis 可以用来实现消息队列</strong>，并且在一些对可靠性要求不高的轻量场景中，它是一种非常实用的解决方案。</p><p>Redis 提供多种数据结构支持队列功能，比如：</p><ul><li>使用 <strong>list</strong> 搭配 <code>LPUSH + BRPOP</code> 实现最基本的<strong>先进先出队列</strong>；</li><li>使用 <strong>stream</strong> 类型可以支持<strong>多消费者组、消费确认、阻塞读取</strong>，更接近完整的消息队列能力；</li><li>也可以用 <strong>pub/sub</strong> 实现<strong>实时广播消息</strong>，用于通知类场景。</li></ul><p>Redis 实现的消息队列具有<strong>响应快、部署简单、集成成本低</strong>的优点，非常适合用于<strong>异步处理、系统解耦、任务削峰</strong>等轻量级场景，比如：异步发送短信、订单通知、注册后欢迎邮件等。</p><p>但需要注意的是，<strong>Redis 并不是专业的消息中间件</strong>，它在以下方面存在不足：</p><ul><li><strong>消息丢失风险</strong>：比如消费者异常宕机、未及时处理消息，消息可能无法恢复；</li><li><strong>缺乏完整的消费确认机制</strong>（list 模型下尤其明显）；</li><li><strong>不支持消息重试、死信队列等机制</strong>；</li><li>在极端高并发、海量消息场景下<strong>可扩展性和稳定性不如 Kafka、RocketMQ 等专业方案</strong>。</li></ul><p>因此，实际选择时要根据业务场景权衡：</p><ul><li>如果只是简单地做异步任务或削峰处理，对可靠性要求不高，Redis 是一种高效、灵活的方案；</li><li>如果消息的顺序、可靠投递、消息持久化等是关键要求，建议使用 Kafka、RabbitMQ 等成熟的消息中间件。</li></ul><h2 id="redis做搜索引擎" tabindex="-1"><a class="header-anchor" href="#redis做搜索引擎"><span>redis做搜索引擎</span></a></h2><p>Redis 本身不是为搜索引擎设计的，但在一定程度上<strong>可以支持一些简单的搜索功能</strong>，特别是基于关键字的检索。通过手动构建倒排索引、结合集合操作（如 <code>SINTER</code>、<code>SUNION</code>）或使用 Redis Module（如 RedisSearch），可以实现关键词匹配、标签筛选等轻量级搜索能力。</p><p>例如，RedisSearch 模块提供了分词、全文索引、权重评分、排序等能力，支持类似搜索引擎的查询语法，适合构建中小型、对实时性要求高的搜索系统。</p><hr><p>对于比较复杂或者数据规模较大的搜索场景，还是不太建议使用 RediSearch 来作为搜索引擎，主要是因为下面这些限制和问题：</p><ul><li><p>数据量限制：Elasticsearch 可以支持 PB 级别的数据量，可以轻松扩展到多个节点，利用分片机制提高可用性和性能。RedisSearch 是基于 Redis 实现的，其能存储的数据量受限于 Redis 的内存容量，不太适合存储大规模的数据（内存昂贵，扩展能力较差）。</p></li><li><p>分布式能力较差：Elasticsearch 是为分布式环境设计的，可以轻松扩展到多个节点。虽然 RedisSearch 支持分布式部署，但在实际应用中可能会面临一些挑战，如数据分片、节点间通信、数据一致性等问题。</p></li><li><p>聚合功能较弱：Elasticsearch 提供了丰富的聚合功能，而 RediSearch 的聚合功能相对较弱，只支持简单的聚合操作。</p></li><li><p>生态较差：Elasticsearch 可以轻松和常见的一些系统/软件集成比如 Hadoop、Spark、Kibana，而 RedisSearch 则不具备该优势。</p></li></ul><hr><p>RediSearch相对于Elasticsearch的优势：</p><ul><li><p>性能更优秀：依赖 Redis 自身的高性能，基于内存操作（Elasticsearch 基于磁盘）。</p></li><li><p>较低内存占用实现快速索引：RediSearch 内部使用压缩的倒排索引，所以可以用较低的内存占用来实现索引的快速构建。</p></li></ul><h2 id="redis实现延时任务" tabindex="-1"><a class="header-anchor" href="#redis实现延时任务"><span>Redis实现延时任务</span></a></h2><p>基于 Redis 实现延时任务的功能有下面两种方案：</p><ol><li>Redis 过期事件监听。</li><li>Redisson 内置的延时队列。</li></ol><hr><p>Redis 过期事件监听存在时效性较差、丢消息、多服务实例下消息重复消费等问题，不被推荐使用。</p><p><strong>Redis 过期事件监听如何实现延时任务</strong></p><p>Redis 可以通过过期事件监听机制来实现延时任务。这个机制的核心原理是利用 Redis 的键空间通知（Keyspace Notifications）功能，当一个设置了过期时间的 key 到期时，Redis 会自动将其删除，并向指定频道发布一条过期事件通知。</p><p>具体来说，Redis 会将过期事件以消息的形式发送到名为 <code>__keyevent@&lt;db&gt;__:expired</code> 的频道（其中 <code>&lt;db&gt;</code> 是数据库编号）。我们只需要在客户端订阅这个频道，就能在 key 过期的瞬间感知到这个事件，并触发对应的业务逻辑，从而实现延时任务的调度。</p><p>这个机制本质上是 Redis 发布订阅（Pub/Sub）功能的一种内置应用场景。通过设置过期 key + 订阅过期事件，就可以在 key 被删除时执行延迟任务逻辑。</p><p><strong>Redis 过期事件监听实现延时任务的缺陷</strong></p><p>1、时效性差：过期事件消息是在 Redis 服务器删除 key 时发布的，而不是一个 key 过期之后就会就会直接发布。Redis 采用的是 定期删除+惰性删除 。因此，就会存在我设置了 key 的过期时间，但到了指定时间 key 还未被删除，进而没有发布过期事件的情况。</p><p>2、丢消息：Redis 的 pub/sub 模式中的消息并不支持持久化，这与消息队列不同。在 Redis 的 pub/sub 模式中，发布者将消息发送给指定的频道，订阅者监听相应的频道以接收消息。当没有订阅者时，消息会被直接丢弃，在 Redis 中不会存储该消息。</p><p>3、多服务实例下消息重复消费：Redis 的 pub/sub 模式目前只有广播模式，这意味着当生产者向特定频道发布一条消息时，所有订阅相关频道的消费者都能够收到该消息。这个时候，我们需要注意多个服务实例重复处理消息的问题，这会增加代码开发量和维护难度。</p><hr><p><strong>Redisson 延时队列</strong></p><p>Redisson 的延迟队列 RDelayedQueue 是基于 Redis 的 SortedSet 来实现的。SortedSet 是一个有序集合，其中的每个元素都可以设置一个分数，代表该元素的权重。Redisson 利用这一特性，将需要延迟执行的任务插入到 SortedSet 中，并给它们设置相应的过期时间作为分数。</p><p>Redisson 定期使用 <code>zrangebyscore</code> 命令扫描 SortedSet 中过期的元素，然后将这些过期元素从 SortedSet 中移除，并将它们加入到就绪消息列表中。就绪消息列表是一个阻塞队列，有消息进入就会被消费者监听到。这样做可以避免消费者对整个 SortedSet 进行轮询，提高了执行效率。</p><p><strong>Redisson 延时队列的优势</strong></p><ol><li><strong>减少了丢消息的可能</strong>：DelayedQueue 中的消息会被持久化，即使 Redis 宕机了，根据持久化机制，也只可能丢失一点消息，影响不大。当然了，你也可以使用扫描数据库的方法作为补偿机制。</li><li><strong>消息不存在重复消费问题</strong>：每个客户端都是从同一个目标队列中获取任务的，不存在重复消费的问题。</li></ol><hr><p>跟 Redisson 内置的延时队列相比，<strong>消息队列</strong>可以通过保障消息消费的可靠性、控制消息生产者和消费者的数量等手段来实现更高的吞吐量和更强的可靠性，实际项目中首选使用消息队列的延时消息这种方案。</p><hr><h1 id="数据类型" tabindex="-1"><a class="header-anchor" href="#数据类型"><span>数据类型</span></a></h1><h2 id="_5种基本数据类型" tabindex="-1"><a class="header-anchor" href="#_5种基本数据类型"><span>5种基本数据类型</span></a></h2><p>Redis 5 种基本数据类型其底层实现主要依赖这 8 种数据结构：简单动态字符串（SDS）、LinkedList（双向链表）、Dict（哈希表/字典）、SkipList（跳跃表）、Intset（整数集合）、ZipList（压缩列表）、QuickList（快速列表）。</p><p>实现如下表所示：</p><table><thead><tr><th style="text-align:left;">String</th><th style="text-align:left;">List</th><th style="text-align:left;">Hash</th><th style="text-align:left;">Set</th><th style="text-align:left;">Zset</th></tr></thead><tbody><tr><td style="text-align:left;">SDS</td><td style="text-align:left;">LinkedList/ZipList/QuickList</td><td style="text-align:left;">Dict、ZipList</td><td style="text-align:left;">Dict、Intset</td><td style="text-align:left;">ZipList、SkipList</td></tr></tbody></table><p>Redis 3.2 之前，List 底层实现是 LinkedList 或者 ZipList。 Redis 3.2 之后，引入了 LinkedList 和 ZipList 的结合 QuickList，List 的底层实现变为 QuickList。从 Redis 7.0 开始， ZipList 被 ListPack 取代。</p><hr><h3 id="string-字符串" tabindex="-1"><a class="header-anchor" href="#string-字符串"><span>String(字符串)</span></a></h3><p>Redis 并没有使用 C 的字符串表示，而是自己构建了一种 <strong>简单动态字符串</strong>（Simple Dynamic String，<strong>SDS</strong>）。相比于 C 的原生字符串，Redis 的 SDS 不光可以保存文本数据还可以保存二进制数据，并且获取字符串长度复杂度为 O(1)（C 字符串为 O(N)）,除此之外，Redis 的 SDS API 是安全的，不会造成缓冲区溢出。</p><p>SDS 的<strong>结构</strong>中包含了几个重要部分：</p><ol><li><strong>len</strong>：记录当前已使用的字节数（不包含结尾的 \0），避免每次求长度都要遍历；</li><li><strong>alloc</strong>：表示分配的总容量，便于后续扩容；</li><li><strong>flags</strong>：标记 SDS 的类型；</li><li><strong>buf[]</strong>：存放实际的字符串内容，以 <code>\0</code> 结尾，兼容 C 字符串。</li></ol><hr><p>SDS <strong>相比于 C 语言中的字符串</strong>有如下提升：</p><ol><li><strong>可以避免缓冲区溢出</strong>：C 语言中的字符串被修改（比如拼接）时，一旦没有分配足够长度的内存空间，就会造成缓冲区溢出。SDS 被修改时，会先根据 len 属性检查空间大小是否满足要求，如果不满足，则先扩展至所需大小再进行修改操作。</li><li><strong>获取字符串长度的复杂度较低</strong>：C 语言中的字符串的长度通常是经过遍历计数来实现的，时间复杂度为 O(n)。SDS 的长度获取直接读取 len 属性即可，时间复杂度为 O(1)。</li><li><strong>减少内存分配次数</strong>：为了避免修改（增加/减少）字符串时，每次都需要重新分配内存（C 语言的字符串是这样的），SDS 实现了空间预分配和惰性空间释放两种优化策略。当 SDS 需要增加字符串时，Redis 会为 SDS 分配好内存，并且根据特定的算法分配多余的内存，这样可以减少连续执行字符串增长操作所需的内存重分配次数。当 SDS 需要减少字符串时，这部分内存不会立即被回收，会被记录下来，等待后续使用（支持手动释放，有对应的 API）。</li><li><strong>二进制安全</strong>：C 语言中的字符串以空字符 <code>\0</code> 作为字符串结束的标识，这存在一些问题，像一些二进制文件（比如图片、视频、音频）就可能包括空字符，C 字符串无法正确保存。SDS 使用 len 属性判断字符串是否结束，不存在这个问题。</li></ol><hr><p><strong>应用场景：</strong></p><ul><li><p><strong>需要存储常规数据的场景</strong>：缓存 Session、Token、图片地址、序列化后的对象(相比较于 Hash 存储更节省内存)。</p></li><li><p><strong>需要计数的场景</strong>：用户单位时间的请求数（简单限流可以用到）、页面单位时间的访问数。</p></li><li><p><strong>分布式锁</strong>：利用 <code>SETNX key value</code> 命令可以实现一个最简易的分布式锁（存在一些缺陷，通常不建议这样实现分布式锁）。</p></li></ul><hr><h3 id="list-列表" tabindex="-1"><a class="header-anchor" href="#list-列表"><span>List(列表)</span></a></h3><p>Redis 中的 List 其实就是链表数据结构的实现。Redis 的 List 的实现为一个 <strong>双向链表</strong>，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销。</p><hr><p><strong>应用场景：</strong></p><ul><li><p><strong>信息流展示</strong>：最新文章、最新动态。</p></li><li><p><strong>消息队列</strong>：<code>List</code> 可以用来做消息队列，只是功能过于简单且存在很多缺陷，不建议这样做。</p></li></ul><hr><h3 id="hash-哈希" tabindex="-1"><a class="header-anchor" href="#hash-哈希"><span>Hash(哈希)</span></a></h3><p>Redis 中的 Hash 是一个 String 类型的 field-value（键值对） 的映射表，特别适合用于存储对象。</p><hr><p><strong>应用场景：</strong></p><ul><li><strong>对象数据存储场景</strong>：举例：用户信息、商品信息、文章信息、购物车信息。</li></ul><hr><h3 id="set-集合" tabindex="-1"><a class="header-anchor" href="#set-集合"><span>Set(集合)</span></a></h3><p>Redis 中的 Set 类型是一种无序集合，集合中的元素没有先后顺序但都唯一。</p><hr><p><strong>应用场景：</strong></p><ul><li><strong>需要存放的数据不能重复的场景</strong>：网站 UV 统计（数据量巨大的场景还是 <code>HyperLogLog</code>更适合一些）、文章点赞、动态点赞等场景。</li><li><strong>需要获取多个数据源交集、并集和差集的场景</strong>：共同好友(交集)、共同粉丝(交集)、共同关注(交集)、好友推荐（差集）、音乐推荐（差集）、订阅号推荐（差集+交集） 等场景。</li><li><strong>需要随机获取数据源中的元素的场景</strong>：抽奖系统、随机点名等场景。</li></ul><hr><h3 id="sorted-set-zset-有序集合" tabindex="-1"><a class="header-anchor" href="#sorted-set-zset-有序集合"><span>Sorted Set(ZSet)(有序集合)</span></a></h3><p>Sorted Set 类似于 Set，但和 Set 相比，Sorted Set 增加了一个权重参数 <code>score</code>，使得集合中的元素能够按 <code>score</code> 进行有序排列，还可以通过 <code>score</code> 的范围来获取元素的列表。</p><hr><p><strong>如何实现</strong>：</p><p>在 Redis 中，<strong>ZSet 的底层实现和元素数量、元素长度有关</strong>：</p><ol><li><strong>压缩列表（ziplist，在新版本里叫 listpack）</strong><ul><li>当 ZSet <strong>元素数量较少</strong>（默认 &lt;128 个）并且 <strong>元素值不长</strong>（默认每个成员 &lt;64 字节），会用压缩列表实现。</li><li>这种情况下内存更紧凑，节省空间，但查询效率不如跳表。</li></ul></li><li><strong>哈希表（dict）+ 跳表（skiplist）</strong><ul><li>当元素数量超过阈值，或者元素过大，Redis 会自动转为 <strong>dict + skiplist</strong> 的结构。</li><li><strong>dict</strong>：member → score，O(1) 查找元素。</li><li><strong>skiplist</strong>：score → member，有序存储，支持范围查找、排序，O(logN)。</li><li>这样能兼顾查找和范围操作的效率。</li></ul></li></ol><p><a href="https://javaguide.cn/database/redis/redis-skiplist.html" target="_blank" rel="noopener noreferrer">Redis为什么用跳表实现有序集合 | JavaGuide</a></p><p><a href="https://javaguide.cn/database/redis/redis-questions-01.html#redis-%E7%9A%84%E6%9C%89%E5%BA%8F%E9%9B%86%E5%90%88%E5%BA%95%E5%B1%82%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E7%94%A8%E8%B7%B3%E8%A1%A8-%E8%80%8C%E4%B8%8D%E7%94%A8%E5%B9%B3%E8%A1%A1%E6%A0%91%E3%80%81%E7%BA%A2%E9%BB%91%E6%A0%91%E6%88%96%E8%80%85-b-%E6%A0%91" target="_blank" rel="noopener noreferrer">Redis 的有序集合底层为什么要用跳表，而不用平衡树、红黑树或者 B+ 树？</a></p><hr><p><strong>应用场景：</strong></p><ul><li><strong>需要随机获取数据源中的元素根据某个权重进行排序的场景</strong>：各种排行榜比如直播间送礼物的排行榜、朋友圈的微信步数排行榜、王者荣耀中的段位排行榜、话题热度排行榜等等。</li><li><strong>需要存储的数据有优先级或者重要程度的场景</strong> 比如优先级任务队列</li></ul><hr><h3 id="其他" tabindex="-1"><a class="header-anchor" href="#其他"><span>其他</span></a></h3><p><strong>存储对象数据用 String 还是 Hash 更好？</strong></p><p>如果对象是整体读写，且字段变化不频繁，可以直接将对象序列化为一个字符串，用 Redis 的 String 类型存储。它结构简单、访问效率高，适合存储结构固定、内容完整读取的场景，比如用户信息、配置快照等。</p><p>而使用 Hash 类型，则更适合对象字段粒度更细、需要频繁按字段读写的情况。Redis 会将 Hash 中的每个 field-value 对独立管理，支持单字段更新，节省流量，也更利于数据解耦。例如，修改用户昵称、头像时只需更新对应字段，无需整体序列化或反序列化。</p><p>此外，Hash 类型在字段较少时内部实现是压缩结构，占用内存更小，但字段过多时可能会影响性能。</p><ul><li>如果是整体读写、结构固定，适合用 String；如果需要按字段读写、字段较多、变更频繁，Hash 更灵活高效。</li></ul><hr><p><strong>购物车信息用 String 还是 Hash 存储更好呢?</strong></p><p>存储购物车信息，更推荐使用 Hash 类型，因为它更适合按用户维度分组、按商品维度操作的场景。</p><p>具体来说，购物车的数据结构通常是：一个用户对应多个商品及其数量。使用 Hash 类型，我们可以将每个用户的购物车作为一个 key（如 <code>cart:userId</code>），其中 field 是商品 ID，value 是数量。</p><p>这样的设计带来几个优势：</p><ol><li>按需更新字段：可以只修改某个商品的数量，避免整体序列化和反序列化；</li><li>结构清晰：每个用户一份 cart，Redis key 总量可控，便于管理；</li><li>节省空间：Redis 对小规模 Hash 做了压缩编码处理，内存更高效；</li><li>业务操作灵活：可以通过 <code>HGETALL</code> 快速获取整个购物车，或者用 <code>HINCRBY</code> 修改某一商品数量。</li></ol><p>相比之下，如果使用 String 存储，每个用户的购物车都需要整体序列化成字符串（如 JSON），每次修改都涉及反序列化、修改、再写入，性能开销更大，代码也更复杂。</p><hr><p><strong>使用Sorted Set实现排行榜</strong></p><p>Redis 实现排行榜最常用的数据结构是 有序集合（Sorted Set），它天生支持按分数排序，非常适合排行榜这种按成绩、积分、热度排名的场景。</p><p>在实现上，排行榜中的每个用户或对象作为有序集合的 member，得分作为 score。我们可以通过以下方式实现：</p><ol><li>添加或更新成员排名：使用 <code>ZADD</code> 命令将用户及其分数加入排行榜，已有则更新；</li><li>获取某个范围的排名：使用 <code>ZREVRANGE</code> 实现从高到低获取前 N 名；</li><li>获取某个用户的排名：使用 <code>ZREVRANK</code> 获取某个用户当前在排行榜中的名次；</li><li>获取某个用户的得分：使用 <code>ZSCORE</code> 查看分数；</li><li>按需设置过期时间或定期清理：可按天、周、月维护多个排行榜 key，例如 <code>rank:daily:20250716</code>，便于隔离不同周期的数据。</li></ol><p>Redis 的有序集合底层使用跳表实现，支持按分数排序的高效插入与查询操作，同时保持集合中成员唯一，避免重复用户。</p><hr><p><strong>使用 Set 实现抽奖系统</strong></p><p>Redis 的 Set 类型非常适合用来实现抽奖系统，原因是它具有元素唯一性和随机操作能力，可以高效地完成抽奖相关逻辑。</p><p>具体实现方式如下：</p><ol><li>初始化奖池：将所有参与抽奖的用户 ID 或奖品 ID 存入一个 Set，例如 <code>SADD lottery_users user1 user2 ...</code>；</li><li>随机抽取中奖者：使用 <code>SRANDMEMBER</code> 从 Set 中随机抽取指定数量的元素，但不删除；</li><li>抽中后移除：如果抽奖规则要求不能重复中奖，可以使用 <code>SPOP</code>，该命令会从 Set 中随机弹出元素，抽一次减一个；</li><li>查看当前奖池人数：使用 <code>SCARD</code> 查看当前参与抽奖的总人数；</li><li>防止重复参与：Set 的唯一性特性天然防止重复添加用户；</li><li>记录中奖名单：可以将中奖者另存一个 Set 或 List，用于后续展示或发奖。</li></ol><p>这种方式适用于用户数量中等、并发不高的抽奖系统，数据结构简单，效率高。</p><hr><h2 id="_3种特殊数据类型" tabindex="-1"><a class="header-anchor" href="#_3种特殊数据类型"><span>3种特殊数据类型</span></a></h2><h3 id="bitmap-位图" tabindex="-1"><a class="header-anchor" href="#bitmap-位图"><span>Bitmap(位图)</span></a></h3><p>Bitmap 存储的是连续的二进制数字（0 和 1），通过 Bitmap, 只需要一个 bit 位来表示某个元素对应的值或者状态，key 就是对应元素本身 。</p><hr><p><strong>应用场景</strong>：</p><ul><li><strong>需要保存状态信息（0/1 即可表示）的场景</strong>：用户签到情况、活跃用户情况、用户行为统计（比如是否点赞过某个视频）。</li></ul><hr><h3 id="hyperloglog-基数统计" tabindex="-1"><a class="header-anchor" href="#hyperloglog-基数统计"><span>HyperLogLog (基数统计)</span></a></h3><p>HyperLogLog 是一种有名的基数计数概率算法 ，基于 LogLog Counting(LLC)优化改进得来，并不是 Redis 特有的，Redis 只是实现了这个算法并提供了一些开箱即用的 API。</p><p>Redis 提供的 HyperLogLog 占用空间非常非常小，只需要 12k 的空间就能存储接近<code>2^64</code>个不同元素。并且，Redis 对 HyperLogLog 的存储结构做了优化，采用两种方式计数：</p><ul><li><strong>稀疏矩阵</strong>：计数较少的时候，占用空间很小。</li><li><strong>稠密矩阵</strong>：计数达到某个阈值的时候，占用 12k 的空间。</li></ul><hr><p>基数计数概率算法为了节省内存并不会直接存储元数据，而是通过一定的概率统计方法预估基数值（集合中包含元素的个数）。因此， HyperLogLog 的计数结果并不是一个精确值，存在一定的误差（标准误差为 <code>0.81%</code> ）。</p><hr><p><strong>应用场景：</strong></p><ul><li><strong>数量巨大（百万、千万级别以上）的计数场景</strong>：热门网站每日/每周/每月访问 ip 数统计、热门帖子 uv 统计。</li></ul><hr><h3 id="geospatial-index-地理位置" tabindex="-1"><a class="header-anchor" href="#geospatial-index-地理位置"><span>Geospatial index(地理位置)</span></a></h3><p>Geospatial index（地理空间索引，简称 GEO） 主要用于存储地理位置信息，基于 Sorted Set 实现。</p><p>通过 GEO 我们可以轻松实现两个位置距离的计算、获取指定位置附近的元素等功能。</p><hr><p><a href="https://juejin.cn/post/6844903966061363207" target="_blank" rel="noopener noreferrer">Redis 到底是怎么实现“附近的人”这个功能的呢？前言：针对“附近的人”这一位置服务领域的应用场景，常见的可使用PG、 - 掘金</a></p><hr><p><strong>应用场景：</strong></p><ul><li><strong>需要管理使用地理空间数据的场景</strong>：附近的人。</li></ul><hr><h3 id="其他-1" tabindex="-1"><a class="header-anchor" href="#其他-1"><span>其他</span></a></h3><p><strong>使用 Bitmap 统计活跃用户</strong></p><p>使用 Redis 的 Bitmap 可以非常高效地统计用户的活跃状态，尤其适合按天、按月等周期统计用户是否活跃、<strong>活跃人数</strong>等场景，核心思路是：用用户 ID 对应 Bitmap 的偏移位，值为 1 表示当天活跃，0 表示未活跃。</p><p>具体做法如下：</p><ol><li>设置活跃状态：当某个用户访问系统时，使用 <code>SETBIT key userId 1</code> 将对应偏移位置为 1。例如：<code>SETBIT active:20250716 12345 1</code>，表示用户 ID 为 12345 在 7 月 16 日活跃；</li><li>统计活跃人数：使用 <code>BITCOUNT key</code> 统计 Bitmap 中值为 1 的位数，即当天活跃用户数；</li><li>判断某用户是否活跃：用 <code>GETBIT key userId</code> 判断某天某用户是否活跃；</li><li>多天活跃分析：可使用 <code>BITOP AND/OR</code> 对多个日期的 Bitmap 做并集或交集，分析连续活跃、总活跃人数等；</li><li>空间高效：Bitmap 本质是二进制位图，支持千万级用户状态压缩在少量内存中，非常节省空间。</li></ol><p>这种方式适合大规模用户活跃统计，尤其在日活、周活、留存分析等业务中非常常见。</p><hr><p><strong>使用 HyperLogLog 统计页面 UV</strong></p><p>HyperLogLog 是 Redis 提供的一种基于概率的数据结构，专门用于高性能地统计海量数据的基数（即不重复元素的个数），非常适合用来统计网站页面的 UV（Unique Visitor）。</p><p>实现方式如下：</p><ol><li>记录访客：每当用户访问页面时，使用 <code>PFADD key userId</code> 将用户 ID（如 IP、用户 ID、会话 ID）添加到 HyperLogLog 中。例如：<code>PFADD uv:20250716 12345</code>；</li><li>获取 UV 数：使用 <code>PFCOUNT key</code> 获取 HyperLogLog 中去重后的用户数量，即当天页面 UV；</li><li>跨日合并统计：若需统计某段时间内的 UV，比如一周，可用 <code>PFMERGE</code> 将多日数据合并到一个新 key，再用 <code>PFCOUNT</code> 查询；</li><li>空间高效：HyperLogLog 不存储具体用户 ID，只维护概率桶，内存占用恒定在约 <strong>12KB</strong>，即使统计上亿用户，空间也不会增加。</li></ol><p>需要注意的是，HyperLogLog 是一种近似统计结构，误差在 0.81% 左右，不适用于要求精确去重的场景。</p><h2 id="其他-2" tabindex="-1"><a class="header-anchor" href="#其他-2"><span>其他</span></a></h2><h3 id="skiplist-跳表" tabindex="-1"><a class="header-anchor" href="#skiplist-跳表"><span>SkipList(跳表)</span></a></h3><p>在 Redis 中，<strong>只有 ZSet（有序集合）用到了跳表</strong>作为底层实现之一。</p><p>跳表（Skip List）是一种有序的数据结构，它通过在链表的基础上增加多层索引来加快查找效率。普通有序链表查找需要 O(n)，而跳表通过分层索引，将时间复杂度降到 O(log n)，性能接近平衡树，同时实现更简单。</p><hr><p><strong>实现方式上：</strong></p><ol><li><strong>层级结构</strong>：跳表是多层的，每一层都是一个有序链表，最底层包含所有数据，越往上的层，节点数越少。</li><li><strong>索引提升</strong>：插入新节点时，会随机生成一个高度 h，把这个节点加入到底层链表，并以概率逐层往上建立索引。这样形成类似“高速公路”的结构。</li><li><strong>查询过程</strong>：查找时，从最高层开始，逐层向下、向右跳，直到找到目标或确定不存在。</li><li><strong>复杂度</strong>：查找、插入、删除的平均复杂度都是 O(log n)，空间复杂度 O(n)。</li></ol><p>跳表的优势是：实现简单，支持区间查找，非常适合做有序集合。Redis 的 <strong>ZSet 就用跳表来存储大规模有序数据</strong>。</p><hr><p><strong>跳表是怎么设置层高的？</strong></p><p>在跳表中，节点的层高（level）是随机生成的，这是跳表的核心思想之一。</p><p><strong>实现方式</strong>一般是：</p><ol><li>给每个节点分配层高时，<strong>从第 1 层开始</strong>，每往上一层都以固定概率 p（通常是 0.5）继续增加一层。</li><li>直到随机失败，或者达到最大层数（如 32 层）。</li><li>这样节点层高的分布近似 <strong>几何分布</strong>：大多数节点只有 1~2 层，极少数节点能达到很高的层。</li></ol><p><strong>为什么这样设计？</strong></p><ul><li>通过概率控制，让高层节点稀疏，形成“金字塔结构”；</li><li>查找时能快速跳跃，平均查找复杂度为 O(log n)；</li><li>实现比红黑树、AVL 树等平衡树更简单，不需要复杂的旋转操作，依靠随机性自动保持“平衡”。</li></ul><p><strong>Redis 跳表举例：</strong> Redis 的 <code>zset</code> 跳表节点层数就是这样用随机数生成的，最大层数 32，概率因子 p=0.25。</p><hr><p><strong>Redis 为什么使用跳表而不是 B+ 树？</strong></p><p>简单来讲：Redis 选择跳表而不是 B+ 树，是因为 Redis 基于内存，不需要 B+ 树的磁盘友好特性；而跳表实现更简单、更新代价更小、范围查询更高效，完全能满足有序集合的需求。</p><ol><li><strong>实现复杂度</strong><ul><li>B+ 树要维护严格的平衡，涉及到节点分裂、合并、旋转，代码复杂；</li><li>跳表只依赖随机算法决定层高，插入/删除逻辑简单，易于实现。</li></ul></li><li><strong>内存存储特性</strong><ul><li>Redis 的数据都在内存里，<strong>CPU 随机访问内存的代价远低于磁盘 I/O</strong>；</li><li>B+ 树的优势主要体现在磁盘存储上，因为它能减少磁盘访问次数；</li><li>在纯内存场景下，跳表完全能满足性能需求。</li></ul></li><li><strong>范围查询性能</strong><ul><li>跳表的<strong>底层是有序链表</strong>，天然支持范围查找，直接顺序遍历即可；</li><li>B+ 树虽然也能做范围查找，但要不断扫描叶子节点，逻辑更复杂。</li></ul></li><li><strong>动态更新更轻量</strong><ul><li>插入/删除时，跳表只需局部修改几个指针，平均复杂度 O(log n)；</li><li>B+ 树插入/删除可能触发节点分裂、合并，调整代价更大。</li></ul></li><li><strong>可预测性与性能均衡</strong><ul><li>跳表查询/插入/删除都能稳定在 O(log n)，并且性能表现接近平衡树；</li><li>对 Redis 这种高并发读写的场景，非常合适。</li></ul></li></ol><hr><h3 id="ziplist-压缩列表" tabindex="-1"><a class="header-anchor" href="#ziplist-压缩列表"><span>ZipList(压缩列表)</span></a></h3><p>压缩列表（ZipList）是 Redis 为了节省内存而设计的一种 <strong>连续内存存储结构</strong>，主要用于存储小量数据，比如 List、Hash、Zset 在数据量较小时会采用它。</p><p>它的实现是：将多个元素紧凑地存放在一块连续内存中，每个元素是一个 entry，包含前一个元素的长度、编码方式和数据内容。通过 <code>prevlen</code> 字段既可以向前遍历，也可以向后遍历。</p><p>这种结构的优点是 <strong>节省内存</strong>，访问时能顺序遍历；缺点是插入、删除元素需要移动后续数据，甚至可能引发连锁更新，所以只适合小数据场景。</p><hr><p><strong>具体实现</strong>：</p><ol><li><strong>结构组成</strong><ul><li><strong>zlbytes</strong>：整个 ziplist 占用字节数。</li><li><strong>zltail</strong>：指向最后一个 entry 的偏移量，方便从尾部快速定位。</li><li><strong>zllen</strong>：entry 数量。</li><li><strong>entry</strong>：存储具体数据（每个 entry 包含三部分：<code>prevlen</code> 前一个节点长度、<code>encoding</code> 编码方式、<code>content</code> 实际内容）。</li><li><strong>zlend</strong>：特殊标记（0xFF），表示列表结束。</li></ul></li><li><strong>存储特点</strong><ul><li>连续内存块存放所有 entry，节省内存，没有额外指针开销。</li><li><code>prevlen</code> 字段保证可以从任意节点向前遍历，支持双向访问。</li><li>entry 的编码方式灵活：小整数、短字符串直接紧凑存储，减少内存浪费。</li></ul></li><li><strong>缺点</strong><ul><li>插入或删除节点时需要 <strong>移动大量内存</strong>，时间复杂度 O(n)，不适合数据量太大的场景。</li><li>链式更新问题：如果某个节点长度变化，会影响后续节点的 prevlen 字段，可能引发连锁更新。</li></ul></li></ol><hr><h3 id="listpack-紧凑列表" tabindex="-1"><a class="header-anchor" href="#listpack-紧凑列表"><span>listpack(紧凑列表)</span></a></h3><p>Listpack 是 Redis 在 Redis 5.0 后引入，为了替代压缩列表而设计的一种 <strong>紧凑型、连续内存的数据结构</strong>，主要用于 <strong>List、Hash、Zset 等底层在元素数量较少或元素较小的场景</strong>。</p><p>它的实现思路和压缩列表类似：同样是把多个 entry 紧凑存放在一块连续内存里。但和 ziplist 不同的是，listpack <strong>每个 entry 都记录自身长度</strong>，而不是记录前一个元素的长度，这样避免了 ziplist 中因为 <code>prevlen</code> 变大导致的“连锁更新”问题。</p><p>所以相比 ziplist，listpack 的优点是：</p><ol><li>内存利用率高，仍然很紧凑；</li><li>插入和删除不会引发大规模数据搬移，性能更稳定；</li><li>设计更简单，减少了 ziplist 那种复杂的边界情况。</li></ol><p>缺点是仍然不适合特别大的数据量，一旦超阈值 Redis 会自动转换为更合适的结构，比如 <strong>quicklist（list）、哈希表（hash）、跳表（zset）</strong>。</p><hr><h3 id="dict-哈希表-字典" tabindex="-1"><a class="header-anchor" href="#dict-哈希表-字典"><span>Dict(哈希表/字典)</span></a></h3><p>Redis 的 哈希表（dict）与 Java 的 <code>HashMap</code> 实现细节不同。</p><p>Redis 的哈希表是典型的 <strong>数组 + 链表</strong> 实现，没有红黑树优化。</p><hr><p><strong>渐进式 rehash 扩容过程</strong>：</p><ol><li>当哈希表负载因子过大时，Redis 会创建一个新的更大的哈希表。</li><li>不是一次性把所有数据迁移过去，而是把 <strong>旧表和新表同时保留</strong>。</li><li>每次有读写操作时，Redis 会顺便把旧表中的少量数据迁移到新表里。</li><li>这样逐步迁移，直到旧表数据全部转移完毕，才释放旧表。</li></ol><p>优点是：<strong>避免了大规模数据迁移造成的性能抖动</strong>，保证了高并发下的平稳运行。</p><p>另外，在渐进式 rehash 进行期间，<strong>新增</strong>一个 key-value 时，会被保存到「哈希表 2 」里面，而「哈希表 1」 则不再进行任何添加操作，这样保证了「哈希表 1 」的 key-value 数量只会减少，随着 rehash 操作的完成，最终「哈希表 1 」就会变成空表。</p><p><strong>查找</strong>一个 key 的值的话，先会在「哈希表 1」 里面进行查找，如果没找到，就会继续到哈希表 2 里面进行找到。</p><hr><p><strong>应用场景：</strong></p><ul><li>Redis 内部的 key-value 数据库本身就是一个哈希表。</li><li>Hash 类型（存储对象属性）在元素数量大、字段较大时也会转换为哈希表存储。</li></ul><hr><h1 id="持久化机制" tabindex="-1"><a class="header-anchor" href="#持久化机制"><span>持久化机制</span></a></h1><p>Redis 支持持久化，而且支持 3 种持久化方式：</p><ul><li>快照（snapshotting，RDB）；</li><li>只追加文件（append-only file，AOF）；</li><li>RDB 和 AOF 的混合持久化（Redis 4.0 新增）。</li></ul><h2 id="rdb快照" tabindex="-1"><a class="header-anchor" href="#rdb快照"><span>RDB快照</span></a></h2><p>Redis 可以通过创建快照来获得存储在内存里面的数据在 <strong>某个时间点</strong> 上的副本。Redis 创建快照之后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis 主从结构，主要用来提高 Redis 性能），还可以将快照留在原地以便重启服务器的时候使用。</p><p>快照持久化是 Redis 默认采用的持久化方式</p><hr><p><strong>RDB 快照是如何实现的呢？</strong></p><p>RDB（Redis DataBase）快照是 Redis 的另一种持久化方式，它通过 <strong>生成内存数据的快照文件</strong>（<code>.rdb</code> 文件）来保存数据。实现过程大致如下：</p><ol><li><strong>触发方式</strong><ul><li>手动触发：<code>SAVE</code>（阻塞）、<code>BGSAVE</code>（后台子进程方式）。</li><li>自动触发：根据配置文件中的 <code>save m n</code> 策略（n 秒内有 m 次写操作）。</li></ul></li><li><strong>实现机制</strong><ul><li><strong>BGSAVE 常用</strong>：Redis 主进程 fork 一个子进程。</li><li>子进程负责将内存中的数据序列化并写入 <code>.rdb</code> 文件。</li><li>主进程继续处理客户端请求，不受阻塞。</li><li>写期间借助 <strong>写时复制（Copy-On-Write）</strong>：主进程修改数据时，才会复制相关页，保证快照一致性。</li></ul></li><li><strong>恢复数据</strong><ul><li>Redis 启动时如果配置了 RDB，会加载 <code>.rdb</code> 文件，将快照数据还原到内存。</li></ul></li></ol><p>总结：RDB 优点是文件体积小、恢复快，缺点是可能丢失最后一次快照后的数据（实时性差）。</p><hr><p><strong>优缺点</strong></p><p>**优点：**RDB通过快照的形式保存某一时刻的数据状态，文件体积小，备份和恢复的速度非常快。并且，RDB是在主线程之外通过fork子进程来进行的，不会阻塞服务器处理命令请求，对Redis服务的性能影响较小。最后，由于是定期快照，RDB文件通常比AOF文件小得多。</p><p>**缺点：**RDB方式在两次快照之间，如果Redis服务器发生故障，这段时间的数据将会丢失。并且，如果在RDB创建快照到恢复期间有写操作，恢复后的数据可能与故障前的数据不完全一致</p><hr><p><strong>RDB 创建快照时会阻塞主线程吗？</strong></p><p>Redis 提供了两个命令来生成 RDB 快照文件：</p><ul><li><code>save</code> : 同步保存操作，会阻塞 Redis 主线程；</li><li><code>bgsave</code> : fork 出一个子进程，子进程执行，不会阻塞 Redis 主线程，默认选项。</li></ul><hr><h2 id="aof日志" tabindex="-1"><a class="header-anchor" href="#aof日志"><span>AOF日志</span></a></h2><p>与快照持久化相比，AOF 持久化的实时性更好。默认情况下 Redis 没有开启 AOF（append only file）方式的持久化（Redis 6.0 之后已经默认是开启了）。</p><hr><p><strong>工作流程</strong></p><p>AOF 持久化功能的实现可以简单分为 5 步：</p><ol><li><strong>命令追加（append）</strong>：所有的写命令会追加到 AOF 缓冲区中。</li><li><strong>文件写入（write）</strong>：将 AOF 缓冲区的数据写入到 AOF 文件中。这一步需要调用<code>write</code>函数（系统调用），<code>write</code>将数据写入到了系统内核缓冲区之后直接返回了（延迟写）。注意！！！此时并没有同步到磁盘。</li><li><strong>文件同步（fsync）</strong>：AOF 缓冲区根据对应的持久化方式（ <code>fsync</code> 策略）向硬盘做同步操作。这一步需要调用 <code>fsync</code> 函数（系统调用）， <code>fsync</code> 针对单个文件操作，对其进行强制硬盘同步，<code>fsync</code> 将阻塞直到写入磁盘完成后返回，保证了数据持久化。</li><li><strong>文件重写（rewrite）</strong>：随着 AOF 文件越来越大，需要定期对 AOF 文件进行重写，达到压缩的目的。</li><li><strong>重启加载（load）</strong>：当 Redis 重启时，可以加载 AOF 文件进行数据恢复。</li></ol><hr><p><strong>AOF 日志是如何实现的？</strong></p><p>AOF（Append Only File）是 Redis 的一种持久化方式，它通过将每条写命令以追加的方式记录到日志文件中来实现数据持久化。当 Redis 重启时，会按日志顺序重新执行这些命令，从而恢复数据。AOF 的写入可以通过三种策略控制持久化频率：每条命令立即写盘（保证最强一致性，但性能开销大）、每秒写盘（折中方案，可能丢失一秒内的数据）、操作系统自己决定写盘时间（效率最高，但丢失风险最大）。</p><hr><p><strong>优缺点</strong></p><p>**优点：**首先，AOF提供了更好的数据安全性，因为它默认每接收到一个写命令就会追加到文件末尾。即使Redis服务器宕机，也只会丢失最后一次写入前的数据。其次，AOF支持多种同步策略（如everysec、always等），可以根据需要调整数据安全性和性能之间的平衡。同时，AOF文件在Redis启动时可以通过重写机制优化，减少文件体积，加快恢复速度。并且，即使文件发生损坏，AOF还提供了redis-check-aof工具来修复损坏的文件。</p><p>**缺点：**因为记录了每一个写操作，所以AOF文件通常比RDB文件更大，消耗更多的磁盘空间。并且，频繁的磁盘IO操作（尤其是同步策略设置为always时）可能会对Redis的写入性能造成一定影响。而且，当问个文件体积过大时，AOF会进行重写操作，AOF如果没有开启AOF重写或者重写频率较低，恢复过程可能较慢，因为它需要重放所有的操作命令。</p><hr><p><a href="https://javaguide.cn/database/redis/redis-persistence.html#aof-%E6%8C%81%E4%B9%85%E5%8C%96%E6%96%B9%E5%BC%8F%E6%9C%89%E5%93%AA%E4%BA%9B" target="_blank" rel="noopener noreferrer">AOF 持久化方式有哪些？</a></p><p><a href="https://javaguide.cn/database/redis/redis-persistence.html#aof-%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AF%E5%9C%A8%E6%89%A7%E8%A1%8C%E5%AE%8C%E5%91%BD%E4%BB%A4%E4%B9%8B%E5%90%8E%E8%AE%B0%E5%BD%95%E6%97%A5%E5%BF%97" target="_blank" rel="noopener noreferrer">AOF 为什么是在执行完命令之后记录日志？</a></p><p><a href="https://javaguide.cn/database/redis/redis-persistence.html#aof-%E9%87%8D%E5%86%99%E4%BA%86%E8%A7%A3%E5%90%97" target="_blank" rel="noopener noreferrer">AOF 重写了解吗？</a></p><p><a href="https://javaguide.cn/database/redis/redis-persistence.html#aof-%E6%A0%A1%E9%AA%8C%E6%9C%BA%E5%88%B6%E4%BA%86%E8%A7%A3%E5%90%97" target="_blank" rel="noopener noreferrer">AOF 校验机制了解吗？</a></p><hr><h2 id="其他-3" tabindex="-1"><a class="header-anchor" href="#其他-3"><span>其他</span></a></h2><p><a href="https://javaguide.cn/database/redis/redis-persistence.html#%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9-rdb-%E5%92%8C-aof" target="_blank" rel="noopener noreferrer">如何选择 RDB 和 AOF？</a></p><p><a href="https://javaguide.cn/database/redis/redis-persistence.html#redis-4-0-%E5%AF%B9%E4%BA%8E%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6%E5%81%9A%E4%BA%86%E4%BB%80%E4%B9%88%E4%BC%98%E5%8C%96" target="_blank" rel="noopener noreferrer">Redis 4.0 对于持久化机制做了什么优化？</a></p><hr><h1 id="线程模型" tabindex="-1"><a class="header-anchor" href="#线程模型"><span>线程模型</span></a></h1><p>对于读写命令来说，Redis 一直是单线程模型。不过，在 Redis 4.0 版本之后引入了多线程来执行一些大键值对的异步删除操作，Redis 6.0 版本之后引入了多线程来处理网络请求（提高网络 IO 读写性能）。</p><hr><h2 id="单线程模型" tabindex="-1"><a class="header-anchor" href="#单线程模型"><span>单线程模型</span></a></h2><p><strong>Redis 基于 Reactor 模式设计开发了一套高效的事件处理模型</strong>（Netty 的线程模型也基于 Reactor 模式），这套事件处理模型对应的是 Redis 中的文件事件处理器（file event handler）。由于文件事件处理器（file event handler）是单线程方式运行的，所以我们一般都说 Redis 是单线程模型。</p><hr><p><strong>文件事件处理器</strong></p><p>在 Redis 中，文件事件处理器（File Event Handler）是其事件驱动架构的核心组件，用于协调客户端请求的接收、处理和响应，是实现高并发网络通信的关键机制。</p><p>可以简单理解为以下四个部分组成：</p><ol><li>多路复用器（IO 多路复用） Redis 底层使用 <code>select</code>、<code>epoll</code> 等系统调用（Linux 默认是 epoll）监听多个 socket 上的事件（如可读、可写、新连接等）。</li><li>文件事件（File Events） 每个 socket（客户端连接）上的“读就绪”“写就绪”事件被封装成文件事件。</li><li>事件分派器 Redis 主线程不断从多路复用器中获取就绪事件，并将其分派给对应的事件处理器函数（回调函数）去处理。</li><li>事件处理器 比如处理“读事件”时，会读取客户端发送的命令，再执行命令并准备返回结果。</li></ol><hr><p><strong>单线程怎么监听大量的客户端连接呢？</strong></p><p>虽然 Redis 的命令处理是单线程的，但它依然可以高效处理大量客户端连接，关键在于它采用了I/O 多路复用技术。</p><p>具体来说，Redis 使用的是 <code>epoll</code>（Linux 下的高性能 I/O 多路复用机制），通过一个线程同时监听多个客户端的 socket 连接事件。当某个连接有数据可读时，Redis 就会在主线程中依次读取、解析并执行命令。</p><p>这种方式的优点是：</p><ol><li>不需要为每个连接创建线程，避免了线程上下文切换和资源开销；</li><li>利用事件驱动机制，让主线程始终处于高效的事件循环中，只处理“就绪”的连接；</li><li>即使有成千上万个连接，只要不是同时大量发送命令，Redis 依旧能快速响应。</li></ol><p>从 Redis 6.0 开始，还引入了多线程处理网络读写，进一步缓解了单线程 I/O 的瓶颈，但命令执行仍然在主线程中，保证了数据操作的原子性和一致性。</p><hr><p><strong>为什么没有使用多线程</strong></p><p>Redis 在 6.0 之前没有使用多线程，是出于性能、简单性和一致性的考虑。Redis 以“单线程+事件驱动”著称，这种模型的优点是：</p><ol><li>避免了并发控制的复杂性：操作完全串行，无需加锁，天然线程安全；</li><li>延迟更低、执行更快：内存操作快，加上 I/O 多路复用，不需要频繁上下文切换；</li><li>代码逻辑清晰，易于维护和调优。</li></ol><p>在当时的硬件和业务场景下，这种设计足够支撑大多数中高并发需求。</p><hr><h2 id="多线程模型" tabindex="-1"><a class="header-anchor" href="#多线程模型"><span>多线程模型</span></a></h2><p><strong>为什么引入多线程</strong></p><p>是因为在高并发网络场景下，瓶颈不再是命令执行，而是网络 I/O 和数据读写。Redis 的单线程模型虽然执行快，但面对大量并发连接时：</p><ul><li>读取客户端数据（recv）、解析命令、发送响应（send）这些 I/O 操作耗时增加；</li><li>主线程需要处理的工作变重，CPU 利用率不均衡，多核优势无法发挥；</li><li>在网卡和网络栈优化之后，网络成为了新的性能短板。</li></ul><p>因此，从 Redis 6.0 开始，引入了多线程用于网络读写阶段，即：</p><ul><li>多个线程负责接收客户端请求、读取数据；</li><li>命令解析和执行仍由主线程处理，保持数据一致性和简洁性；</li><li>响应发送也可通过多线程加速。</li></ul><p>这种方式既提升了网络性能，又不引入多线程并发执行命令的复杂性。</p><hr><h2 id="后台线程" tabindex="-1"><a class="header-anchor" href="#后台线程"><span>后台线程</span></a></h2><p>虽然 Redis 的命令处理主流程是单线程的，但它实际上运行着多个<strong>后台线程或子线程</strong>，用于处理一些<strong>耗时操作或系统性任务</strong>，以避免阻塞主线程，提高整体响应能力。</p><p>常见的后台线程或任务包括：</p><ol><li><strong>持久化相关线程</strong><ul><li>Redis 在执行 RDB 快照或 AOF 重写时，会<strong>创建子进程（fork）</strong>，用于在后台保存数据，不影响主线程服务客户端请求。</li></ul></li><li><strong>异步删除大 key 或释放内存</strong><ul><li>当删除大型对象（如大 List/Hash）或键空间淘汰时，Redis 会将这些操作交给后台线程异步处理，防止主线程被长时间阻塞。</li></ul></li><li><strong>AOF rewrite buffer 同步线程</strong><ul><li>在 AOF 重写过程中，有专门线程将命令追加到重写缓冲区。</li></ul></li><li><strong>I/O 多线程（从 Redis 6.0 起）</strong><ul><li>Redis 引入了多线程支持用于处理网络读写，主线程负责命令执行，多线程负责数据的接收和发送，提高并发性能。</li></ul></li><li><strong>后台定期任务线程</strong><ul><li>包括过期键删除、定时任务、统计信息更新等，也会部分通过异步调度方式处理，避免集中耗时。</li></ul></li></ol><hr><h1 id="网络模型" tabindex="-1"><a class="header-anchor" href="#网络模型"><span>网络模型</span></a></h1><p>Redis 使用的是 <strong>I/O 多路复用（IO multiplexing）+ 单线程事件驱动</strong> 的网络模型。</p><ol><li><strong>I/O 多路复用</strong><ul><li>通过 <code>select/poll/epoll/kqueue</code> 这些系统调用，Redis 可以在一个线程里同时监听成千上万个客户端的连接。</li><li>当某个连接有事件发生（可读/可写），操作系统会通知 Redis，避免了传统阻塞 I/O 里“一直等待”的浪费。</li></ul></li><li><strong>单线程事件循环</strong><ul><li>Redis 内部有一个事件循环（event loop），类似一个 <code>while(true)</code> 死循环： <ul><li>处理 I/O 事件（客户端请求）</li><li>处理定时任务（比如过期键删除）</li><li>处理文件事件（AOF、RDB）</li></ul></li><li>所有命令的执行都在 <strong>单线程顺序执行</strong>，避免了加锁开销。</li></ul></li><li><strong>高效的原因</strong><ul><li>单线程避免上下文切换和锁竞争。</li><li>I/O 多路复用保证 Redis 即便有大量连接，也能高效调度。</li><li>命令执行本身大多是内存操作，非常快。</li></ul></li></ol><hr><h2 id="i-o-多路复用" tabindex="-1"><a class="header-anchor" href="#i-o-多路复用"><span>I/O 多路复用</span></a></h2><p><strong>为什么要使用 I/O 多路复用</strong></p><p>Redis 是 <strong>单线程</strong> 处理网络请求的（早期版本如此，核心命令处理仍是单线程），如果采用传统阻塞 I/O，那么一个连接的读写操作阻塞，就会影响到所有请求。 I/O 多路复用的好处是：</p><ul><li><strong>单线程也能高并发</strong>：通过内核提供的 <code>select</code>、<code>epoll</code> 等机制，同时监听大量连接的读写事件。</li><li><strong>避免线程切换开销</strong>：Redis 不需要为每个连接分配线程，而是依赖内核告诉它哪个连接可读/可写。</li><li><strong>保证高吞吐</strong>：即使几万个客户端连接，单线程也能高效处理。</li></ul><hr><p><strong>Redis 是怎么实现的</strong></p><ul><li>Redis 封装了一个事件处理器 <strong><code>ae</code>（ae.c）</strong>，里面统一封装了 <code>select</code>、<code>epoll</code>、<code>kqueue</code> 等系统调用，根据操作系统选择最优实现。</li><li>Redis 主线程会把 <strong>socket 文件描述符</strong> 注册到多路复用器中，监听 <strong>读事件</strong> 和 <strong>写事件</strong>。</li><li>当有事件发生时（比如客户端发来命令），内核会通知 Redis，Redis 就调用对应的事件回调函数进行处理。</li><li>整个过程是 <strong>事件驱动模型</strong>（Reactor 模式），保证单线程也能高效处理海量请求。</li></ul><hr><h1 id="内存管理" tabindex="-1"><a class="header-anchor" href="#内存管理"><span>内存管理</span></a></h1><h2 id="数据过期" tabindex="-1"><a class="header-anchor" href="#数据过期"><span>数据过期</span></a></h2><p><strong>一般情况下，缓存数据都会设置一个过期时间。为什么？</strong></p><p>缓存数据设置过期时间，主要是为了解决数据一致性、内存占用和系统稳定性等几个核心问题：</p><ol><li><strong>保证数据的时效性和一致性</strong> 缓存属于副本，可能会和数据库中的真实数据存在差异。设置过期时间可以让旧数据自动失效，降低缓存与数据源之间的不一致风险。</li><li><strong>防止缓存膨胀，节约内存资源</strong> 如果不设置过期时间，缓存中的数据可能长期存在，导致内存不断增长，最终可能引发 OOM（内存溢出）或缓存淘汰压力过大。</li><li><strong>提升系统的可控性和可维护性</strong> 设置合理的过期策略，可以更好地控制缓存命中率、失效时机，从而在更新频繁、热点突变等场景下保持系统稳定。</li><li><strong>应对业务场景中的数据变化</strong> 比如排行榜、活动页、热搜词等数据本身就是周期性变化的，设置过期时间可以自动驱动数据刷新，减少手动干预。</li></ol><hr><p><strong>Redis 是如何判断数据是否过期的呢？</strong></p><p>Redis 通过一个叫做过期字典（可以看作是 hash 表）来保存数据过期的时间。过期字典的键指向 Redis 数据库中的某个 key（键），过期字典的值是一个 long long 类型的整数，这个整数保存了 key 所指向的数据库键的过期时间（毫秒精度的 UNIX 时间戳）。</p><p>当 Redis 需要判断一个 key 是否过期时，会执行以下逻辑：</p><p>**1. 先查主字典（dict）：**是否存在这个 key； **2. 再查过期字典（expires dict）：**如果存在该 key 的过期时间，Redis 会将当前系统时间与其过期时间进行对比； <strong>3. 如果当前时间 ≥ 过期时间，则认为该 key 已过期。</strong></p><hr><p><strong>大量Key集中过期怎么办</strong></p><p>当 Redis 中存在大量 key 在同一时间点集中过期时，可能会导致以下问题：</p><ul><li>请求延迟增加：Redis 在处理过期 key 时需要消耗 CPU 资源，如果过期 key 数量庞大，会导致 Redis 实例的 CPU 占用率升高，进而影响其他请求的处理速度，造成延迟增加。</li><li>内存占用过高：过期的 key 虽然已经失效，但在 Redis 真正删除它们之前，仍然会占用内存空间。如果过期 key 没有及时清理，可能会导致内存占用过高，甚至引发内存溢出。</li></ul><p>为了避免这些问题，可以采取以下方案：</p><ol><li>尽量避免 key 集中过期：在设置键的过期时间时尽量随机一点。</li><li>开启 lazy free 机制：修改 <code>redis.conf</code> 配置文件，将 <code>lazyfree-lazy-expire</code> 参数设置为 <code>yes</code>，即可开启 lazy free 机制。开启 lazy free 机制后，Redis 会在后台异步删除过期的 key，不会阻塞主线程的运行，从而降低对 Redis 性能的影响。</li></ol><hr><h2 id="过期删除策略" tabindex="-1"><a class="header-anchor" href="#过期删除策略"><span>过期删除策略</span></a></h2><p>常用的过期数据的删除策略：</p><ol><li><strong>惰性删除</strong>：只会在取出/查询 key 的时候才对数据进行过期检查。这种方式对 CPU 最友好，但是可能会造成太多过期 key 没有被删除。</li><li><strong>定期删除</strong>：周期性地随机从设置了过期时间的 key 中抽查一批，然后逐个检查这些 key 是否过期，过期就删除 key。相比于惰性删除，定期删除对内存更友好，对 CPU 不太友好。</li><li><strong>延迟队列</strong>：把设置过期时间的 key 放到一个延迟队列里，到期之后就删除 key。这种方式可以保证每个过期 key 都能被删除，但维护延迟队列太麻烦，队列本身也要占用资源。</li><li><strong>定时删除</strong>：每个设置了过期时间的 key 都会在设置的时间到达时立即被删除。这种方法可以确保内存中不会有过期的键，但是它对 CPU 的压力最大，因为它需要为每个键都设置一个定时器。</li></ol><hr><p><strong>Redis 采用的是那种删除策略呢？</strong></p><p>Redis 采用的是 定期删除+惰性/懒汉式删除 结合的策略，这也是大部分缓存框架的选择。定期删除对内存更加友好，惰性删除对 CPU 更加友好。两者各有千秋，结合起来使用既能兼顾 CPU 友好，又能兼顾内存友好。</p><hr><p><strong>为什么 Redis 采用惰性删除和定期删除的策略，而不是在 key 一过期就立即删除它？</strong></p><p>主要是出于性能和可扩展性的考虑。</p><p>首先，如果要做到 key 一过期就立刻删除，就意味着 Redis 需要为每一个设置了过期时间的 key 启动一个定时器，持续监听它是否到期。这种方式会带来两个严重的问题：</p><ol><li>性能开销高 Redis 是高性能的内存数据库，如果每个 key 都要创建定时任务或轮询检查，会造成 CPU 资源浪费，尤其在大量 key 存在时，系统开销难以控制。</li><li>线程调度复杂 Redis 的核心是单线程执行命令，频繁地处理定时删除会引入大量异步调度逻辑，破坏简单的事件模型，增加系统复杂度，也容易引发不可控的延迟。</li></ol><hr><p><strong>Redis 中的定期删除是如何做的</strong></p><p>它的实现方式并不是遍历所有设置了过期时间的 key，而是采用了“定期 + 随机 + 控制频率”的策略，具体逻辑如下：</p><ol><li>执行频率 默认每秒执行 <strong>10 次</strong>过期扫描（由 <code>serverCron</code> 定时器触发）。</li><li>随机抽样 每次从带有过期时间的 key 中随机抽取最多 20 个 key。</li><li>过期判断并删除 遍历这 20 个 key，比较当前时间与每个 key 的过期时间，如果已过期则立即删除。</li><li>重复触发机制 如果这 20 个 key 中，超过 25% 是已过期的，Redis 会继续执行下一轮扫描，直到比例小于 25% 或达到最大执行时间限制（避免阻塞主线程）。</li></ol><hr><p><strong>为什么是随机抽样而不是把所有过期 key 都删除？</strong></p><p>这样会对性能造成太大的影响。如果我们 key 数量非常庞大的话，挨个遍历检查是非常耗时的，会严重影响性能。Redis 设计这种策略的目的是为了平衡内存和性能。</p><hr><h2 id="内存淘汰策略" tabindex="-1"><a class="header-anchor" href="#内存淘汰策略"><span>内存淘汰策略</span></a></h2><blockquote><p>相关问题：MySQL 里有 2000w 数据，Redis 中只存 20w 的数据，如何保证 Redis 中的数据都是热点数据?</p></blockquote><p>Redis 的内存淘汰策略只有在运行内存达到了配置的最大内存阈值时才会触发，这个阈值是通过 <code>redis.conf</code> 的 <code>maxmemory</code> 参数来定义的。64 位操作系统下，<code>maxmemory</code> 默认为 0，表示不限制内存大小。32 位操作系统下，默认的最大内存值是 3GB。</p><hr><p>Redis 提供了多种内存淘汰策略，用于在内存使用达到上限时决定如何处理新写入请求。整体策略分为两类：<strong>只淘汰设置了过期时间的 key</strong>，和<strong>对所有 key 都可能淘汰</strong>。</p><p>具体来说，有以下几种常见策略：</p><ul><li><strong>noeviction</strong>：默认策略，不淘汰任何 key，一旦内存满了，写入命令会报错，适用于对数据完整性要求高的场景。</li><li><strong>volatile-lru / allkeys-lru</strong>：使用最近最少使用（LRU）策略淘汰 key，<code>volatile-lru</code> 只针对设置了过期时间的 key，<code>allkeys-lru</code> 则适用于所有 key，适合缓存类应用。</li><li><strong>volatile-lfu / allkeys-lfu</strong>：使用最不常用（LFU）策略淘汰 key，淘汰访问频率最低的 key，更适合访问分布稳定的场景。</li><li><strong>volatile-random / allkeys-random</strong>：随机淘汰 key，策略简单但效果不稳定。</li><li><strong>volatile-ttl</strong>：优先淘汰快要过期的 key，基于剩余生存时间。</li></ul><h2 id="内存碎片" tabindex="-1"><a class="header-anchor" href="#内存碎片"><span>内存碎片</span></a></h2><p><strong>为什么redis会有内存碎片</strong></p><p>Redis 内存碎片的本质，是由于<strong>内存分配和释放不均衡</strong>，导致<strong>物理内存中虽然还有空闲空间，但无法有效利用</strong>，形成内存碎片。</p><p>主要原因包括以下几点：</p><ol><li><strong>频繁分配与释放内存</strong>： Redis 在不断写入、删除 key 的过程中，频繁地申请和释放内存，容易造成大小不一的空闲块分布在内存中，难以复用。</li><li><strong>数据结构扩容缩容</strong>： 像 Hash、List、Set 等结构在元素变化时会动态扩容或缩容，旧空间释放，新空间分配，容易产生碎片。</li><li><strong>内存对齐与分配算法的限制</strong>： Redis 底层使用 jemalloc 等内存分配器，为了对齐性能，可能申请比实际需要更大的内存空间，留下难以复用的小空洞。</li><li><strong>惰性删除和过期清理导致空间不连续释放</strong>： 一些 key 被延迟删除，导致释放内存的时间不集中，增加碎片化概率。</li></ol><hr><p><a href="https://javaguide.cn/database/redis/redis-memory-fragmentation.html#%E5%A6%82%E4%BD%95%E6%9F%A5%E7%9C%8B-redis-%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87%E7%9A%84%E4%BF%A1%E6%81%AF" target="_blank" rel="noopener noreferrer">如何查看 Redis 内存碎片的信息？</a></p><p><a href="https://javaguide.cn/database/redis/redis-memory-fragmentation.html#%E5%A6%82%E4%BD%95%E6%B8%85%E7%90%86-redis-%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87" target="_blank" rel="noopener noreferrer">如何清理 Redis 内存碎片？</a></p><hr><h1 id="事务" tabindex="-1"><a class="header-anchor" href="#事务"><span>事务</span></a></h1><p>严格来说，Redis 事务不能完全满足传统数据库的 <strong>ACID</strong> 四大特性，但各特性情况不同：</p><ol><li><strong>原子性（Atomicity）</strong><ul><li>Redis 的事务里所有命令在 <strong>EXEC</strong> 时按顺序执行，中途不会被其他命令打断，但<strong>单条命令执行失败不会回滚整个事务</strong>。</li><li>因此严格意义上不完全原子。</li></ul></li><li><strong>一致性（Consistency）</strong><ul><li>Redis 本身的数据结构保证命令执行后数据是有效状态，所以在事务执行完毕后，数据仍然是合法的。</li><li>可以认为在一定程度上保持一致性。</li></ul></li><li><strong>隔离性（Isolation）</strong><ul><li>Redis 单线程执行命令，事务里的命令执行时不会被其他客户端命令插入，但<strong>事务命令队列被放入后，其他客户端仍可以修改 watched key</strong>，所以隔离性有限。</li></ul></li><li><strong>持久性（Durability）</strong><ul><li>如果开启 AOF 或 RDB，执行后的数据才会持久化，但在事务执行过程中 Redis 崩溃，可能部分命令已执行、部分未执行。</li><li>因此持久性依赖持久化策略，不能保证像数据库一样严格。</li></ul></li></ol><p><strong>总结</strong>：Redis 事务保证顺序执行，但<strong>不支持回滚、隔离性和持久性都有限</strong>，严格 ACID 并不满足，更多是为了批量执行和保证顺序性。</p><hr><h2 id="原子性" tabindex="-1"><a class="header-anchor" href="#原子性"><span>原子性</span></a></h2><p><strong>单条命令</strong>：Redis 是单线程的，单条命令天然具备原子性。</p><p><strong>事务（MULTI/EXEC）</strong>：严格来说，Redis 的事务 <strong>不完全符合数据库事务的 ACID 原子性</strong>。</p><ul><li>它保证了事务中的命令会<strong>顺序、不可分割地执行</strong>（不会被其他命令打断）。</li><li>但它 <strong>不支持回滚</strong>：如果事务中某条命令失败，已经执行的命令不会撤销，所以不满足数据库意义上的“原子性”。</li></ul><p>因此，Redis 事务其实是不满足原子性的。</p><hr><p><strong>如何实现redis 原子性</strong></p><p>Redis 实现原子性主要依赖 <strong>单线程执行 + 事务命令队列机制</strong>：</p><ol><li><strong>单线程执行</strong><ul><li>Redis 使用单线程处理所有客户端请求，保证同一时刻只有一个命令在执行。</li><li>这样在事务执行时，其他客户端命令不会插入中间，保证命令顺序不被打断。</li></ul></li><li><strong>事务命令队列（MULTI/EXEC）</strong><ul><li>当客户端发起 <strong>MULTI</strong> 时，事务开始，所有命令不会立即执行，而是入队。</li><li><strong>EXEC</strong> 时一次性顺序执行队列中的所有命令，中途不会被其他客户端命令插入。</li><li>虽然单条命令执行失败<strong>不会回滚</strong>整个事务，但整个队列按顺序执行保证了原子性特征。</li></ul></li><li><strong>Lua 脚本</strong><ul><li>Redis 的 Lua 脚本在执行过程中是不可中断的，所以它可以满足数据库意义上的“原子性”，即脚本内的所有操作要么全部执行完成，要么在执行期间不会被其他命令打断，但它仍然不具备事务的回滚能力。</li></ul></li></ol><hr><h2 id="持久性" tabindex="-1"><a class="header-anchor" href="#持久性"><span>持久性</span></a></h2><p>Redis 支持持久化，而且支持 3 种持久化方式：</p><ul><li>快照（snapshotting，RDB）；</li><li>只追加文件（append-only file，AOF）；</li><li>RDB 和 AOF 的混合持久化（Redis 4.0 新增）。</li></ul><p>简单来说：</p><ul><li>如果开启了 <strong>AOF 持久化</strong>，Redis 会在执行事务中的每条命令时写入 AOF 文件；</li><li>如果依赖的是 <strong>RDB 快照</strong>，则要等到下一次快照发生时数据才会被持久化；</li><li>如果两种机制都未启用，那么事务执行的数据在 Redis 重启后会丢失。</li></ul><p>因此，<strong>Redis 的事务可以结合持久化机制实现“持久性”，但事务本身不等同于数据库那种强 ACID 保证。</strong></p><hr><h1 id="性能优化" tabindex="-1"><a class="header-anchor" href="#性能优化"><span>性能优化</span></a></h1><p><a href="https://javaguide.cn/database/redis/redis-questions-02.html#redis-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96-%E9%87%8D%E8%A6%81" target="_blank" rel="noopener noreferrer">Redis 性能优化（重要）</a></p><h1 id="穿透击穿雪崩阻塞" tabindex="-1"><a class="header-anchor" href="#穿透击穿雪崩阻塞"><span>穿透击穿雪崩阻塞</span></a></h1><h2 id="缓存穿透" tabindex="-1"><a class="header-anchor" href="#缓存穿透"><span>缓存穿透</span></a></h2><p>缓存穿透说简单点就是大量请求的 key 是不合理的，<strong>根本不存在于缓存中，也不存在于数据库中</strong>。这就导致这些请求直接到了数据库上，根本没有经过缓存这一层，对数据库造成了巨大的压力，可能直接就被这么多请求弄宕机了。</p><hr><p><strong>解决方法</strong></p><p>常见的解决方案有三种：</p><p><strong>第一，缓存空值。</strong> 当请求的 key 在数据库中查不到时，将一个空对象或特定标识（如 <code>null</code> 或 <code>&quot;&quot;</code>）写入缓存，并设置较短的过期时间。这样后续相同请求就不会再打到数据库。</p><p><strong>第二，使用布隆过滤器。</strong> 将所有合法 key 的集合预先存入布隆过滤器，每次请求前先判断 key 是否存在于布隆过滤器中。如果判断为不存在，直接拦截请求，避免访问缓存和数据库。</p><p><strong>第三，加强接口安全。</strong> 通过接口校验、用户权限控制、验证签名、加验证码等方式，限制恶意用户或机器人批量构造非法请求。</p><hr><h2 id="缓存击穿" tabindex="-1"><a class="header-anchor" href="#缓存击穿"><span>缓存击穿</span></a></h2><p>缓存击穿是指某个<strong>热点 key 在缓存中刚好失效</strong>的瞬间，有大量并发请求同时访问这个 key，由于缓存失效，请求全部穿透到数据库，造成瞬时高并发压力，可能引发数据库崩溃。</p><hr><p><strong>解决方法</strong></p><p><strong>第一，加互斥锁。</strong> 当发现某个 key 失效时，让第一个请求线程去加载数据库并重建缓存，其他线程等待或快速失败。常见做法是在查询时对 key 加分布式锁，避免重复加载。</p><p><strong>第二，设置合理的过期时间 + 提前异步刷新。</strong> 给热点 key 设置较长过期时间，同时使用定时任务或异步线程，在临近过期时主动刷新缓存，避免大面积失效。</p><p><strong>第三，永不过期 + 后台更新机制。</strong> 对一些真正高频访问的数据，可以考虑缓存永久有效，由后台异步服务定时更新缓存，完全避免过期瞬间失效。</p><hr><h2 id="缓存雪崩" tabindex="-1"><a class="header-anchor" href="#缓存雪崩"><span>缓存雪崩</span></a></h2><p><strong>存雪崩</strong>是指<strong>大量缓存数据在同一时间集中失效</strong>，导致大量请求同时访问数据库，数据库承压严重，可能宕机。这种问题一般发生在大量 key 过期时间相同，或者 Redis 故障时。</p><hr><p><strong>解决方法</strong></p><p><strong>针对 Redis 服务不可用的情况</strong>：</p><ol><li><strong>Redis 集群</strong>：采用 Redis 集群，避免单机出现问题整个缓存服务都没办法使用。Redis Cluster 和 Redis Sentinel 是两种最常用的 Redis 集群实现方案。</li><li><strong>多级缓存</strong>：设置多级缓存，例如本地缓存+Redis 缓存的二级缓存组合，当 Redis 缓存出现问题时，还可以从本地缓存中获取到部分数据。</li></ol><p><strong>针对大量缓存同时失效的情况</strong>：</p><ol><li><strong>设置随机失效时间</strong>（可选）：为缓存设置随机的失效时间，例如在固定过期时间的基础上加上一个随机值，这样可以避免大量缓存同时到期，从而减少缓存雪崩的风险。</li><li><strong>提前预热</strong>（推荐）：针对热点数据提前预热，将其存入缓存中并设置合理的过期时间，比如秒杀场景下的数据在秒杀结束之前不过期。</li><li><strong>持久缓存策略</strong>（看情况）：虽然一般不推荐设置缓存永不过期，但对于某些关键性和变化不频繁的数据，可以考虑这种策略。</li></ol><hr><h2 id="阻塞" tabindex="-1"><a class="header-anchor" href="#阻塞"><span>阻塞</span></a></h2><h3 id="为什么阻塞" tabindex="-1"><a class="header-anchor" href="#为什么阻塞"><span>为什么阻塞？</span></a></h3><p>尽管 Redis 是基于<strong>单线程模型</strong>，处理速度非常快，但仍会因为某些操作耗时过长而阻塞主线程。常见原因有：</p><ol><li><strong>大 key 操作</strong> 对包含大量元素的 key 执行全量命令（如 <code>LRANGE</code>、<code>HGETALL</code>、<code>SMEMBERS</code>）会导致长时间占用主线程。</li><li><strong>慢查询命令</strong> 一些命令本身计算复杂，如 <code>SORT</code>、<code>ZUNIONSTORE</code>、<code>SUNION</code>，对数据量大的 key 会严重拖慢响应。</li><li><strong>阻塞型命令</strong> 命令如 <code>BLPOP</code>、<code>BRPOP</code> 在 key 不存在时会阻塞客户端，客户端线程被挂起等待数据返回，但不会阻塞 Redis 本身。</li><li><strong>AOF 重写 / RDB 快照期间资源竞争</strong> 虽然是后台子进程执行，但若服务器 I/O 或 CPU 资源紧张，会影响主线程性能，引发间接阻塞。</li><li><strong>客户端读写缓冲区积压</strong> 如果客户端消费能力差，写缓冲区过大，Redis 主线程需要等待数据写完才能继续处理请求，导致延迟。</li><li><strong>主从复制阻塞</strong> 全量同步或从库处理慢会影响主库 <code>PSYNC</code>、<code>BGSAVE</code> 等操作，影响主线程响应。</li></ol><hr><h3 id="如何解决阻塞问题" tabindex="-1"><a class="header-anchor" href="#如何解决阻塞问题"><span>如何解决阻塞问题？</span></a></h3><p>应对 Redis 阻塞问题，通常从<strong>优化使用场景、命令选择、资源管理</strong>几方面入手：</p><ol><li><strong>避免操作大 key</strong><ul><li>拆分大 key 为多个小 key</li><li>禁用高风险命令，限制 key 大小</li><li>使用 <code>SCAN</code> 替代全量读取</li></ul></li><li><strong>优化慢查询命令</strong><ul><li>尽量避免使用全量计算类命令</li><li>利用分页处理、预计算等手段</li></ul></li><li><strong>合理使用阻塞命令</strong><ul><li>设置合理超时时间</li><li>对关键场景使用消息队列替代阻塞命令</li></ul></li><li><strong>优化持久化策略</strong><ul><li>在流量低峰期执行 AOF 重写或 RDB 快照</li><li>开启 <code>lazy-free</code> 异步删除大 key</li></ul></li><li><strong>增强监控与告警</strong><ul><li>使用 <code>slowlog</code>、<code>info</code>、<code>latency</code> 命令跟踪瓶颈</li><li>对慢操作设置告警，提前定位问题</li></ul></li><li><strong>隔离关键业务或分片部署</strong><ul><li>高并发或高吞吐场景下进行 Redis 分区分库</li><li>核心数据与非核心数据分离部署，减少干扰</li></ul></li></ol><hr><h1 id="集群" tabindex="-1"><a class="header-anchor" href="#集群"><span>集群</span></a></h1><p><a href="https://xiaolincoding.com/interview/redis.html#%E9%9B%86%E7%BE%A4" target="_blank" rel="noopener noreferrer">Redis面试题 集群</a></p><h2 id="redis-cluster-集群" tabindex="-1"><a class="header-anchor" href="#redis-cluster-集群"><span><strong>Redis Cluster</strong>(集群)</span></a></h2><ol><li>为什么需要 Redis Cluster？解决了什么问题？有什么优势？</li><li>Redis Cluster 是如何分片的？</li><li>为什么 Redis Cluster 的哈希槽是 16384 个？</li><li>如何确定给定 key 的应该分布到哪个哈希槽中？</li><li>Redis Cluster 支持重新分配哈希槽吗？</li><li>Redis Cluster 扩容缩容期间可以提供服务吗？</li><li>Redis Cluster 中的节点是怎么进行通信的？</li></ol><hr><p>Redis 集群（Redis Cluster）是 Redis 提供的 <strong>分布式解决方案</strong>，它通过 <strong>分片（Sharding）+ 多副本</strong> 来实现数据的水平扩展和高可用。</p><ol><li><strong>数据分片</strong>： 集群将整个数据空间分为 <strong>16384 个槽（slot）</strong>，每个节点负责一部分槽位的数据。客户端请求时，Redis 会根据 <strong>key 的哈希值</strong> 来定位数据所在的槽，再路由到对应节点。</li><li><strong>高可用</strong>： 每个主节点都可以配置从节点，主节点宕机后，从节点会自动提升为主节点，保证服务可用。</li><li><strong>特点</strong>： <ul><li><strong>去中心化</strong>：没有中心节点，所有节点平等，互相保存路由信息。</li><li><strong>自动容错</strong>：支持主从切换。</li><li><strong>扩展性强</strong>：可线性扩展至上百个节点。</li></ul></li><li><strong>不足</strong>： <ul><li>不支持多 key 跨槽事务（除非 key 使用相同的哈希标签）。</li><li>部署和运维相对单机复杂。</li></ul></li></ol><hr><hr><h2 id="redis-sentinel-哨兵" tabindex="-1"><a class="header-anchor" href="#redis-sentinel-哨兵"><span><strong>Redis Sentinel</strong>(哨兵)</span></a></h2><ol><li>什么是 Sentinel？ 有什么用？</li><li>Sentinel 如何检测节点是否下线？主观下线与客观下线的区别？</li><li>Sentinel 是如何实现故障转移的？</li><li>为什么建议部署多个 sentinel 节点（哨兵集群）？</li><li>Sentinel 如何选择出新的 master（选举机制）？</li><li>如何从 Sentinel 集群中选择出 Leader？</li><li>Sentinel 可以防止脑裂吗？</li></ol><hr><h3 id="原理" tabindex="-1"><a class="header-anchor" href="#原理"><span>原理</span></a></h3><p>Redis 在 2.8 版本以后提供的<strong>哨兵（Sentinel）机制</strong>，它的作用是实现<strong>主从节点故障转移</strong>。它会监测主节点是否存活，如果发现主节点挂了，它就会选举一个从节点切换为主节点，并且把新主节点的相关信息通知给从节点和客户端。</p><p>哨兵其实是一个运行在特殊模式下的 Redis 进程，所以它也是一个节点。哨兵节点主要负责三件事情：监控、选主、通知。</p><hr><h3 id="选主节点的算法" tabindex="-1"><a class="header-anchor" href="#选主节点的算法"><span>选主节点的算法</span></a></h3><hr><h2 id="主从同步" tabindex="-1"><a class="header-anchor" href="#主从同步"><span><strong>主从同步</strong></span></a></h2><hr><p>Redis 的主从同步分为 <strong>完全同步（全量同步）</strong> 和 <strong>增量同步</strong>，根据主从节点的状态来选择。</p><h3 id="完全同步" tabindex="-1"><a class="header-anchor" href="#完全同步"><span>完全同步</span></a></h3><p>完全同步<strong>发生在以下几种情况</strong>：</p><ul><li><p>初次同步：当一个从服务器（slave）首次连接到主服务器（master）时，会进行一次完全同步。</p></li><li><p>从服务器数据丢失：如果从服务器数据由于某种原因（如断电）丢失，它会请求进行完全同步。</p></li><li><p>主服务器数据发生变化：如果从服务器长时间未与主服务器同步，导致数据差异太大，也可能触发完全同步。</p></li></ul><hr><p><strong>实现过程</strong>：</p><ul><li>从服务器发送SYNC命令：从服务器向主服务器发送SYNC命令，请求开始同步。</li><li>主服务器生成RDB快照：接收到SYNC命令后，主服务器会保存当前数据集的状态到一个临时文件，这个过程称为RDB（Redis Database）快照。</li><li>传输RDB文件：主服务器将生成的RDB文件发送给从服务器。</li><li>从服务器接收并应用RDB文件：从服务器接收RDB文件后，会清空当前的数据集，并载入RDB文件中的数据。</li><li>主服务器记录写命令：在RDB文件生成和传输期间，主服务器会记录所有接收到的写命令到replication backlog buffer。</li><li>传输写命令：一旦RDB文件传输完成，主服务器会将replication backlog buffer中的命令发送给从服务器，从服务器会执行这些命令，以保证数据的一致性。</li></ul><hr><h3 id="增量同步" tabindex="-1"><a class="header-anchor" href="#增量同步"><span>增量同步</span></a></h3><p>增量同步允许从服务器从断点处继续同步，而不是每次都进行完全同步。它基于PSYNC命令，使用了运行ID（run ID）和复制偏移量（offset）的概念。</p><p><strong>主要步骤</strong>：</p><ul><li>从服务器在恢复网络后，会发送 psync 命令给主服务器，此时的 psync 命令里的 offset 参数不是 -1；</li><li>主服务器收到该命令后，然后用 CONTINUE 响应命令告诉从服务器接下来采用增量复制的方式同步数据；</li><li>然后主服务将主从服务器断线期间，所执行的写命令发送给从服务器，然后从服务器执行这些命令。</li></ul><hr><h1 id="其他-4" tabindex="-1"><a class="header-anchor" href="#其他-4"><span>其他</span></a></h1><h2 id="_3种常用的缓存读写策略详解" tabindex="-1"><a class="header-anchor" href="#_3种常用的缓存读写策略详解"><span><a href="https://javaguide.cn/database/redis/3-commonly-used-cache-read-and-write-strategies.html" target="_blank" rel="noopener noreferrer">3种常用的缓存读写策略详解</a></span></a></h2><h2 id="如何保证缓存和数据库数据的一致性" tabindex="-1"><a class="header-anchor" href="#如何保证缓存和数据库数据的一致性"><span><a href="https://javaguide.cn/database/redis/redis-questions-02.html#%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E7%BC%93%E5%AD%98%E5%92%8C%E6%95%B0%E6%8D%AE%E5%BA%93%E6%95%B0%E6%8D%AE%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7" target="_blank" rel="noopener noreferrer">如何保证缓存和数据库数据的一致性？</a></span></a></h2><p>缓存与数据库双写时存在数据不一致的风险，尤其在更新、删除操作中。常见的一致性方案有以下几种：</p><p><strong>第一，先删除缓存，再更新数据库。</strong> 这是较常用的方案，更新数据前先删掉缓存，等下次读请求时再从数据库加载最新数据写入缓存。但这存在并发问题：<strong>如果删除缓存后还没来得及更新数据库，读取请求进来了，就会缓存旧数据。</strong></p><p><strong>第二，先更新数据库，再删除缓存。</strong> 这是更推荐的做法，更新数据库成功后再删除缓存，避免缓存中存在过期脏数据。为了防止并发问题，可以结合<strong>延迟双删</strong>策略：第一次删除在更新后立即执行，第二次删除在短暂延迟后异步执行一次，确保彻底清理脏缓存。</p><p><strong>第三，使用消息队列异步更新缓存。</strong> 将数据库更新操作投递到消息队列，由消费端统一负责删除或更新缓存，提高系统解耦性和可靠性。</p><p><strong>第四，引入 Canal 等中间件监听数据库变更。</strong> 通过监听数据库 binlog，实时感知变更并同步更新缓存，适合数据一致性要求高的场景。</p><hr><h2 id="网络模型-vs-线程模型" tabindex="-1"><a class="header-anchor" href="#网络模型-vs-线程模型"><span>网络模型 vs 线程模型</span></a></h2><p><strong>网络模型</strong> 通常指 <strong>I/O 模型</strong>，也就是操作系统层面上，应用程序与内核交互、处理网络读写的方式。 常见的有：</p><ul><li>阻塞 I/O（Blocking IO）</li><li>非阻塞 I/O（Non-blocking IO）</li><li>I/O 多路复用（select、poll、epoll）</li><li>信号驱动 I/O</li><li>异步 I/O</li></ul><p>Redis 的网络模型就是 <strong>I/O 多路复用模型</strong>。</p><hr><p><strong>线程模型</strong> 指的是应用程序在逻辑上如何使用线程来处理任务：</p><ul><li>一个请求一个线程（传统 BIO）</li><li>多请求复用少量线程（NIO、Reactor 模型）</li><li>单线程事件循环（Redis）</li></ul><p>Redis 的线程模型是 <strong>单线程 + 事件驱动</strong>。</p><hr><h2 id="redis支持并发操作吗" tabindex="-1"><a class="header-anchor" href="#redis支持并发操作吗"><span>Redis支持并发操作吗</span></a></h2><p>Redis 本身采用单线程处理命令请求，依赖 I/O 多路复用机制来同时处理大量客户端连接，所以在同一时刻 Redis 只会执行一个命令，从而天然保证了每个操作的<strong>原子性</strong>，不会出现多线程并发下的数据竞争问题。</p><p>但这并不意味着 Redis 不能支持并发操作。Redis 可以同时接收大量客户端请求，并通过事件循环机制按顺序快速处理，所以整体上依然具备<strong>高并发处理能力</strong>。</p><p>如果业务需要更强的并行能力，可以通过 <strong>多实例 + 分片集群</strong> 来提升并发处理能力。</p><hr><h2 id="如何保证-redis-和-mysql-数据缓存一致" tabindex="-1"><a class="header-anchor" href="#如何保证-redis-和-mysql-数据缓存一致"><span>如何保证 redis 和 mysql 数据缓存一致</span></a></h2><p>保证 Redis 和 MySQL 数据一致性，需要结合具体业务场景，常用策略有三类：</p><ol><li><strong>缓存穿透与更新顺序控制</strong><ul><li><strong>先更新数据库，再删除缓存</strong>：修改操作先落库，确保数据持久化成功后，再删除缓存中的旧数据。这样避免了删除缓存失败导致的脏数据。</li><li><strong>先更新缓存，再更新数据库</strong>：存在风险，如果更新缓存成功但数据库写入失败，会导致数据不一致，一般不推荐。</li></ul></li><li><strong>缓存失效策略</strong><ul><li>使用 <strong>短期过期时间</strong> 或 <strong>定期刷新缓存</strong>，降低缓存与数据库的数据差异窗口。</li><li>可结合 <strong>延时双删策略</strong>：删除缓存后，等待短时间再删除一次，防止并发写入导致缓存回写脏数据。</li></ul></li><li><strong>消息队列同步</strong><ul><li>修改数据库时，通过消息队列通知其他系统或服务更新缓存，实现 <strong>异步最终一致性</strong>。</li><li>适用于高并发和复杂分布式场景。</li></ul></li></ol><p><strong>总结</strong>： 核心是保证 <strong>写数据库→删缓存</strong> 的操作顺序、合理设置过期策略，以及在必要时通过消息队列实现异步同步，以降低缓存与数据库的不一致风险。</p><hr><h2 id="如何设计秒杀场景处理高并发以及超卖现象" tabindex="-1"><a class="header-anchor" href="#如何设计秒杀场景处理高并发以及超卖现象"><span>如何设计秒杀场景处理高并发以及超卖现象</span></a></h2><p><strong>秒杀场景的高并发和超卖问题本质</strong>：大量用户在短时间内同时访问库存资源，如果直接操作数据库，会导致性能瓶颈；同时，如果并发控制不当，还可能出现超卖（库存被超量扣减）。</p><p><strong>处理思路</strong>：</p><ol><li><strong>前端限流</strong><ul><li>使用 Nginx 限流、令牌桶或漏桶算法，限制单位时间内请求数量，减轻后端压力。</li></ul></li><li><strong>请求排队/异步处理</strong><ul><li>将请求先写入消息队列（如 Kafka、RabbitMQ、Redis Stream），由后台按序消费处理，保证库存扣减顺序。</li></ul></li><li><strong>缓存预减库存</strong><ul><li>将库存信息缓存在 Redis 中，利用原子操作（如 <code>DECR</code>）先在缓存中扣减库存。</li><li>当库存扣减成功，再异步写数据库；失败则直接返回秒杀结束。</li></ul></li><li><strong>乐观锁 / 悲观锁控制</strong><ul><li><strong>乐观锁</strong>：在数据库更新库存时使用版本号或 CAS（如 <code>UPDATE stock SET count = count - 1 WHERE count &gt; 0 AND version = ?</code>），防止超卖。</li><li><strong>悲观锁</strong>：通过行锁锁定库存行，但在高并发场景下容易造成性能瓶颈，不推荐直接使用。</li></ul></li><li><strong>库存标记和售罄标志</strong><ul><li>当库存为 0 时，在 Redis 设置售罄标记，后续请求直接返回结束，减少无效请求。</li></ul></li><li><strong>分布式锁（可选）</strong><ul><li>在多实例情况下，可以用 Redis 分布式锁或 Redisson 来保证同一库存只被一个线程扣减，避免超卖。</li></ul></li><li><strong>数据库优化</strong><ul><li>对库存表添加索引，尽量减少写锁冲突。</li><li>数据库分表、分库提高并发处理能力。</li></ul></li></ol><p><strong>总结</strong>： 秒杀高并发处理通常是**“先缓存+队列异步+原子操作”**的组合策略，通过前端限流、Redis 预扣库存、消息队列异步写库以及乐观锁保证库存一致性，从而解决超卖问题。</p><hr><h2 id="布隆过滤器" tabindex="-1"><a class="header-anchor" href="#布隆过滤器"><span>布隆过滤器</span></a></h2><p><strong>布隆过滤器（Bloom Filter）是一种空间效率高、允许一定误判的概率型数据结构</strong>，主要用于判断某个元素是否存在于一个集合中。</p><p><strong>原理：</strong></p><ol><li><strong>数据结构</strong>：布隆过滤器通常由一个长度为 <code>m</code> 的位数组和 <code>k</code> 个独立的哈希函数组成。</li><li><strong>添加元素</strong>：把要存储的元素分别用 <code>k</code> 个哈希函数计算出 <code>k</code> 个索引，然后将位数组对应位置置为 1。</li><li><strong>查询元素</strong>：判断一个元素是否存在时，同样用 <code>k</code> 个哈希函数计算索引，如果对应的位都为 1，则认为元素可能存在；如果有任意一位是 0，则一定不存在。</li></ol><p><strong>特点</strong>：</p><ul><li><strong>优点</strong>：极大节省存储空间，查询非常快，适合海量数据去重或存在性判断。</li><li><strong>缺点</strong>：存在<strong>误判（false positive）</strong>，即可能判断元素存在但实际上不存在；不能删除元素（标准布隆过滤器）。</li></ul><p><strong>应用场景</strong>：</p><ul><li>缓存穿透防护（判断请求的数据是否存在，避免查询数据库）。</li><li>去重（如网站去重 URL）。</li><li>数据库或分布式系统快速判定元素是否存在。</li></ul><hr><h2 id="大key-热key" tabindex="-1"><a class="header-anchor" href="#大key-热key"><span>大Key &amp; 热Key</span></a></h2><h3 id="什么是大key问题" tabindex="-1"><a class="header-anchor" href="#什么是大key问题"><span>什么是大Key问题</span></a></h3><p>Redis大key问题指的是某个key对应的value值所占的内存空间比较大，导致Redis的性能下降、内存不足、数据不均衡以及主从同步延迟等问题。</p><p>大Key没有固定的判别标准，通常认为字符串类型的key对应的value值占用空间大于1M，或者集合类型的k元素数量超过1万个，就算是大key。</p><hr><h3 id="缺点" tabindex="-1"><a class="header-anchor" href="#缺点"><span>缺点</span></a></h3><p>**内存占用过高。**大Key占用过多的内存空间，可能导致可用内存不足，从而触发内存淘汰策略。在极端情况下，可能导致内存耗尽，Redis实例崩溃，影响系统的稳定性。</p><p>**性能下降。**大Key会占用大量内存空间，导致内存碎片增加，进而影响Redis的性能。对于大Key的操作，如读取、写入、删除等，都会消耗更多的CPU时间和内存资源，进一步降低系统性能。</p><p>**阻塞其他操作。**某些对大Key的操作可能会导致Redis实例阻塞。例如，使用DEL命令删除一个大Key时，可能会导致Redis实例在一段时间内无法响应其他客户端请求，从而影响系统的响应时间和吞吐量。</p><p>**网络拥塞。**每次获取大key产生的网络流量较大，可能造成机器或局域网的带宽被打满，同时波及其他服务。例如：一个大key占用空间是1MB，每秒访问1000次，就有1000MB的流量。</p><p>**主从同步延迟。**当Redis实例配置了主从同步时，大Key可能导致主从同步延迟。由于大Key占用较多内存，同步过程中需要传输大量数据，这会导致主从之间的网络传输延迟增加，进而影响数据一致性。</p><p>**数据倾斜。**在Redis集群模式中，某个数据分片的内存使用率远超其他数据分片，无法使数据分片的内存资源达到均衡。另外也可能造成Redis内存达到maxmemory参数定义的上限导致重要的key被逐出，甚至引发内存溢出。</p><hr><h3 id="如何解决" tabindex="-1"><a class="header-anchor" href="#如何解决"><span>如何解决</span></a></h3><p>对大Key进行拆分。例如将含有数万成员的一个HASH Key拆分为多个HASH Key，并确保每个Key的成员数量在合理范围。在Redis集群架构中，拆分大Key能对数据分片间的内存平衡起到显著作用。</p><p>对大Key进行清理。将不适用Redis能力的数据存至其它存储，并在Redis中删除此类数据。注意，要使用异步删除。</p><p>监控Redis的内存水位。可以通过监控系统设置合理的Redis内存报警阈值进行提醒，例如Redis内存使用率超过70%、Redis的内存在1小时内增长率超过20%等。</p><p>对过期数据进行定期清。堆积大量过期数据会造成大Key的产生，例如在HASH数据类型中以增量的形式不断写入大量数据而忽略了数据的时效性。可以通过定时任务的方式对失效数据进行清理。</p><hr><h3 id="什么是热key" tabindex="-1"><a class="header-anchor" href="#什么是热key"><span>什么是热Key</span></a></h3><p>通常以其接收到的Key被请求频率来判定，例如：</p><p><strong>QPS集中在特定的Key</strong>：Redis实例的总QPS（每秒查询率）为10,000，而其中一个Key的每秒访问量达到了7,000。</p><p><strong>带宽使用率集中在特定的Key</strong>：对一个拥有上千个成员且总大小为1 MB的HASH Key每秒发送大量的HGETALL操作请求。</p><p><strong>CPU使用时间占比集中在特定的Key</strong>：对一个拥有数万个成员的Key（ZSET类型）每秒发送大量的ZRANGE操作请求。</p><hr><h3 id="如何解决-1" tabindex="-1"><a class="header-anchor" href="#如何解决-1"><span>如何解决</span></a></h3><p>在Redis集群架构中对热Key进行复制。在Redis集群架构中，由于热Key的迁移粒度问题，无法将请求分散至其他数据分片，导致单个数据分片的压力无法下降。此时，可以将对应热Key进行复制并迁移至其他数据分片，例如将热Key foo复制出3个内容完全一样的Key并名为foo2、foo3、foo4，将这三个Key迁移到其他数据分片来解决单个数据分片的热Key压力。</p><p>使用读写分离架构。如果热Key的产生来自于读请求，您可以将实例改造成读写分离架构来降低每个数据分片的读请求压力，甚至可以不断地增加从节点。但是读写分离架构在增加业务代码复杂度的同时，也会增加Redis集群架构复杂度。不仅要为多个从节点提供转发层（如Proxy，LVS等）来实现负载均衡，还要考虑从节点数量显著增加后带来故障率增加的问题。Redis集群架构变更会为监控、运维、故障处理带来了更大的挑战。</p><hr></div><!----><!----><!----></div><footer class="vp-page-meta"><div class="vp-meta-item edit-link"><a class="auto-link external-link vp-meta-label" href="https://github.com/Nu11Cat/Nu11Cat.github.io/edit/main/docs/1.Note/3.Database&amp;MQ/Redis.md" aria-label="Edit this page" rel="noopener noreferrer" target="_blank"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon" name="edit"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->Edit this page<!----></a></div><div class="vp-meta-item git-info"><div class="update-time"><span class="vp-meta-label">Last Updated:</span><time class="vp-meta-info" datetime="2025-08-28T08:51:18.000Z" data-allow-mismatch>8/28/25, 8:51 AM</time></div><div class="contributors"><span class="vp-meta-label">Contributors: </span><!--[--><!--[--><span class="vp-meta-info" title="email: 2111867383@qq.com">Nu11Cat</span><!--]--><!--]--></div></div></footer><nav class="vp-page-nav"><a class="route-link auto-link prev" href="/1.Note/3.Database_MQ/MySQL.html" aria-label="MySQL"><div class="hint"><span class="arrow start"></span>Prev</div><div class="link"><!---->MySQL</div></a><a class="route-link auto-link next" href="/1.Note/3.Database_MQ/Elasticsearch.html" aria-label="Elasticsearch"><div class="hint">Next<span class="arrow end"></span></div><div class="link">Elasticsearch<!----></div></a></nav><!----><!----><!--]--></main><!--]--><!----></div><!--]--><!--]--><!--[--><!----><!--[--><!--]--><!--]--><!--]--></div>
    <script type="module" src="/assets/app-DjrNW2Lh.js" defer></script>
  </body>
</html>
