---
title : 2.故障排查实战
---

------

**问：线上系统突然响应变慢，如何排查性能瓶颈？**

答：排查性能瓶颈应采取系统化的方法：

- **确认问题现象**：从监控系统中查看请求响应时间是否异常，是否集中在某个接口或全局。
- **分析系统负载**：通过 top、vmstat、iostat 等命令检查 CPU、内存、磁盘 IO、网络是否存在瓶颈。
- **线程状态检查**：使用 jstack 查看是否存在大量线程处于 BLOCKED、WAITING 状态，排查是否有死锁或锁竞争。
- **GC 行为分析**：通过 jstat 或 GC 日志查看是否存在频繁 Full GC 或 GC 时间过长，是否为内存回收问题。
- **数据库压力排查**：查看慢 SQL 日志、数据库连接数、执行时间，是否存在连接泄漏、表锁、索引缺失等问题。
- **第三方依赖排查**：如调用外部服务、消息队列、缓存是否出现延迟、失败重试等异常。
- **逐级定位代码热点**：可使用 Arthas trace/watch/monitor 观察函数调用耗时，定位慢点。

------

**问：如何处理线程死锁问题？**

答：

- **识别死锁**：使用 jstack 工具导出线程栈，搜索是否有 `Found one Java-level deadlock` 提示。
- **分析死锁原因**：通常是两个线程互相等待对方持有的锁，形成循环等待。
- **常见场景**：多个 synchronized 嵌套、多个 ReentrantLock 顺序不一致、多个线程间共享资源交错加锁。
- **解决方案**：
  - 统一加锁顺序，避免循环等待；
  - 使用 `tryLock()` 避免永久阻塞；
  - 引入超时机制避免无限等待；
  - 审查业务逻辑中锁的粒度，降低锁冲突。

------

**问：如何排查频繁 Full GC 的原因？**

答：

- **检查堆内存设置**：是否堆过小（如 -Xmx 设置太低），导致频繁 Full GC。
- **分析对象生命周期**：是否存在大量对象被频繁创建且未被及时释放，尤其是大对象进入老年代。
- **监控 GC 日志**：使用 -Xlog:gc* 或 GCViewer 工具分析 GC 次数、耗时、晋升频率。
- **查找内存泄漏**：使用 MAT、VisualVM 等工具分析堆 dump，识别无法被回收的大对象或强引用链。
- **排查缓存滥用**：是否使用了全局静态缓存但未设置容量限制或 TTL。

------

**问：如何定位接口响应慢的问题？**

答：

- **从日志入手**：查看 access log、trace log 是否记录请求时间、参数、耗时。
- **使用链路追踪系统**：如 SkyWalking、Zipkin、Jaeger 追踪接口调用链，定位慢在哪一层。
- **排查依赖资源**：如数据库、Redis、HTTP 第三方服务等调用耗时。
- **逐层下钻**：
  - 控制层是否有数据转换、权限处理耗时；
  - 服务层是否有业务逻辑复杂度高；
  - DAO 层是否有 N+1 查询、未命中索引、锁等待；
- **代码级别分析**：结合 Arthas `trace` 或 `profiler` 工具，查看具体哪个方法调用慢。

------

**问：服务频繁抛出 `OutOfMemoryError`，如何排查？**

答：

- **明确 OOM 类型**：是 Java heap space、Metaspace、Direct buffer 还是 GC overhead limit exceeded。
- **查看 JVM 参数**：确认堆/非堆大小是否设置合理，如 Metaspace 太小易导致类加载溢出。
- **收集堆转储**：设置 -XX:+HeapDumpOnOutOfMemoryError 并分析 .hprof 文件，查看哪些类实例占用大量内存。
- **排查泄漏来源**：
  - ThreadLocal 未清理；
  - 静态集合无限增长；
  - 缓存未设置上限；
  - 第三方连接池资源未释放。
- **内存调优**：如优化缓存策略、缩短生命周期、减少对象创建。

------

**问：如何排查接口高并发下的请求超时或失败问题？**

答：

- **先看限流熔断**：是否触发了 Hystrix、Sentinel、Resilience4j 等降级策略。
- **排查线程池耗尽**：服务端是否线程池队列满，触发拒绝策略。
- **排查数据库连接耗尽**：连接池是否配置过小，连接泄露导致新请求无连接可用。
- **查看网络栈指标**：是否存在网络丢包、RTT 增高，导致 Socket 超时。
- **查看服务端 GC 行为**：是否因 Full GC 暂停导致请求超时。
- **综合压力测试验证瓶颈**：使用 JMeter、wrk 等模拟高并发重现问题。

------

**问：系统频繁重启，如何定位问题原因？**

答：

- **查看日志**：排查是否有 `OutOfMemoryError`、`Fatal Error` 或 Spring 容器初始化失败等致命错误。
- **排查容器/平台**：如 Kubernetes 是否因健康检查失败触发自动重启。
- **系统资源检查**：如进程占用 CPU 或内存过高被操作系统 kill（dmesg 查看 OOM Killer）。
- **查看配置中心/依赖服务**：初始化依赖服务不可用导致启动失败。

------

**问：日志排查时有哪些常见误区？**

答：

- **无结构化日志**：不使用统一格式记录请求 ID、用户信息，导致无法串联调用链。
- **日志级别不合理**：调试信息用 info，错误信息未用 error，导致日志信噪比低。
- **日志输出不完整**：异常堆栈只记录 message，未输出 stack trace。
- **忽略日志量与性能的权衡**：频繁记录大日志会影响系统性能甚至触发磁盘写满。

------

**问：如何构建可观测性强的系统以便故障快速定位？**

答：

- **日志完善**：统一日志格式，引入 traceId，配合链路追踪。
- **指标监控**：使用 Prometheus + Grafana，暴露 JVM、线程池、GC、业务指标。
- **链路追踪**：集成 SkyWalking、Zipkin 实现调用链追踪。
- **告警系统**：构建实时告警系统，基于异常率、RT、QPS、系统资源设定告警规则。
- **灰度与回滚机制**：避免大规模影响，快速定位问题版本。
- **自动诊断脚本**：如一键收集 jstack、GC 日志、容器日志等信息。

