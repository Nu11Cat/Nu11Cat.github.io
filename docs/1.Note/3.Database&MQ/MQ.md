---
title : MQ
order : 6
---

# 消息队列

消息队列是一种异步的进程间通信方式，主要用于解决分布式系统中的组件通信问题。它的核心模型是 **‘生产者/消费者’模型**：生产者发送消息到队列，消费者从队列中获取消息进行处理。双方不需要同时在线，也不需要知道彼此的存在。

## 作用

1. **系统解耦**：这是它最重要的作用。假设系统A需要调用系统B的接口。如果不使用消息队列，系统A和系统B是**强耦合**的，如果系统B宕机或接口变更，系统A会立刻受到影响。引入了消息队列后，系统A只需要把消息发送出去就算完成任务，完全不需要关心谁来处理、何时处理。系统B也只需要从队列里取消息，而不需要关心消息的来源。这样，两个系统就通过一个中间件**解耦**了，彼此的依赖性和影响降到了最低。
2. **异步处理**：对于一些非核心的、耗时的操作（比如下单成功后发短信、发优惠券），主流程不需要等待它们完成，只需要发一个消息到队列就可以直接返回，极大地缩短了响应时间，提升了用户体验。
3. **削峰**：在流量高峰时期（比如秒杀），大量的请求瞬间涌入，后端服务可能无法承受。消息队列可以作为一个**缓冲区**，将这些请求平稳地接收下来，后端服务可以按照自己能处理的速度慢慢消费，避免了系统被突发流量冲垮。

---

除此之外，还有：

**1. 实现最终一致性（分布式事务）**

这是消息队列在微服务架构中一个核心且经典的应用。它通过**事务消息**或**本地事务表**等模式，来解决分布式系统下的数据一致性问题。

- **场景**：用户下单支付成功后，需要更新订单状态、扣减库存、增加积分。这三个操作分属不同服务，必须保证同时成功或失败。
- **如何做**：订单服务在本地数据库事务中，更新订单状态并**向消息队列发送一条事务消息**。消息队列保证这条消息最终一定能被投递。库存和积分服务消费这条消息，执行各自操作。通过**重试机制**，确保这些操作最终都会成功，从而实现所有系统数据的**最终一致性**。**RocketMQ** 提供了完整的事务消息方案。

**2. 顺序保证**

在某些业务场景下，消息必须严格按照产生的顺序被处理。

- **场景**：一个账户的“创建账户” -> “存入100元” -> “取出50元” 这三个操作必须按顺序执行，乱序会导致账户余额错误。
- **如何做**：在 **Kafka** 或 **RocketMQ** 中，通过将需要保证顺序的消息发送到同一个 **Topic 的同一个 Partition** 中。因为一个分区只能被一个消费者顺序消费，从而天然保证了消息的顺序性。

**3.数据流处理（流平台）**

这是将消息队列能力发挥到极致的场景。此时它不再仅仅是“消息中间件”，而是一个**实时的数据流平台**，是大数据领域的基石。

- **场景**：实时用户行为分析、实时监控告警、实时推荐系统。
- **如何做**：各种应用（如前端、后端服务）作为生产者，将日志、点击事件、监控指标等数据以流的形式持续写入 **Kafka**。下游的流处理框架（如 **Flink、Spark Streaming**）实时消费这些数据流，进行清洗、聚合、计算。结果可用于实时大屏或驱动业务逻辑。Kafka 的高吞吐和持久化特性使其成为**事实上的流数据标准源**。

**4. 延时/定时调度**

消息队列可以作为一个分布式的、高可用的定时器。

- **场景**：订单下单后30分钟未支付自动关闭；预约会议开始前15分钟发送提醒。
- **如何做**：**RocketMQ** 原生支持延迟消息，可在发送时指定延迟级别。**RabbitMQ** 可通过 `TTL`（消息存活时间）和 `死信队列`机制来实现。消息会在队列中等待指定时间后才被投递给消费者。

**5. 系统重构与数据同步**

在系统重构或数据迁移期间，消息队列是保证业务平滑过渡和数据一致性的利器。

- **场景**：将单体数据库拆分为多个微服务数据库，需要实时同步用户数据。
- **如何做**：旧系统在修改数据时，同时向消息队列发送一条数据变更消息。新系统订阅这些消息，从而在自己的数据库中维护一份相同的用户数据。这种方式对原有系统侵入性小，实现了数据的实时同步。

---

## 可能带来哪些问题

**系统可用性降低：** 系统可用性在某种程度上降低，为什么这样说呢？在加入 MQ 之前，你不用考虑消息丢失或者说 MQ 挂掉等等的情况，但是，引入 MQ 之后你就需要去考虑了！

**系统复杂性提高：** 加入 MQ 之后，你需要保证消息没有被重复消费、处理消息丢失的情况、保证消息传递的顺序性等等问题！

**一致性问题：** 我上面讲了消息队列可以实现异步，消息队列带来的异步确实可以提高系统响应速度。但是，万一消息的真正消费者并没有正确消费消息怎么办？这样就会导致数据不一致的情况了

---

## JMS 和 AMQP

- **JMS**：是一个 **Java 平台的 API 规范/标准**，它定义了如何编写Java代码来和消息中间件进行交互。它关心的是**接口**。
- **AMQP**：是一个**跨语言的**、**线级的** **网络协议**。它定义了数据在网络上的传输格式。它关心的是**通信**。

---

JMS 是 Java EE 的一部分，它只是一套接口，本身并不实现消息的收发。它的主要目的是，让 Java 开发者能够用一套统一的API来操作不同的消息中间件，从而实现**解耦**。

**JMS 两种消息模型**：

- **点对点模型**：消息发送到**队列**。一个消息只能被**一个消费者**消费。
- **发布/订阅模型**：消息发送到**主题**。一个消息会被**所有订阅了该主题的消费者**消费。

---

它的核心是更灵活的**路由机制**：

- **生产者**将消息发送到 **Exchange**（交换机），并指定一个 **Routing Key**。
- **Exchange** 根据自身的**类型**和与 **Queue** 的 **Binding** 规则，将消息路由到一个或多个队列中。
- **消费者**从 **Queue** 中获取消息。

---

**AMQP提供了五种消息模型**：①direct exchange；②fanout exchange；③topic change；④headers exchange；⑤system exchange。本质来讲，后四种和 JMS 的 pub/sub 模型没有太大差别，仅是在路由机制上做了更详细的划分；

---

**二者区别:**

AMQP 为消息定义了线路层（wire-level protocol）的协议，而 JMS 所定义的是 API 规范。在 Java 体系中，多个 client 均可以通过 JMS 进行交互，不需要应用修改代码，但是其对跨平台的支持较差。而 AMQP 天然具有跨平台、跨语言特性。

JMS 支持 `TextMessage`、`MapMessage` 等复杂的消息类型；而 AMQP 仅支持 `byte[]` 消息类型（复杂的类型可序列化后发送）。

由于 Exchange 提供的路由算法，AMQP 可以提供多样化的路由方式来传递消息到消息队列，而 JMS 仅支持 队列 和 主题/订阅 方式两种。

---

## RPC vs 消息队列

- **从用途来看**：RPC 主要用来解决两个服务的远程通信问题，不需要了解底层网络的通信机制。通过 RPC 可以帮助我们调用远程计算机上某个服务的方法，这个过程就像调用本地方法一样简单。消息队列主要用来降低系统耦合性、实现任务异步、有效地进行流量削峰。
- **从通信方式来看**：RPC 是双向直接网络通讯，消息队列是单向引入中间载体的网络通讯。
- **从架构上来看**：消息队列需要把消息存储起来，RPC 则没有这个要求，因为前面也说了 RPC 是双向直接网络通讯。
- **从请求处理的时效性来看**：通过 RPC 发出的调用一般会立即被处理，存放在消息队列中的消息并不一定会立即被处理。

RPC 和消息队列本质上是网络通讯的两种不同的实现机制，两者的用途不同，万不可将两者混为一谈。

---

## 常见的消息队列

**1. Apache Kafka**

- **定位**：**分布式流处理平台**，主打高吞吐、高扩展性。
- **特点**：
  - **极致性能**：采用顺序写、页缓存、零拷贝等技术，吞吐量可达百万级/秒，在大数据领域是事实标准。
  - **持久化**：消息会持久化到磁盘，并支持多副本，数据可靠性高。
  - **生态丰富**：与 Flink、Spark、Storm 等流处理框架无缝集成。
- **典型场景**：**日志收集**、**用户行为跟踪**、**流式数据处理**、**Metrics 监控数据**等海量数据且允许少量延迟的场景。

**2. RabbitMQ**

- **定位**：**传统企业级消息代理**，主打可靠性、灵活的路由和强大的管理界面。
- **特点**：
  - **协议支持**：率先支持 **AMQP** 协议，提供了灵活的消息路由机制（Exchange、Binding）。
  - **功能丰富**：支持消息确认、持久化、死信队列、优先级队列等企业级特性。
  - **管理友好**：提供非常完善和友好的 Web 管理界面。
- **典型场景**：**业务系统解耦**、**异步任务处理**、**订单系统**等对消息可靠性要求高、业务逻辑复杂的场景。

**3. Apache RocketMQ**

- **定位**：**金融级可靠**的消息队列，是阿里开源的产品，在国内非常流行。
- **特点**：
  - **金融级数据一致性**：提供完整的**事务消息**解决方案，是其在电商、金融等领域的核心优势。
  - **海量消息堆积**：支持万亿级消息堆积能力，处理慢消费场景能力强。
  - **功能全面**：同时支持顺序消息、延迟消息、轨迹消息等。
- **典型场景**：**电商交易**、**金融支付**等对事务一致性要求极高的核心业务系统。

**4. Apache Pulsar**

- **定位**：新一代**云原生**消息流平台，被誉为 Kafka 的有力竞争者。
- **特点**：
  - **存算分离架构**：采用计算（Broker）和存储（BookKeeper）分离的架构，使其扩展性极佳，故障恢复更快。
  - **多租户支持**：原生支持多租户，非常适合云上部署和大公司内部平台化。
  - **一体化**：同时支持队列和流两种语义，社区活跃。
- **典型场景**：**云原生环境**、**多租户SaaS平台**、**需要极致弹性的消息平台**。

**5. Redis**

- **定位**：**内存型**数据结构存储，但其 Pub/Sub 和 List 结构可用于简单的消息队列场景。
- **特点**：
  - **极致快**：基于内存操作，延迟极低。
  - **功能简单**：没有持久化（Pub/Sub）、没有ack机制、无高级特性，消息容易丢失。
- **典型场景**：**简单的发布订阅**（如聊天室、服务发现）、**实时性要求极高但允许消息丢失**的业务。

---

# Kafka

## 基础

Kafka本质上是一个**分布式的、高吞吐量的、基于发布订阅模式的流处理平台**，而不仅仅是一个传统的消息队列。它的设计目标就是处理海量的实时数据流。

---

### **特点**

**1. 高吞吐量与低延迟**

这是Kafka最广为人知的特点。它能在普通的硬件上支持每秒数十万甚至百万级的消息吞吐，同时保持毫秒级的延迟。这主要得益于其三大核心技术：

- **顺序读写磁盘**：Kafka将消息持续追加到日志文件末尾，充分利用了磁盘顺序读写速度远快于随机读写的特性。
- **零拷贝技术**：消费者读取数据时，数据直接从磁盘文件通过DMA方式传输到网卡， bypass了应用程序和CPU的多次拷贝，极大减少了开销。
- **页缓存与批量处理**：大量利用操作系统页缓存，减少了JVM GC压力；同时生产者和消费者都支持批量操作，大幅提升了网络和I/O效率。

**2. 可持久化与高可靠**

Kafka不像某些内存队列，它**将所有消息持久化到磁盘**，并且支持配置多副本机制。每个分区的数据都有多个副本，分布在不同Broker上，一旦主副本宕机，其他副本会迅速接管，保证了数据的可靠性和服务的可用性，消息不会丢失。

**3. 高可扩展性**

Kafka的扩展性极佳，体现在：

- **水平扩展**：集群可以通过简单地增加Broker来提升整体性能。Topic可以划分为多个**Partition**，这些Partition可以分布在不同Broker上，实现了数据的分布式存储和并行处理。
- **松耦合**：生产者和消费者与集群是解耦的，客户端的增减不会影响Broker集群。

**4. 丰富的生态系统**

Kafka不仅仅是一个消息队列，更是一个完整的**流处理平台**。其强大的**Kafka Connect**和**Kafka Streams**组件，使得它能够轻松地与各种数据源集成并实现复杂的流式数据处理，成为了大数据领域事实上的标准数据管道。

---

### **核心概念**

Kafka的核心架构围绕几个关键概念构建：

- **Producer & Consumer**：生产者和消费者，分别是数据的发送方和接收方。
- **Broker**：Kafka集群由多个服务器节点组成，每个节点就是一个Broker，负责接收、存储和投递消息。
- **Topic**：数据流的类别或主题，生产者向Topic发送消息，消费者订阅Topic消费消息。
- **Partition**：这是Kafka实现高并发和水平扩展的**核心设计**。每个Topic可以被分成多个Partition，分布在不同Broker上。消息以**追加**的形式写入Partition，保证了顺序性。
- **Consumer Group**：这是实现“发布-订阅”模式的关键。同一个Consumer Group内的多个消费者共同消费一个Topic，每条消息只会被组内的一个消费者消费，从而实现负载均衡。

---

### **应用场景**

Kafka主要用在两大类场景：

1. **消息系统**：作为企业级的消息总线，进行系统解耦和异步通信。
2. **流处理平台**：这是它更核心的定位。常用于**实时日志收集**、**用户行为跟踪**、**运营指标监控**等，作为大数据流处理管道（与Flink、Spark Streaming集成）的**数据源**。

---

### 相比于其他消息队列的优势

主要的优势如下：

1. **极致的性能**：基于 Scala 和 Java 语言开发，设计中大量使用了批量处理和异步的思想，最高可以每秒处理千万级别的消息。
2. **生态系统兼容性无可匹敌**：Kafka 与周边生态系统的兼容性是最好的没有之一，尤其在大数据和流计算领域。

------

### 消息模型

**Kafka 的消息模型是基于发布-订阅模式的，其核心实现依赖于三个关键概念：主题（Topic）、分区（Partition）和消费者组（Consumer Group）。**

1. **生产者（Producer）将消息发布到特定的主题（Topic）**。主题是消息的类别或 feed 名称。
2. **每个主题可以被划分为多个分区（Partition）**。分区是 Kafka 实现水平扩展和并行处理的基础。
   - 消息在分区内以**有序的、不可变序列**方式存储，每条消息都有一个唯一的偏移量（Offset）。
   - 生产者将消息发送到主题时，Kafka 会根据消息的 Key（或轮询策略）决定将其写入哪个分区。
3. **消费者通过消费者组（Consumer Group）进行订阅和消费**。
   - 一个消费者组可以包含多个消费者实例。
   - **组内的所有消费者协同工作，共同消费一个主题的所有消息**。每个分区在同一时间只能被组内的**一个消费者**消费。
   - 这种设计实现了“负载均衡”和“扇出”两种模式：
     - **负载均衡（竞争消费者模式）**：所有消息被均衡地分配给组内的消费者实例处理。
     - **扇出（发布-订阅模式）**：同一个主题可以被**多个不同的消费者组**订阅，每个组都会收到全部消息的副本。

**总结来说，Kafka 的消息模型是通过“主题-分区-消费者组”的机制，将消息流进行分割（分区）并由多个消费者（组）并行处理，从而实现了高吞吐量和可扩展性。**

------

## 机制

### 多副本机制

“Kafka的多副本机制是它保证数据不丢和服务高可用的核心设计。我了解它的核心思想是为同一份数据创建多个备份。

**1. 它是怎么工作的？**

- 对于每个数据分片（Partition），Kafka都会创建多个副本，存放在不同的服务器上。
- 这些副本里，只有一个“老大”，叫做 **Leader**，负责处理所有的读写请求。
- 其他副本都是“小弟”，叫做 **Follower**。它们只做一件事：不停地从Leader那里拷贝数据，努力保持和Leader的数据一致。

**2. 它带来了两大核心好处：**

- **第一，高可用，服务不停机。** 这是最重要的好处。如果存放Leader的那台服务器宕机了，Kafka会立刻从那些数据同步得好的Follower里，自动选出一个新的Leader来顶替。这个切换过程非常快，用户几乎感觉不到，这样就保证了服务一直在线。
- **第二，高可靠，数据不丢失。** 因为同一份数据有好几个备份，即使坏掉一两台机器，数据依然安全地保存在其他机器的副本上，这样就保证了消息不会丢失。

**3. 一个关键概念：ISR（同步副本集合）**

- 不是所有Follower都能随时被选为Leader。只有那些和Leader数据差得不多的、处于“同步中”的Follower，才会被放在一个叫 **ISR** 的名单里。
- 一旦Leader宕机，只有在这个ISR名单里的Follower才有资格参加新Leader的选举。这样可以确保新Leader上的数据是最全的，避免数据错乱。

**总结一下：** Kafka通过让多个副本‘一主多从’分工协作的方式，用额外的机器和存储空间作为代价，换来了系统极高的可靠性和可用性。”

------

### 重试机制

在消费过程中，当其中一个消息消费异常时，会进行重试，重试多次后会跳过当前消息，继续进行后续消息的消费，不会一直卡在当前消息。

默认配置下，会进行最多 10 次 的重试，每次重试的时间间隔为 0，即立即进行重试。如果在 10 次重试后仍然无法成功消费消息，则不再进行重试，消息将被视为消费失败。

---

**自定义重试次数以及时间间隔**，只需要在 `DefaultErrorHandler` 初始化的时候传入自定义的 `FixedBackOff` 即可。重新实现一个 `KafkaListenerContainerFactory` ，调用 `setCommonErrorHandler` 设置新的自定义的错误处理器就可以实现。

------

**自定义重试失败后逻辑**，需要手动实现，重写 `DefaultErrorHandler` 的 `handleRemaining` 函数，加上自定义的告警等操作。`DefaultErrorHandler` 只是默认的一个错误处理器，Spring Kafka 还提供了 `CommonErrorHandler` 接口。手动实现 `CommonErrorHandler` 就可以实现更多的自定义操作，有很高的灵活性。例如根据不同的错误类型，实现不同的重试逻辑以及业务逻辑等

---

**重试失败的数据怎么处理**

**死信队列（Dead Letter Queue，简称 DLQ）** 是消息中间件中的一种特殊队列。它主要用于处理无法被消费者正确处理的消息，通常是因为消息格式错误、处理失败、消费超时等情况导致的消息被"丢弃"或"死亡"的情况。当消息进入队列后，消费者会尝试处理它。如果处理失败，或者超过一定的重试次数仍无法被成功处理，消息可以发送到死信队列中，而不是被永久性地丢弃。在死信队列中，可以进一步分析、处理这些无法正常消费的消息，以便定位问题、修复错误，并采取适当的措施。

---

## Zookeeper

**ZooKeeper 是一个开源的分布式协调服务**。它就像一个**分布式系统的“大脑”或“总控中心”**，为大型分布式应用提供**统一配置管理、分布式锁、领导者选举**和**服务注册与发现**等核心协同功能，保证集群中各个节点间的状态一致性与可靠协同。

它的数据模型类似于**文件目录树**，通过其提供的原语，开发人员可以轻松构建高可用的分布式应用。**Kafka、Hadoop、HBase** 等众多知名分布式系统都依赖它来实现协调管理。

---

在 Kafka 2.8 之后，引入了基于 Raft 协议的 KRaft 模式，不再依赖 Zookeeper，大大简化了 Kafka 的架构。

---

**作用**

ZooKeeper在早期的Kafka架构中，扮演着**‘分布式协调员’** 的核心角色，主要负责维护和管理整个Kafka集群的**元数据**和**状态信息**。它的作用主要体现在以下四个方面：

1. **Broker管理：服务的注册与发现**
   - Kafka的每个Broker（服务器）启动时，都会到ZooKeeper上的一个指定目录（如`/brokers/ids`）里**注册**一个临时节点，把自己的地址、端口等信息写上去。
   - 这样，所有Broker和客户端（Producer、Consumer）都能从ZooKeeper上**实时感知到**当前有哪些Broker是存活在线的。这是实现服务发现的基础。
2. **Topic与Partition的元数据管理**
   - 所有Topic的配置信息、它们被分成了几个Partition、每个Partition的副本存放在哪些Broker上……这些重要的**元数据**都存储在ZooKeeper中。
   - 客户端需要知道去哪个Broker上找到某个Topic的某个Partition，就需要先查询ZooKeeper。
3. **Controller的选举与脑裂避免**
   - 这是ZooKeeper**最关键的作用**。Kafka集群中需要有一个**唯一的领导者**，叫做Controller。
   - Controller负责管理分区和副本的状态，比如监控Broker故障并触发**Leader副本的重新选举**。
   - 所有Broker都会尝试在ZooKeeper上抢占创建一个**临时节点**（比如`/controller`）。ZooKeeper能保证最终**只有一个Broker能创建成功**，这个Broker就成为Controller。这样就完美避免了“脑裂”（出现多个领导者）的问题。
4. **消费者组的位移管理（老版本）**
   - 在比较老的Kafka版本中，Consumer消费到了哪个位置（Offset）这个信息也是提交到ZooKeeper来保存的。
   - **但需要特别说明的是**，新版本的Kafka已经将消费位移的管理迁移到了Kafka内部一个叫做`__consumer_offsets`的特殊Topic中，不再依赖ZooKeeper，以此来提升性能和降低依赖。

**总结来说，ZooKeeper就像是Kafka集群的‘大脑’和‘信息公告板’，它不参与实际的数据传输，但负责维护集群里‘谁活着、谁是什么角色、数据在哪’这些最重要的元信息，保证了整个集群的协调一致和高可用。**

------

## 消费顺序、消息丢失、重复消费

### 如何保证消费顺序

Kafka保证消息消费顺序的方式非常巧妙，它**只在分区级别保证严格的消息顺序**，而不是在主题级别。

**1. 核心机制：分区内的顺序性**

- Kafka的每个**分区（Partition）** 都是一个有序的、不可变的消息序列。
- 消息在写入分区时会获得一个唯一的**偏移量（Offset）**，这个偏移量就是它在分区中的顺序标识。
- 消费者实例在消费某个分区时，会按偏移量的顺序依次读取消息。这就保证了**在单个分区内，消息的消费顺序与生产顺序是完全一致的**。

**2. 如何利用这一机制？**

如果业务上需要保证一组消息的顺序，我们必须确保这些消息都被发送到**同一个分区**。实现这一点最常见的方法是：

- 在发送消息时，为消息指定一个**Key**。
- Kafka的生产者客户端会根据这个Key的哈希值，计算出它应该被路由到哪个分区。
- 因此，**所有具有相同Key的消息，都会被发送到同一个分区**，从而保证了这些消息的顺序性。

**举例说明：**

假设要保证同一个订单的所有状态变更消息（创建订单 -> 付款 -> 发货 -> 完成）必须按顺序消费。我们可以在生产消息时，**使用订单ID作为Key**。这样，所有关于这个订单的消息都会进入同一个分区，并被消费者按顺序处理。

**3. 重要的限制与权衡**

- **全局顺序**：如果需要保证整个Topic的全局顺序，只能将Topic设置为仅有**1个分区**。但这会严重限制Topic的吞吐量和并发能力，通常不建议这样做。
- **消费者并发**：要消费一个分区，一个消费者组内最多只能有一个消费者实例。如果分区数少于消费者数，会导致部分消费者空闲。

**总结来说，Kafka通过‘分区内有序’的设计，配合‘让需要保序的消息拥有相同Key’的生产者策略，在提供高吞吐量的同时，满足了业务上局部的顺序性需求。**

---

### 如何保证消息不丢失

Kafka为了保证消息不丢失，在其内部架构上做了几个核心的设计，这些设计共同构成了其高可靠性的基石。主要体现在以下三个方面：

**1. 冗余机制：多副本（Replication）**

这是最根本的机制。Kafka为每个分区的数据创建多个副本（例如3个），并将这些副本分散在不同的物理服务器（Broker）上。这样，单台机器的宕机或磁盘损坏不会导致数据永久丢失，因为其他副本仍然完好无损。

**2. 一致性协议：ISR（In-Sync Replicas）同步副本集与Leader选举**

光有副本还不够，必须保证副本之间的一致性。Kafka引入了ISR的概念。

- **ISR**是一个动态集合，包含了所有与主副本（Leader）保持数据同步的副本。
- 生产者可以配置为只有当消息被ISR中的所有副本都成功接收后，才认为发送成功（对应`acks=all`）。**这确保了在消息被确认时，已经在多个Broker上完成了持久化。**
- 当Leader副本失效时，Kafka的Controller组件会**严格地从ISR集合中选举出新的Leader**。这个机制至关重要，它防止了数据不一致的副本成为领导者，从而保证了已被生产者确认的消息绝不会因故障切换而丢失。

**3. 持久化存储：顺序写入与日志段（Log Segment）**

- Kafka直接将消息**追加（Append）写入到磁盘的日志文件**中，而不是依赖内存缓存。这是一种顺序写操作，其性能非常高。
- 消息不会被立即删除，而是会根据配置的保留策略（例如保留7天）持久保存在磁盘上。这意味着在保留期内，即使消费者还没有消费，消息也始终安全地存在于磁盘上。

**总结来说，Kafka自身通过‘数据多副本冗余’、‘基于ISR的一致性协议’和‘消息持久化到磁盘’这三项核心设计，从架构层面保证了消息在系统内部不会丢失。**

---

### 如何保证不重复消费

**kafka 出现消息重复消费的原因：**

- 服务端侧已经消费的数据没有成功提交 offset（根本原因）。
- Kafka 侧 由于服务端处理业务时间长或者网络链接等等原因让 Kafka 认为服务假死，触发了分区 rebalance。

**解决方案：**

- 消费消息服务做幂等校验，比如 Redis 的 set、MySQL 的主键等天然的幂等功能。这种方法最有效。

- 将 

  `enable.auto.commit`

   参数设置为 false，关闭自动提交，开发者在代码中手动提交 offset。那么这里会有个问题：

  什么时候提交 offset 合适？

  - 处理完消息再提交：依旧有消息重复消费的风险，和自动提交一样
  - 拉取到消息即提交：会有消息丢失的风险。允许消息延时的场景，一般会采用这种方式。然后，通过定时任务在业务不繁忙（比如凌晨）的时候做数据兜底。

---

# RabbitMQ







---

# RocketMQ
