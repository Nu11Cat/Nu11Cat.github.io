---
title : Java多线程
order: 4
---

# 多线程

## 线程

### 进程与线程

**进程（Process）** 是操作系统资源分配的最小单位，每个进程拥有独立的内存空间、代码、数据和系统资源。进程之间相互独立，数据不共享，通信成本较高。

**线程（Thread）** 是程序执行的最小单位，是进程内部的一个执行流。一个进程可以包含多个线程，它们共享同一块内存（代码、堆等），但每个线程有自己的栈空间和程序计数器。由于共享资源，线程之间通信开销小，切换快，但也更容易出现并发问题。

进程是容器，线程是容器中的执行单元。线程必须依附于进程存在，离开进程线程无法单独存在。

### 线程安全

线程安全和不安全是在多线程环境下对于同一份数据的访问是否能够保证其正确性和一致性的描述。

- 线程安全指的是在多线程环境下，对于同一份数据，不管有多少个线程同时访问，都能保证这份数据的正确性和一致性。
- 线程不安全则表示在多线程环境下，对于同一份数据，多个线程同时访问时可能会导致数据混乱、错误或者丢失。

### 创建线程的方式

第一种是**继承 Thread 类**，重写它的 `run()` 方法，然后创建实例调用 `start()` 方法启动线程。这种方式简单直观，但因为 Java 不支持多继承，所以灵活性较差。

第二种是**实现 Runnable 接口**，把线程逻辑写在 `run()` 方法中，再把这个实现类传给 Thread 构造器。这种方式更灵活，适合资源共享，也更符合面向接口编程的思想。

第三种是**实现 Callable 接口并结合 FutureTask 使用**。这个方式的优势是可以有返回值，且可以抛出异常，更适合需要拿到线程执行结果的场景。

如果使用线程池，比如通过 `ExecutorService` 来提交任务，那底层其实也是通过 Callable 或 Runnable 实现的，只是线程的创建和管理交给了线程池，效率更高、控制力更强。

### 生命周期和状态

Java线程大致有 **六种状态**，定义在 `Thread.State` 枚举中，整个生命周期如下：

**1. 新建（New）**
 线程对象刚创建，还没调用 `start()` 方法。

**2. 就绪（Runnable）**
 调用 `start()` 后，线程进入就绪队列，等待 CPU 调度。此时并没有运行。

**3. 运行中（Running）**
 线程真正获得 CPU 时间片，开始执行 `run()` 方法的代码。

**4. 阻塞（Blocked）**
 线程尝试获取某个被别的线程持有的锁（比如 synchronized），获取不到就进入阻塞状态，直到拿到锁。

**5. 等待（Waiting）**
 线程主动等待别的线程的通知，例如调用了 `wait()`、`join()`，没有设置超时。必须通过 `notify()` 或 `join()` 结束才会被唤醒。

**6. 计时等待（Timed Waiting）**
 和等待类似，但设置了超时时间，比如 `sleep(1000)`、`wait(1000)`、`join(1000)`。

**7. 终止（Terminated）**
 线程运行完了，或者抛异常终止了，生命周期结束。

### 线程上下文切换

线程在执行过程中会有自己的运行条件和状态（也称上下文），比如上文所说到过的程序计数器，栈信息等。当出现如下情况的时候，线程会从占用 CPU 状态中退出。

- 主动让出 CPU，比如调用了 `sleep()`, `wait()` 等。
- 时间片用完，因为操作系统要防止一个线程或者进程长时间占用 CPU 导致其他线程或者进程饿死。
- 调用了阻塞类型的系统中断，比如请求 IO，线程被阻塞。
- 被终止或结束运行

这其中前三种都会发生线程切换，线程切换意味着需要保存当前线程的上下文，留待线程下次占用 CPU 的时候恢复现场。并加载下一个将要占用 CPU 的线程上下文。这就是所谓的 **上下文切换**。

### Thread 类的 run 方法

**可以直接调用 Thread 类的 run 方法吗？**

可以，但是一般不会直接调用 `run()`，而是使用 `start()` 来正确启动线程。

直接调用 `run()` 并不会启动一个新线程，它只是一个普通的方法调用，会在当前线程中执行，不具备多线程的效果。

正常启动线程，应该调用 `start()` 方法。`start()` 会由 JVM 创建新的线程，然后自动调用该线程的 `run()` 方法，真正实现多线程并发。

### sleep() 方法和 wait() 方法

在Java中，`sleep()` 和 `wait()` 都是控制线程执行流程的方法，两者都可以暂停线程的执行，但它们的用途和行为有显著不同。

**`sleep()`** 是 `Thread` 类的方法，用于让当前线程暂停执行指定的时间。线程在暂停期间不会释放持有的锁。它通常用于线程执行的延时，比如定时任务或控制任务的执行频率。当线程调用 `sleep()` 后，它会进入 **“Timed Waiting”** 状态，直到指定时间过去后自动唤醒。需要注意的是，`sleep()` 会抛出 `InterruptedException`，如果线程在睡眠过程中被中断。

**`wait()`** 是 `Object` 类的方法，必须在同步块或同步方法中调用，因为它需要持有对象的锁。当线程调用 `wait()` 后，它会进入 **“Waiting”** 状态，直到其他线程通过调用 `notify()` 或 `notifyAll()` 来唤醒它。与 `sleep()` 不同，`wait()` 会释放持有的锁，允许其他线程访问共享资源。这种机制通常用于线程间的通信，例如生产者-消费者问题。

简单来说，`sleep()` 用于让线程休眠一段时间，而 `wait()` 用于线程间的协调和同步，通常结合 `notify()` 或 `notifyAll()` 一起使用。

>**`wait()`属于`Object` 类**：`wait()` 是让获得对象锁的线程实现等待，会自动释放当前线程占有的对象锁。每个对象（`Object`）都拥有对象锁，既然要释放当前线程占有的对象锁并让其进入 WAITING 状态，自然是要操作对应的对象（`Object`）而非当前的线程（`Thread`）。
>
>**`sleep()` 属于 `Thread`** ：因为 `sleep()` 是让当前线程暂停执行，不涉及到对象类，也不需要获得对象锁。

## 多线程

### 并发与并行

**并发（Concurrency）** 指的是多个任务在同一时间段内交替执行，可能只用一个 CPU 核心，通过任务切换实现“同时进行”的效果。本质是**逻辑上的同时**，底层依靠时间片轮转。

**并行（Parallelism）** 是指多个任务在**同一时刻真正同时运行**，必须依赖多核 CPU。每个任务在不同的核心上同时执行，实现**物理上的同时**。

举个例子，如果一个厨房只有一个人做饭，但能快速切换做饭、洗菜、炒菜的动作，那是并发；如果厨房有三个人分别同时做这三件事，那是并行。

并发更关注**任务切换效率**，并行更关注**处理能力最大化**。

### 同步与异步

同步和异步是描述任务执行时的等待与通知机制。

**同步（Synchronous）** 是指调用方发起请求后，**必须等待任务执行完毕才能继续**执行后续操作。调用过程是阻塞的。

**异步（Asynchronous）** 是指调用方发起请求后，**不等待任务完成，立即返回**，任务在后台执行，完成后通过回调、通知或轮询的方式获取结果。调用过程是非阻塞的。

举个例子，打电话让别人帮你查快递并等他查完再挂电话，这是同步；而发个微信让他查，等查完再告诉你，是异步。

在 Java 中，普通方法调用是同步的；使用 `CompletableFuture`、`Future`、线程池提交任务时，就是异步执行，主线程可以继续做其他事。

**同步编程**简单直观，但可能导致资源浪费和线程阻塞；**异步编程**提高了程序响应性和资源利用率，常用于 I/O 密集型或高并发场景。

### 为什么要使用多线程?

使用多线程的核心目的是**提升程序的效率和响应能力**

第一，**提高资源利用率**。现代 CPU 都是多核的，多线程可以让多个核心同时工作，实现真正的并行，提高处理能力。如果单线程运行，只能用到一个核心，浪费硬件资源。

第二，**提升程序响应性**。比如在图形界面或 Web 应用中，一个线程处理用户输入，另一个线程处理后台逻辑，可以避免界面卡顿，提升用户体验。

第三，**简化模型结构**。像生产者-消费者、事件驱动、定时任务等，如果用多线程实现，会比纯粹的轮询或状态机更自然、清晰。

第四，**加快任务处理速度**。比如同时处理多个客户端请求，或者将一个大任务拆分为多个线程并发处理，能够显著缩短整体耗时。

### 单核CPU

单核 CPU 是支持 Java 多线程的。操作系统通过时间片轮转的方式，将 CPU 的时间分配给不同的线程。（并发）

**单核 CPU 上运行多个线程效率一定会高吗？**

不一定。在单核 CPU 上运行多个线程时，线程是通过时间片轮转来切换执行的，并不是真正的同时运行，而是快速切换看起来“像是”并发。

这种切换会带来上下文切换开销，包括保存和恢复线程状态、缓存失效、内存切换等。如果线程数量过多或者频繁切换，反而会导致效率下降，甚至不如单线程执行。

另外，多线程引入了线程同步、锁竞争、死锁等问题，在单核环境下，这些问题的代价会更明显，降低程序整体性能。

所以在单核 CPU 上，是否使用多线程，取决于具体场景：

- 适合多线程的情况：比如大量 I/O 操作（读写文件、网络请求等），CPU 在等待时可以切到其他线程，提升资源利用率。

- 不适合多线程的情况：如果是 CPU 密集型运算，多线程反而因为频繁切换和锁竞争导致更低的效率。

# 锁

## 死锁

**死锁（Deadlock）** 是指两个或多个线程在执行过程中，因争夺资源而导致**相互等待对方释放资源**，从而使得所有线程都无法继续执行的情况。

Java 线程的 `jstack` 工具**检测死锁**：如果有死锁，`jstack` 的输出中通常会有 `Found one Java-level deadlock:`的字样，后面会跟着死锁相关的线程信息。

**死锁的四个必要条件**：

1. **互斥**：至少有一个资源是处于**独占模式**的，即某一时刻只能有一个线程使用该资源。
2. **持有并等待**：一个线程已经持有了至少一个资源，但又在等待其他线程持有的资源。
3. **非抢占**：资源不能被强制抢占，只有线程自己释放资源。
4. **循环等待**：一组线程之间存在一种“环形等待”关系，即线程A等待线程B持有的资源，线程B又在等待线程A持有的资源。

**防止和避免死锁的方法**：

1. **避免循环等待**：通过一定的策略（比如按顺序加锁）来避免出现循环等待。
2. **使用 `tryLock`**：例如 `ReentrantLock` 提供的 `tryLock()` 方法，能够尝试获得锁，如果无法获得就放弃，避免死锁。
3. **锁超时机制**：通过设置锁的最大等待时间，避免无限等待。
4. **减少锁的粒度**：尽量减少持有锁的时间，并且尽可能避免嵌套锁。

## 可重入锁

**可重入锁（Reentrant Lock）\**指的是\**同一个线程在获取锁之后，可以再次获取这把锁而不会发生死锁**。

换句话说，如果一个线程已经获得了某个锁，它可以在没有释放该锁的情况下再次进入同一个锁保护的代码块，系统会自动记录**锁的重入次数**，等线程退出时再逐层释放。

Java 中的 `synchronized` 和 `ReentrantLock` 都是**可重入锁**的实现。

举个例子说明：如果一个线程调用一个加了锁的方法，而这个方法内部又调用了另一个加了相同锁的方法，由于同一个线程已经持有了锁，所以可以顺利进入内层方法，不会被自己阻塞。

可重入锁的好处是**避免了递归调用或内部方法调用时死锁的问题**，也让程序结构更加清晰。

## 乐观锁和悲观锁

乐观锁和悲观锁本质上是两种并发控制策略，它们的核心区别在于对**数据冲突的预期不同**。

**悲观锁**认为并发冲突是很常见的，因此每次访问共享资源时都会**先加锁**，比如使用 `synchronized` 或 `ReentrantLock` 来保证同一时刻只有一个线程访问资源。这种方式安全性高，适用于并发写多、冲突频繁的场景，比如转账、订单扣库存等。

而**乐观锁**则认为并发冲突是少数，它**不加锁**，而是每次读取数据时带上一个版本号或时间戳，修改时再比对当前版本是否一致。如果一致就更新成功，否则就重试。像 Java 中的 `AtomicInteger`、`AtomicReference`，底层就是基于 CAS 实现的乐观锁。数据库中也常用乐观锁，比如用 `version` 字段控制更新。

简单来说，**悲观锁重在预防，乐观锁重在事后校验**。

悲观锁通常多用于写比较多的情况（多写场景，竞争激烈），这样可以避免频繁失败和重试影响性能，悲观锁的开销是固定的。不过，如果乐观锁解决了频繁失败和重试这个问题的话（比如`LongAdder`），也是可以考虑使用乐观锁的，要视实际情况而定。

乐观锁通常多用于写比较少的情况（多读场景，竞争较少），这样可以避免频繁加锁影响性能。不过，乐观锁主要针对的对象是单个共享变量。

**版本号机制**

版本号机制是实现乐观锁的常见方式之一，主要用于解决并发修改共享数据的问题。

它的核心思路是：每条数据都加一个版本号字段（如 version），每次读取数据时一并读取当前版本号，更新时也携带这个版本号。

当进行更新操作时，系统会检查当前数据库中的版本号是否与之前读取的一致：

- 如果一致，说明这段时间内没人改动过这条数据，就允许更新，并把版本号 +1；
- 如果不一致，说明其他线程已经修改过了，当前更新失败，可以选择重试或提示用户。

这个机制避免了加锁，也能有效防止脏写（Lost Update）问题。

**CAS算法**

CAS，全称是 Compare-And-Swap（比较并交换），是一种常见的无锁并发原子操作，底层由硬件指令支持。

它的核心思想是：在更新某个共享变量时，先比较它的当前值是否是预期值，如果是，则更新为新值；如果不是，说明已经被其他线程修改过，更新失败，通常会进行重试。

在 Java 中，`java.util.concurrent.atomic` 包下的原子类，比如 `AtomicInteger`、`AtomicReference`，就是基于 CAS 实现的乐观锁。

**ABA 问题**是 CAS 算法中一个典型的并发陷阱。

CAS 只比较当前值和预期值是否相等，但**并不知道这个值在期间是否发生过变化又被改回来了**，也就是说，它只能比较“值”，但不知道“过程”。为了避免 ABA 问题，Java 提供了带版本号的原子引用类：`AtomicStampedReference`：每次更新时不仅比较值，还比较一个“版本号”或“时间戳”，确保值和版本都没变，从而检测到中间的变化。

## 公平锁和非公平锁

**公平锁** : 锁被释放之后，先申请的线程先得到锁。性能较差一些，因为公平锁为了保证时间上的绝对顺序，上下文切换更频繁。

**非公平锁**：锁被释放之后，后申请的线程可能会先获取到锁，是随机或者按照其他优先级排序的。性能更好，但可能会导致某些线程永远无法获取到锁。

## 可中断锁和不可中断锁

**可中断锁**，指的是**线程在等待获取锁的过程中，可以被中断，从而提前退出等待**；而**不可中断锁**则不支持这种机制，一旦开始等待锁，就必须等到锁可用才能继续执行，期间不能响应中断。

在 Java 中，`synchronized` 是一种**不可中断锁**。如果一个线程在尝试进入 `synchronized` 块时被阻塞，那么它只能无限等待下去，除非获取到锁或者线程被强制终止，中间无法通过中断机制来提前结束。

而 `ReentrantLock` 支持**可中断锁**，它提供了一个方法叫做 `lockInterruptibly()`，线程在调用这个方法加锁时，如果被其他线程中断，会立刻抛出 `InterruptedException`，从而退出等待。这种机制在高并发或者死锁预防场景中非常有用。

## 共享锁和独占锁

区别主要体现在是否允许多个线程同时持有锁。

**独占锁**指的是**同一时刻只能被一个线程持有**，其他线程必须等待锁释放后才能继续执行。这种锁常用于写操作，目的是防止多个线程同时修改共享资源，从而确保数据一致性。Java 中的 `synchronized` 和 `ReentrantLock` 都属于独占锁的典型实现。

而**共享锁**允许**多个线程同时持有**，只要它们执行的操作不会互相冲突。共享锁通常用于读操作，也叫“读锁”。多个线程可以同时读取共享数据，只要没有线程进行写操作，这种方式可以显著提高读密集型场景下的并发性能。

# JMM

# 线程池

线程池（Thread Pool）是 Java 并发编程中一种\线程管理机制，它的作用是：**预先创建一组线程并重复利用，避免频繁创建和销毁线程的开销**，从而提升系统性能和资源利用率。

在没有线程池的情况下，每次执行任务都要新建线程，而线程的创建和销毁是昂贵的系统操作，频繁使用会导致性能下降，甚至资源耗尽。线程池通过**复用已存在的线程来执行多个任务**，大大降低了系统开销。

## 好处

- 复用线程，避免频繁创建销毁，提高性能；
- 统一调度任务，便于控制并发量和资源使用；
- 支持任务排队**、**定时执行**、**取消等高级特性；
- 适用于高并发、高吞吐量的服务端程序。

## 如何创建线程池

在 Java 中，创建线程池主要有两种方式：

第一种是使用 JDK 提供的 `Executors` 工具类。它封装了几种常见的线程池类型，比如固定大小的线程池、缓存线程池、单线程池和支持定时任务的线程池。这种方式创建线程池非常方便，适合快速开发和一般业务场景。

第二种是直接使用 `ThreadPoolExecutor` 类进行自定义创建。它是线程池的核心实现类，可以精细地配置核心线程数、最大线程数、任务队列、线程存活时间以及拒绝策略等参数。相比 `Executors`，`ThreadPoolExecutor` 更灵活，也更适合在复杂或高并发场景中使用。

## 不推荐使用内置线程池

实际开发中，不推荐直接使用`Executors` 工具类来快速创建线程池（内置线程池）。

1. **隐藏的资源风险：任务队列无界**

例如，`newFixedThreadPool` 和 `newSingleThreadExecutor` 内部使用的是**无界队列**，也就是说如果任务提交得太快，超过线程处理能力，任务会无限堆积，导致内存占用不断上升，严重时甚至引发 **OOM（内存溢出）**。

而开发者往往不易察觉，因为这些方法对参数封装太多，**不透明、不可控**。

2. **最大线程数不可控**

像 `newCachedThreadPool` 会根据任务数量**无限制地创建新线程**，如果短时间内有大量并发请求，可能导致系统创建大量线程，占满 CPU 和内存资源，甚至把系统压垮。

3. **拒绝策略不明确**

内置线程池默认使用的是 `AbortPolicy` 拒绝策略，也就是说，当线程池满了并且队列也满时，会**直接抛出异常**，如果业务代码没有处理好，就可能导致任务丢失或程序崩溃。

4. **不符合实际业务需求**

实际业务中往往需要根据具体场景调整线程池参数，比如控制最大并发量、设置有界队列、限制任务等待时间等。而内置线程池不支持这种精细化配置，不适合复杂场景。

**推荐做法：**

在生产环境中，更推荐**手动使用 `ThreadPoolExecutor` 来创建线程池**，明确指定核心线程数、最大线程数、队列容量和拒绝策略，从而在性能、安全性和资源使用之间做出合理权衡。

## 常见参数

常见的几个参数包括：核心线程数、最大线程数、线程存活时间、任务队列、线程工厂和拒绝策略。

首先是核心线程数，也就是 corePoolSize。它表示线程池中始终保留的线程数量，即使这些线程空闲，也不会被销毁。当有新任务到来时，如果当前线程数还没达到这个值，就会优先创建新线程来处理任务。

接着是最大线程数，也就是 maximumPoolSize。它定义了线程池允许创建的最大线程数量。当任务很多，核心线程都在忙，并且任务队列也满了，线程池才会创建超过核心数量的线程，但不会超过这个最大值。

然后是 keepAliveTime，它表示线程在空闲状态下的最大存活时间。超过这个时间没有新任务时，非核心线程会被回收掉。如果配置了允许核心线程超时，这个参数对核心线程也生效。

任务队列是线程池内部用于缓存等待执行任务的数据结构。比较常见的有有界队列和无界队列。如果使用无界队列，比如默认的 LinkedBlockingQueue，在任务堆积过多时容易导致内存溢出。生产环境中更推荐使用有界队列，能更好地控制系统负载。

线程工厂用于定制线程的创建方式，比如给线程起个有意义的名字，设置是否为守护线程等。合理命名线程有助于排查问题和监控线程状态。

最后是拒绝策略。当线程池达到最大线程数并且任务队列已满时，新的任务就无法被接受，这时就会触发拒绝策略。常见的策略包括直接抛出异常、由调用线程执行任务、丢弃任务，或者丢弃最旧的任务。

整体来看，线程池参数的配置需要根据具体业务场景来调整。核心线程数决定基本并发能力，最大线程数控制系统极限，队列影响任务调度方式，拒绝策略则决定在资源耗尽时如何应对。合理配置这些参数，才能构建出稳定、高效、可控的并发系统。

## 核心线程

`ThreadPoolExecutor` 默认不会回收核心线程，即使它们已经空闲了。

核心线程空闲时，其状态分为以下两种情况：

- **设置了核心线程的存活时间** ：核心线程在空闲时，会处于 `WAITING` 状态，等待获取任务。如果阻塞等待的时间超过了核心线程存活时间，则该线程会退出工作，将该线程从线程池的工作线程集合中移除，线程状态变为 `TERMINATED` 状态。
- **没有设置核心线程的存活时间** ：核心线程在空闲时，会一直处于 `WAITING` 状态，等待获取任务，核心线程会一直存活在线程池中。

当队列中有可用任务时，会唤醒被阻塞的线程，线程的状态会由 `WAITING` 状态变为 `RUNNABLE` 状态，之后去执行对应任务。



# 关键字等

## volatile

`volatile` 是 Java 中一种轻量级的内存同步机制，用于修饰变量，确保变量的**可见性**和**禁止指令重排序**。然而，它并不保证操作的**原子性**。

在 Java 中，每个线程都有自己的工作内存，当线程操作一个变量时，首先会从主内存拷贝该变量的副本到工作内存，线程只会操作工作内存中的副本，最后在合适的时候将结果刷新回主内存。如果没有适当的同步机制，可能导致多个线程读取到的变量值不同，从而出现可见性问题。`volatile` 通过确保线程写入变量时，会立刻将其更新到主内存，并且线程每次读取时，都会从主内存中获取最新的值，从而解决了**可见性**问题。

为了提高性能，计算机可能对程序指令进行重排序，而 `volatile` 可以禁止对带有 `volatile` 变量的写操作和后续读操作的**重排序**，确保这些操作按顺序执行。当一个变量被声明为 `volatile` 时，Java 编译器和 CPU 会在它的读写操作前后插入特定的内存屏障。

然而，`volatile` 并不保证**原子性操作**。比如对 `volatile` 变量的递增操作（`++`）可能仍然会出现竞态条件，因为它涉及多个步骤：读取、修改和写入。因此，仍然需要 `synchronized` 或其他机制来保证原子性。

`volatile` 的底层实现依赖于 Java 内存模型（JMM），通过内存屏障来确保变量的可见性和禁止指令重排序。

## synchronized

`synchronized` 是 Java 中最基本的线程同步机制，用于**保证多线程环境下对共享资源的互斥访问**。它可以修饰方法或代码块，达到加锁的效果，从而避免线程安全问题。

`synchronized` 主要有三种**用法**：

1. 修饰实例方法：锁的是当前对象（`this`），保证同一实例的同步。
2. 修饰静态方法：锁的是类对象（`Class`），适用于类级别的同步。
3. 修饰代码块：可以指定任意对象作为锁，更加灵活，适合控制粒度。

```text
构造方法不能使用 synchronized 关键字修饰。不过，可以在构造方法内部使用 synchronized 代码块。
另外，构造方法本身是线程安全的，但如果在构造方法中涉及到共享资源的操作，就需要采取适当的同步措施来保证整个构造过程的线程安全。
```

### **底层原理**

`synchronized` 是 Java 提供的内置锁机制，它的底层原理主要依赖于 JVM 的实现，特别是在 HotSpot 虚拟机中，锁是通过**对象头中的 Monitor（监视器）**来实现的。

首先，从编译层面来看，当我们使用 `synchronized` 修饰代码块或方法时，Java 编译器会在字节码中生成两条指令：`monitorenter` 和 `monitorexit`，分别对应加锁和释放锁的操作。JVM 在运行时会通过这两个指令来管理锁的获取和释放。

从运行时角度来看，每个对象在内存中都有一个对象头，其中包含了一块叫做 Mark Word 的区域，它记录了对象的哈希码、GC信息以及锁标志位。当线程尝试进入同步代码块时，会先查看这个对象头的锁状态，并尝试通过 CAS 操作去获取锁。如果获取失败，根据当前锁的状态，可能会进入自旋或者阻塞等待。

为了提升锁的性能，HotSpot JVM 在 JDK 1.6 开始引入了**锁优化机制**，将锁分为四种状态：

1. **无锁**：初始状态，无任何线程竞争；
2. **偏向锁**：当只有一个线程访问同步块时，会将锁偏向该线程，之后这个线程进入同步块时不再进行 CAS 操作；
3. **轻量级锁**：当多个线程尝试竞争偏向锁时，偏向锁会升级为轻量级锁，线程通过自旋方式尝试获取锁，避免了线程挂起和恢复的开销；
4. **重量级锁**：当自旋失败，竞争激烈时，锁会升级为重量级锁，其他线程会被挂起，等待唤醒。

这些锁的状态是根据竞争情况**自动升级**的，从偏向锁到轻量级锁再到重量级锁，但不会降级。这种策略是为了提高获得锁和释放锁的效率。

最后，在内存语义方面，`synchronized` 也保证了**可见性和有序性**。进入同步代码块之前，线程会将工作内存中的共享变量值清空，从主内存中重新读取；退出同步块时会将修改后的值刷新回主内存，从而保证了线程之间数据的可见性。

### 偏向锁废弃

偏向锁最早是在 **JDK 1.6** 引入的，目的是**优化无竞争场景下的加锁性能**。它会将锁“偏向”于第一个获得锁的线程，以后这个线程再次进入同步块时就不需要执行 CAS 操作，从而提高性能。

不过，在**JDK 15** 中，**偏向锁被默认关闭**（通过 JVM 参数 `UseBiasedLocking=false`），因为随着硬件和 JVM 其他优化手段（如轻量级锁、自旋锁）的提升，偏向锁的收益变小了。

最终在 **JDK 18 中，偏向锁被彻底移除**，JVM 不再支持这个机制。

### 和 volatile 有什么区别

`synchronized` 关键字和 `volatile` 关键字是两个互补的存在，而不是对立的存在！

- `volatile` 关键字是线程同步的轻量级实现，所以 `volatile`性能肯定比`synchronized`关键字要好 。但是 `volatile` 关键字只能用于变量而 `synchronized` 关键字可以修饰方法以及代码块 。
- `volatile` 关键字能保证数据的可见性，但不能保证数据的原子性。`synchronized` 关键字两者都能保证。
- `volatile`关键字主要用于解决变量在多个线程之间的可见性，而 `synchronized` 关键字解决的是多个线程之间访问资源的同步性

## ReentrantLock

`ReentrantLock` 是 Java 中 `java.util.concurrent.locks` 包下的一个**可重入独占锁**，它提供了比 `synchronized` 更加灵活和强大的线程同步机制。

首先，`ReentrantLock` 和 `synchronized` 的核心功能类似，都是用来实现**线程间的互斥访问**，但它提供了更多高级特性，包括：

1. **可重入性**：同一个线程可以重复获取同一把锁，不会死锁。
2. **可中断锁获取**：可以调用 `lockInterruptibly()` 来实现响应中断，避免死等。
3. **限时尝试加锁**：通过 `tryLock()` 设置超时时间，控制等待时间。
4. **公平锁与非公平锁**：构造函数可以传入 `true` 创建公平锁，先来先得，默认是非公平锁，性能更好。
5. **结合 Condition 使用**：可以创建多个条件队列（`newCondition()`），实现类似 `Object.wait/notify` 的机制，但更灵活。

从底层实现来看，`ReentrantLock` 基于 **AQS（AbstractQueuedSynchronizer）**，通过一个**FIFO 等待队列**管理线程的排队和唤醒，内部依赖 **CAS + 自旋 + 阻塞机制** 实现高效的线程调度。

相比 `synchronized`，`ReentrantLock` 更适合高并发或复杂线程控制场景，例如需要超时控制、公平策略或多个条件队列的情况。但要注意，它**必须手动释放锁**，一般建议用 `try-finally` 块包裹，防止死锁。

### 和synchronized有什么区别

在 Java 中，`synchronized` 和 `ReentrantLock` 都是用来实现线程同步的工具，但它们在实现机制、功能特性以及使用灵活性上有明显的区别。

首先，从实现层面来说，`synchronized` 是 Java 的一个关键字，由 JVM 层面直接支持。它的加锁和释放锁操作是由编译器和虚拟机自动控制的，使用起来比较简单。我们只需要加在方法或者代码块上，就能实现互斥访问。而 `ReentrantLock` 是一个显示锁，属于 `java.util.concurrent.locks` 包，它是基于 AQS（AbstractQueuedSynchronizer）框架实现的，锁的获取和释放都需要我们手动操作。

其次，在功能方面，`ReentrantLock` 提供了比 `synchronized` 更丰富的控制能力。例如，它支持**可中断锁获取**，也就是说线程在等待锁的过程中可以响应中断；还支持**限时尝试加锁**，通过 `tryLock()` 方法可以设置超时时间，这在一些高并发场景中非常有用。此外，它还支持**公平锁机制**，我们可以通过构造函数指定锁是公平的还是非公平的。而 `synchronized` 是非公平的，线程获取锁的顺序无法控制。

再者，在等待通知机制上，`ReentrantLock` 提供了一个 `Condition` 类，可以创建多个条件变量，用于更细粒度的线程控制。而 `synchronized` 只能依赖对象的 `wait()` 和 `notify()` 方法，且每个对象只能有一个条件队列，控制能力比较弱。

最后，从性能角度看，早期的 `synchronized` 性能较差，但自从 JDK 1.6 引入了偏向锁、轻量级锁等优化后，它的性能已经大幅提升。在低竞争或短时间加锁的场景下，`synchronized` 的性能和 `ReentrantLock` 是相当的。而在复杂并发场景中，`ReentrantLock` 通常更有优势，因为它支持非阻塞的锁获取方式，可以减少线程切换和上下文开销。

总结来说，`synchronized` 更适合结构简单、对性能要求不高的场景，使用方便、易于维护；而 `ReentrantLock` 则适用于并发更复杂、需要更强控制力的场合，比如可中断、限时、公平锁或多个等待条件等需求。

## ReentrantReadWriteLock

`ReentrantReadWriteLock` 是 Java 并发包中提供的一种**读写分离锁**，它实现了 `ReadWriteLock` 接口，内部包含一把**读锁（共享锁）和一把写锁（独占锁）**，用于提升多线程读操作时的并发性能。

它的核心思想是：**读操作可以并发执行，写操作必须独占**。也就是说，多个线程可以同时获取读锁，只要没有线程持有写锁；而写锁一旦被持有，其他线程无论是读还是写，都会被阻塞。

举个简单的例子，如果系统中读远远多于写，比如缓存读取场景，就可以使用 `ReentrantReadWriteLock` 来让多个线程并发读，提高吞吐量；而当写操作发生时，它会自动阻塞其他读写线程，直到写操作完成。

这个锁的**特点**包括：

1. **可重入性**：读锁和写锁都支持可重入。写线程可以再次获取写锁，也可以在持有写锁的情况下获取读锁（锁降级）；但读锁不能升级为写锁，避免死锁。
2. **支持公平和非公平模式**：默认是非公平锁，也可以通过构造函数创建公平锁，保证线程获取锁的顺序。
3. **锁降级支持**：写锁可以降级为读锁，即线程在持有写锁的同时获取读锁，再释放写锁，这对缓存更新等场景非常有用。
4. **基于 AQS 实现**：它内部使用两个 `Sync` 子类分别管理读和写的状态，读锁是共享模式，写锁是独占模式。

>**读锁和写锁**
>
>在线程持有读锁的情况下，该线程不能取得写锁(因为获取写锁的时候，如果发现当前的读锁被占用，就马上获取失败，不管读锁是不是被当前线程持有)。
>
>在线程持有写锁的情况下，该线程可以继续获取读锁（获取读锁时如果发现写锁被占用，只有写锁没有被当前线程占用的情况才会获取失败）。
>
>写锁可以降级为读锁，但是读锁却不能升级为写锁。这是因为读锁升级为写锁会引起线程的争夺，毕竟写锁属于是独占锁，这样的话，会影响性能。
>
>另外，还可能会有死锁问题发生。举个例子：假设两个线程的读锁都想升级写锁，则需要对方都释放自己锁，而双方都不释放，就会产生死锁。

## StampedLock

不重要

`StampedLock` 是 Java 8 中引入的一种新的锁机制。它是为了解决传统读写锁在高并发读场景下性能不够理想的问题，提供了**更高吞吐量的读写控制机制**。

和 `ReentrantReadWriteLock` 类似，`StampedLock` 也提供**读锁、写锁**，但它的核心机制不同：**每次加锁都会返回一个 stamp（戳），这个戳是一个 long 值，用于后续解锁或验证操作**。

### 三种模式：

1. **写锁（write lock）**：是独占的，获取方式是 `lockWrite()`，释放用 `unlockWrite(stamp)`，类似于传统的写锁。
2. **悲观读锁（read lock）**：是共享的，通过 `lockRead()` 获取，适用于读操作频繁、对数据一致性要求高的场景。
3. **乐观读锁（optimistic read）**：最大的特点。使用 `tryOptimisticRead()` 获取一个 stamp，不加锁，读取后用 `validate(stamp)` 检查期间数据是否被写线程修改。如果验证通过，说明读取的数据有效；否则需要回退到悲观读锁重新读取。

这种**乐观读**机制非常适合**读多写少**的高并发环境，能极大减少读写冲突，提高系统并发性。

### 与 ReentrantReadWriteLock 的区别：

- `StampedLock` 支持**乐观读**，能在无锁条件下完成读取，提高性能；
- `StampedLock` **不可重入**，即线程不能重复获取相同类型的锁；
- 解锁必须依赖加锁返回的 `stamp` 值，**不支持 `Condition` 条件变量**；
- **使用更复杂**，需要手动控制 `stamp` 的获取与验证，但灵活性和性能更高。

## ThreadLocal

`ThreadLocal` 是 Java 提供的一种线程本地变量工具，它的作用是**为每个线程提供一份独立的变量副本**，从而避免多线程访问共享变量时产生的线程安全问题。

简单来说，通过 `ThreadLocal`，每个线程访问的变量都是它自己私有的，互不干扰。它非常适合用于**线程范围内共享但线程之间隔离的场景**，比如用户会话信息、数据库连接、事务管理等。

### 实现原理

它的底层原理并不是把数据放在 `ThreadLocal` 对象里，而是将数据**存储在线程内部**。具体来说，每个线程内部都有一个专门的结构，叫做 `ThreadLocalMap`，这是一个专门用于存储当前线程的本地变量副本的特殊哈希表。这个表的键是 `ThreadLocal` 实例本身，值就是线程自己对应的数据。

当我们调用 `ThreadLocal.set()` 方法时，其实就是把数据存进了当前线程自己的那张表里；而调用 `get()` 方法时，系统就会从这张表中查找与当前 `ThreadLocal` 实例对应的值。也就是说，虽然所有线程共享同一个 `ThreadLocal` 对象，但它们访问的是自己线程内部的数据，因此互不影响。

这个设计的最大特点是**隔离性**：每个线程只访问自己的变量副本，没有共享，不需要加锁，从根本上避免了线程安全问题。

不过，`ThreadLocalMap` 有一个值得注意的点：它的键是一个弱引用，也就是说，如果某个 `ThreadLocal` 对象没有被外部强引用持有，那么它的键会被垃圾回收，而它对应的值还会残留在线程内部，导致内存泄漏。这个问题在使用线程池时尤其明显，因为线程会被复用，如果变量没被清理，可能影响后续线程的执行。因此在使用 `ThreadLocal` 后，建议手动调用 `remove()` 方法，及时清理变量。

此外，Java 还提供了 `InheritableThreadLocal`，它允许子线程继承父线程的变量副本，适合用于线程间传递一些上下文信息，比如用户身份、请求 ID 等。

### 内存泄漏

`ThreadLocal` 可能导致**内存泄露**，主要是因为它底层使用的 `ThreadLocalMap` 中，**key 是弱引用，value 是强引用**，而且这个 map 是保存在线程对象内部的。

具体来说，当我们创建一个 `ThreadLocal` 变量并使用后，如果外部代码没有强引用再指向这个变量，那么 JVM 会在下一次垃圾回收时**回收掉这个弱引用的 key**，但是由于 `ThreadLocalMap` 中的 value 是强引用，它不会被自动回收，就会变成一个“key 为 null，value 还存在”的残留对象。

更关键的是：这个 `ThreadLocalMap` 是存在线程对象里的，而**线程对象本身不会被回收，尤其在线程池中会被长时间复用**，这就导致那些 key 为 null 的 value 长期留在内存里，形成内存泄露。

**正确做法：**

在使用 `ThreadLocal` 时，务必在使用完毕后手动调用 `remove()` 方法，清除当前线程中的变量，释放引用，防止内存泄漏。

### 跨线程传递ThreadLocal 的值

普通 `ThreadLocal` 无法跨线程传递。因为它是为线程隔离设计的，每个线程内部维护自己独立的变量副本，默认线程之间是互不可见的。

在实际开发中，我们有时候确实需要把某些线程上下文信息，比如用户身份、请求 ID、事务信息等，从一个线程**传递给另一个线程**。这就涉及了 **“ThreadLocal 跨线程传递”**的问题。

---

**1. InheritableThreadLocal：用于父子线程传递**

Java 标准库提供了一个子类叫 `InheritableThreadLocal`，它的作用是在**子线程创建时**，把父线程中对应的 ThreadLocal 值**复制一份**到子线程里。

原理是在 `Thread` 类中，创建子线程时会检查父线程是否有 `inheritableThreadLocals`，如果有，就将其内容拷贝到子线程。

这个机制可以实现在子线程中读取父线程设置的变量值，但也有两个局限：

- **只在创建子线程那一刻生效**，后续父线程对变量的修改，子线程无法感知；
- **在线程池中无效**，因为线程池中的线程是复用的，不会重新触发拷贝操作。

------

**2. TransmittableThreadLocal：解决线程池场景下的变量传递**

为了支持在线程池中也能传递上下文变量，阿里开源了一个增强版工具类叫 **`TransmittableThreadLocal`（TTL）**。

TTL 的核心原理是：在任务提交给线程池时，它会把当前线程中的所有 TTL 变量**复制到任务中**，再由框架在任务执行前注入到目标线程，执行完后再恢复现场。通过这种**包装 Runnable 或 Callable 的方式**，实现了跨线程、跨线程池上下文的“显式传递”。

简单来说，TTL 是通过 **任务封装 + ThreadLocalMap 拷贝 + 执行前注入 + 执行后清理** 实现变量在异步线程之间的“可控传播”。

这解决了 `InheritableThreadLocal` 在线程池中无效的问题，是在日志链路追踪、分布式调用等场景下非常实用的方案。

# 其他



















