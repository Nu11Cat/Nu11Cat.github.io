---
title : 操作系统
wiki: computer_basics
---

# 操作系统

操作系统是管理计算机硬件和软件资源的系统程序，它为用户和应用程序提供统一的接口和运行环境，负责处理任务调度、内存管理、文件系统、设备驱动等核心功能，使计算机系统高效、稳定、可用。

**操作系统主要有哪些功能**

从资源管理的角度来看，操作系统有 6 大功能：

1. **进程和线程的管理**：进程的创建、撤销、阻塞、唤醒，进程间的通信等。
2. **存储管理**：内存的分配和管理、外存（磁盘等）的分配和管理等。
3. **文件管理**：文件的读、写、创建及删除等。
4. **设备管理**：完成设备（输入输出设备和外部存储设备等）的请求或释放，以及设备启动等功能。
5. **网络管理**：操作系统负责管理计算机网络的使用。网络是计算机系统中连接不同计算机的方式，操作系统需要管理计算机网络的配置、连接、通信和安全等，以提供高效可靠的网络服务。
6. **安全管理**：用户的身份认证、访问控制、文件加密等，以防止非法用户对系统资源的访问和操作。

## 用户态和内核态

根据进程访问资源的特点，我们可以把进程在系统上的运行分为两个级别：

- **用户态(User Mode)** : 用户态运行的进程可以直接读取用户程序的数据，拥有较低的权限。当应用程序需要执行某些需要特殊权限的操作，例如读写磁盘、网络通信等，就需要向操作系统发起系统调用请求，进入内核态。
- **内核态(Kernel Mode)**：内核态运行的进程几乎可以访问计算机的任何资源包括系统的内存空间、设备、驱动程序等，不受限制，拥有非常高的权限。当操作系统接收到进程的系统调用请求时，就会从用户态切换到内核态，执行相应的系统调用，并将结果返回给进程，最后再从内核态切换回用户态。

### 为什么要有用户态和内核态

- 在 CPU 的所有指令中，有一些指令是比较危险的比如内存分配、设置时钟、IO 处理等，如果所有的程序都能使用这些指令的话，会对系统的正常运行造成灾难性地影响。因此，我们需要限制这些危险指令只能内核态运行。这些只能由操作系统内核态执行的指令也被叫做 **特权指令** 。
- 如果计算机系统中只有一个内核态，那么所有程序或进程都必须共享系统资源，例如内存、CPU、硬盘等，这将导致系统资源的竞争和冲突，从而影响系统性能和效率。并且，这样也会让系统的安全性降低，毕竟所有程序或进程都具有相同的特权级别和访问权限。

因此，同时具有用户态和内核态主要是为了保证计算机系统的安全性、稳定性和性能。

### 用户态和内核态是如何切换的

用户态切换到内核态的 3 种方式：

1. **系统调用（Trap）**：用户态进程 **主动** 要求切换到内核态的一种方式，主要是为了使用内核态才能做的事情比如读取磁盘资源。系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现。
2. **中断（Interrupt）**：当外围设备完成用户请求的操作后，会向 CPU 发出相应的中断信号，这时 CPU 会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。
3. **异常（Exception）**：当 CPU 在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。

在系统的处理上，中断和异常类似，都是通过中断向量表来找到相应的处理程序进行处理。区别在于，中断来自处理器外部，不是由任何一条专门的指令造成，而异常是执行当前指令的结果。

## 系统调用

**系统调用是用户态程序与操作系统内核之间进行交互的接口，允许应用程序请求操作系统执行一些只有内核才能完成的受保护操作。**

例如，读写文件、分配内存、创建进程、进行网络通信等操作，用户程序本身没有权限直接访问硬件或关键资源，因此必须通过系统调用让操作系统代为执行。

### 系统调用的过程

系统调用的过程可以简单分为以下几个步骤：

1. 用户态的程序发起系统调用，因为系统调用中涉及一些特权指令（只能由操作系统内核态执行的指令），用户态程序权限不足，因此会中断执行，也就是 Trap（Trap 是一种中断）。
2. 发生中断后，当前 CPU 执行的程序会中断，跳转到中断处理程序。内核程序开始执行，也就是开始处理系统调用。
3. 当系统调用处理完成后，操作系统使用特权指令（如 `iret`、`sysret` 或 `eret`）切换回用户态，恢复用户态的上下文，继续执行用户程序。

# 进程

线程见Java多线程

---

## 进程，线程，协程的区别

**进程**是操作系统中进行资源分配和调度的基本单位，它拥有自己的独立内存空间和系统资源。每个进程都有独立的堆和栈，不与其他进程共享。进程间通信需要通过特定的机制，如管道、消息队列、信号量等。由于进程拥有独立的内存空间，因此其稳定性和安全性相对较高，但同时上下文切换的开销也较大，因为需要保存和恢复整个进程的状态。

**线程**是进程内的一个执行单元，也是CPU调度和分派的基本单位。与进程不同，线程共享进程的内存空间，包括堆和全局变量。线程之间通信更加高效，因为它们可以直接读写共享内存。线程的上下文切换开销较小，因为只需要保存和恢复线程的上下文，而不是整个进程的状态。然而，由于多个线程共享内存空间，因此存在数据竞争和线程安全的问题，需要通过同步和互斥机制来解决。

**协程**是一种用户态的轻量级线程，其调度完全由用户程序控制，而不需要内核的参与。协程拥有自己的寄存器上下文和栈，但与其他协程共享堆内存。协程的切换开销非常小，因为只需要保存和恢复协程的上下文，而无需进行内核级的上下文切换。这使得协程在处理大量并发任务时具有非常高的效率。然而，协程需要程序员显式地进行调度和管理，相对于线程和进程来说，其编程模型更为复杂。

---

### 进程vs线程

**进程（Process）** 是操作系统中进行资源分配和调度的基本单位，它拥有自己的独立内存空间和系统资源。每个进程都有独立的堆和栈，不与其他进程共享。进程间通信需要通过特定的机制，如管道、消息队列、信号量等。由于进程拥有独立的内存空间，因此其稳定性和安全性相对较高，但同时上下文切换的开销也较大，因为需要保存和恢复整个进程的状态。

**线程（Thread）** 是进程内的一个执行单元，也是CPU调度和分派的基本单位。与进程不同，线程共享进程的内存空间，包括堆和全局变量。线程之间通信更加高效，因为它们可以直接读写共享内存。线程的上下文切换开销较小，因为只需要保存和恢复线程的上下文，而不是整个进程的状态。然而，由于多个线程共享内存空间，因此存在数据竞争和线程安全的问题，需要通过同步和互斥机制来解决。

进程是容器，线程是容器中的执行单元。线程必须依附于进程存在，离开进程线程无法单独存在。

---

### 进程切换和线程切换

**进程切换**：进程切换涉及到更多的内容，包括整个进程的地址空间、全局变量、文件描述符等。因此，进程切换的开销通常比线程切换大。

**线程切换**：线程切换只涉及到线程的堆栈、寄存器和程序计数器等，不涉及进程级别的资源，因此线程切换的开销较小。

**为什么线程切换比进程切换快**

线程切换比进程切换快是因为线程共享同一进程的地址空间和资源，线程切换时只需切换堆栈和程序计数器等少量信息，而不需要切换地址空间，避免了进程切换时需要切换内存映射表等大量资源的开销，从而节省了时间和系统资源。

---

## PCB

**PCB（Process Control Block）** 即进程控制块，是操作系统中用来管理和跟踪进程的数据结构，每个进程都对应着一个独立的 PCB，用于记录该进程的全部关键信息。

**PCB 通常包含以下内容：**

1. **进程标识信息**：如进程 ID（PID）、父进程 ID；
2. **处理器状态信息**：保存 CPU 寄存器、程序计数器（PC）、程序状态字（PSW）等，用于进程切换时恢复上下文；
3. **进程控制信息**：如进程状态（就绪、运行、阻塞等）、优先级、调度信息；
4. **内存管理信息**：如页表、段表、内存分配情况；
5. **文件管理信息**：打开的文件列表、I/O 资源信息；
6. **通信信息**：用于进程间通信的缓冲区、消息队列、信号等信息。

---

## 进程有哪几种状态

1. **就绪（Ready）**
    进程已具备运行条件，正在等待被 CPU 调度执行。
2. **运行（Running）**
    进程正在使用 CPU 执行指令，是唯一处于执行状态的进程（在单核系统中）。
3. **阻塞（Blocked）/等待（Waiting）**
    进程因等待某些事件（如 I/O 完成、资源可用）而暂停执行，即使有 CPU 也不能运行。
4. **新建（New）**
    进程正在被创建，尚未进入就绪队列。
5. **结束（Terminated）**
    进程已完成执行或被强制终止，正在释放资源。

---

## 进程上下文

**进程上下文**是进程在执行过程中某一时刻的状态的快照。它包含了操作系统为了能够**暂停当前进程并在之后准确地恢复它**所需要的所有信息。

它主要包含两大部分信息：

一是**用户级上下文**，即进程用户地址空间的内容，如代码、数据、堆和尤其重要的**用户栈**。

二是更关键的**系统级上下文**，主要是内核维护的**进程控制块**，其中记录了进程标识符、CPU寄存器状态（如程序计数器、栈指针）、内存管理信息（如页表指针）、文件打开状态等所有内核管理所需的信息。

上下文切换的过程就是保存当前进程的CPU状态到其PCB，切换内存空间，再从下一个进程的PCB中恢复其状态到CPU的过程。这个操作是有开销的，因此频繁的上下文切换会影响系统性能。

---

## 进程间通信方式

进程间通信（IPC，Inter-Process Communication）是指不同进程之间交换数据的机制，常见的通信方式包括以下几种：

1. **管道（Pipe）**
   - 单向通信，通常用于有亲缘关系的进程（如父子进程）；
   - 包括匿名管道和命名管道（FIFO）。
2. **消息队列（Message Queue）**
   - 允许多个进程以消息的形式发送和接收数据；
   - 支持异步通信，结构化、可管理。
3. **共享内存（Shared Memory）**
   - 将一块内存区域映射到多个进程的地址空间；
   - 速度快，但需要配合同步机制（如信号量）保证数据一致性。
4. **信号量（Semaphore）**
   - 主要用于进程间的**同步**和**互斥**，不是直接用于传递数据；
   - 可与其他方式联合使用，如共享内存+信号量。
5. **信号（Signal）**
   - 一种异步通信机制，内核向进程发送中断通知，如终止信号（SIGTERM）或用户自定义信号。
6. **套接字（Socket）**
   - 支持本地和分布式进程通信，基于网络协议；
   - 常用于客户端-服务器模型，支持 TCP/UDP。
7. **内存映射文件（mmap）**
   - 不同进程可以通过映射同一文件到内存来共享数据；
   - 类似共享内存，但通常用于文件数据共享。

---

## 进程的调度算法

**进程调度算法是操作系统决定哪个进程获得 CPU 执行权的策略，常见的有以下几种：**

1. **先来先服务（FCFS, First-Come First-Served）**
    最简单的调度策略，按进程到达时间先后顺序依次调度，容易导致长作业“拖延”短作业，平均等待时间较长。
2. **短作业优先（SJF, Shortest Job First）**
    优先调度估计运行时间最短的进程，可降低平均等待时间，但无法预知准确的执行时间，可能导致长作业饥饿。
3. **优先级调度（Priority Scheduling）**
    每个进程被分配优先级，高优先级进程优先执行。可能导致低优先级进程长期得不到调度，需引入“优先级动态调整”避免饥饿。
4. **时间片轮转（RR, Round Robin）**
    所有就绪进程轮流执行，每个进程分配固定时间片，到时间就切换。适用于多用户系统，响应快但上下文切换频繁。
5. **多级反馈队列调度（Multilevel Feedback Queue）**
    综合考虑优先级与时间片，引入多个队列，进程根据行为动态调整优先级，兼顾公平性与效率，是现代操作系统常用的策略。

---

## 僵尸进程和孤儿进程

**僵尸进程**是指一个子进程已经执行结束（即已经终止），但其父进程**没有调用 wait() 或 waitpid() 回收子进程的退出状态信息**，导致子进程的进程控制块（PCB）仍然保留在系统中。这种进程不会占用 CPU 和内存资源，但会占用一个 PID。如果父进程长时间不回收，系统中的僵尸进程可能堆积，耗尽 PID 资源，影响系统稳定。

**孤儿进程**是指一个子进程的父进程**提前终止**，此时孤儿进程仍在运行。为了让孤儿进程得到妥善处理，Linux 系统会自动将其由 **init 进程（PID 1）接管**，由 init 负责对子进程进行善后，包括资源回收等。

---

## 其他

### 为什么进程崩溃不会对其他进程产生很大影响

**进程隔离性**：每个进程都有自己独立的内存空间，当一个进程崩溃时，其内存空间会被操作系统回收，不会影响其他进程的内存空间。这种进程间的隔离性保证了一个进程崩溃不会直接影响其他进程的执行。

**进程独立性**：每个进程都是独立运行的，它们之间不会共享资源，如文件、网络连接等。因此，一个进程的崩溃通常不会对其他进程的资源产生影响。

---

### 管道有几种方式

管道在Linux中有两种方式：匿名管道和命名管道。

**匿名管道**：是一种在父子进程或者兄弟进程之间进行通信的机制，只能用于具有亲缘关系的进程间通信，通常通过pipe系统调用创建。

**命名管道**：是一种允许无关的进程间进行通信的机制，基于文件系统，可以在不相关的进程之间进行通信。

---

### 信号和信号量的区别

**信号**：一种处理异步事件的方式。信号是比较复杂的通信方式，用于通知接收进程有某种事件发生，除了用于进程外，还可以发送信号给进程本身。

**信号量**：进程间通信处理同步互斥的机制。是在多线程环境下使用的一种设施，它负责协调各个线程，以保证它们能够正确，合理的使用公共资源。

---

# 内存管理

内存管理是操作系统负责分配、回收和保护内存资源的一项核心功能，确保多个进程在使用内存时高效且互不干扰。

## 主要职责：

1. **地址空间管理**：为每个进程分配独立的虚拟地址空间，并映射到物理内存，保障安全隔离。
2. **内存分配与回收**：按需为进程分配内存，在进程结束或释放时及时回收。
3. **内存保护**：防止进程非法访问不属于自己的内存区域。
4. **换页/置换管理**：当物理内存不足时，将不活跃数据暂存到磁盘（如交换空间），实现虚拟内存扩展。
5. **内存共享和重定位**：支持多个进程共享公共代码段，提高效率。

---

## 内存碎片

**内存碎片**是指由于频繁的内存分配与释放，导致内存空间被分割成很多**无法有效利用的小块区域**，从而降低了内存使用效率。

------

根据位置不同，内存碎片分为两类：

1. **外部碎片**：指空闲内存被分散在不连续的区域中，虽然总空闲内存足够，但没有一块足够大的连续区域供分配。例如，有 100KB 空闲，但被分成多个 1~5KB 的小块，无法满足一个 30KB 的请求。
2. **内部碎片**：指实际分配给进程的内存大于其实际需要，未被使用的部分形成浪费。例如，申请 18 字节但系统按 32 字节对齐分配，剩余 14 字节就是内部碎片。

------

**产生原因**主要是由于动态内存分配机制（如 malloc/free），以及不同大小内存块频繁申请与释放，导致内存空间不再连续。

------

**解决方式**包括：

- 内存池（对象池）管理，避免频繁分配；
- 紧凑整理（如标记-整理算法）；
- 使用分页或分段机制，减少对连续内存的依赖。

---

## 内存管理方式

**内存管理方式是操作系统为实现高效、灵活、安全地分配和回收内存资源而采用的策略，常见的方式主要有以下几种：**

1. **连续分配管理**
    最早期的方式，将进程分配到一块连续的物理内存区域，包括静态分区和动态分区。
   - 优点：简单、访问快；
   - 缺点：容易产生**外部碎片**，不易扩展。
2. **分页（Paging）**
    把虚拟内存和物理内存划分成固定大小的页（Page）和页框（Frame），通过页表实现地址映射。
   - 优点：消除了外部碎片，支持虚拟内存；
   - 缺点：可能出现**内部碎片**，且多级页表会增加访问开销。
3. **分段（Segmentation）**
    将程序划分为逻辑段（如代码段、数据段、栈段等），每段可以大小不同，独立分配内存。
   - 优点：更符合程序逻辑结构，利于保护和共享；
   - 缺点：仍可能有**外部碎片**，实现比分页复杂。
4. **段页式管理（Segmented Paging）**
    结合分页和分段的优点，每个段再分页，兼顾逻辑结构和物理管理效率，是现代操作系统常用方式。
   - 优点：灵活、可扩展，支持大空间管理；
   - 缺点：地址转换复杂，依赖硬件支持。

---

## 虚拟内存

**虚拟内存是一种由操作系统和硬件协同提供的内存管理机制，它通过将物理内存与磁盘空间结合，使每个进程拥有一个独立、连续的逻辑内存空间，从而突破了实际物理内存的限制。**

简单来说，虚拟内存让程序“以为”自己有独占的大块内存，而实际上底层由操作系统动态地将活跃的数据加载到物理内存，不活跃的数据则临时存放在磁盘（如交换区或页面文件）中。

**虚拟内存的核心作用有四点：**

1. **扩展可用内存容量**
    通过将部分数据临时存放在磁盘，实现“以小博大”，让程序可以使用比实际物理内存更大的空间，支持大型应用运行。
2. **实现进程隔离**
    每个进程拥有独立的虚拟地址空间，彼此互不干扰，提升了系统的稳定性和安全性，防止非法访问和内存泄漏影响其他进程。
3. **简化内存管理**
    进程看到的是连续的虚拟内存，程序员不必关心物理内存碎片和实际分布，提高编程效率，也便于操作系统动态分配内存。
4. **支持内存保护与共享**
    操作系统可以控制哪些虚拟页可读/可写/可执行，还可实现只读共享（如多个进程共享同一个库文件的代码段），减少资源浪费。

---

## 共享内存

**共享内存**是允许两个或多个进程**直接读写同一块物理内存区域**的IPC（进程间通信）方式。它是**最快**的一种IPC机制，因为数据不需要在内核和用户空间之间来回拷贝。

**优点**：

- **极速**：避免了数据拷贝，是最快的IPC。
- **自然**：使用方式与操作普通内存无异，非常方便。

**缺点与挑战**：

- **需要同步**：这是共享内存最大的挑战。多个进程同时读写同一块内存会导致**竞态条件**。必须使用**同步机制**（如**信号量**、**互斥锁**或**文件锁**）来保护共享内存，确保数据的一致性。
- **生命周期管理**：共享内存段是独立于进程的。即使所有进程都崩溃了，共享内存段可能依然存在于内核中，需要手动清理（使用 `ipcrm`命令）。

---

**底层原理（内存映射）**

这背后的魔法是**虚拟内存**和**页表**。

- 每个进程都有自己的虚拟地址空间和页表，页表负责将虚拟地址映射到物理地址。
- 当进程A和进程B都附加到同一块共享内存时，它们的页表中，**不同的虚拟地址页面**被映射到了**相同的物理内存帧**上。
- 进程A写入其虚拟地址 `0x1234`，通过页表转换，实际是写入了物理地址 `0xAAAA`。
- 进程B读取其虚拟地址 `0x5678`，通过页表转换，实际是从物理地址 `0xAAAA`读取。
- 这样，两个进程就通过共享的物理内存 `0xAAAA`实现了通信。

---

## 虚拟地址和物理地址

**虚拟地址**是进程在访问内存时使用的地址，是一种逻辑上的地址；
**物理地址**是实际存在于硬件内存条上的地址，用于真正读写内存数据。

操作系统为每个进程分配独立的虚拟地址空间，进程只能访问自己的虚拟地址，无法直接看到或访问物理内存。

---

为了让多个进程共享物理内存且互不干扰，操作系统和硬件引入了**地址映射机制**，即将**虚拟地址映射到物理地址**。

**地址映射过程**：

“虚拟地址到物理地址的转换过程，是现代操作系统内存管理的核心魔法。这个过程主要由**MMU（内存管理单元）** 这个硬件部件协助CPU来完成，其核心是查询一个叫做**页表**的数据结构。

整个过程可以概括为以下几步：

1. **地址拆分**：当CPU执行一条需要访问内存的指令时，给出的是一个虚拟地址。MMU首先会把这个虚拟地址拆分成两部分：**虚拟页号** 和**页内偏移量**。假设是4KB的页，那么低12位就是偏移量，剩下的高位就是页号。
2. **查询页表**：MMU使用拆分出来的**虚拟页号**作为索引，去查询当前进程的**页表**。页表是操作系统为每个进程单独维护的一个映射表，它的每个条目（PTE）都记录了一个虚拟页对应的**物理页框号**以及一些控制位（如存在位、读写权限位）。
3. **有效性检查**：在拿到页表项后，MMU会进行两项关键检查：
   - **存在位检查**：检查该页是否已加载到物理内存中。如果不在（存在位为0），则会触发一个**缺页异常**。CPU会中断当前执行，跳转到操作系统的缺页异常处理程序。操作系统负责将所需的页从磁盘调入物理内存，更新页表，然后重新执行刚才那条指令。
   - **权限检查**：检查当前操作（读、写、执行）是否符合页表项中规定的权限。如果违反（例如试图写一个只读的页），会触发一个**段错误**或**访问违例**。
4. **地址合成**：如果所有检查都通过，MMU就从页表项中提取出**物理页框号**，然后将它和第一步拆分出来的**页内偏移量**组合起来，最终得到真正的**物理地址**。
5. **访问内存**：现在，这个物理地址就可以被放到地址总线上，去访问真正的物理内存了。

**为了提升性能，这个查询过程实际上有一个极快的缓存：TLB（快表）**。TLB是MMU内部的一个缓存，存放着最近使用过的虚拟页号到物理页框号的映射。转换时，MMU会**首先查询TLB**。如果命中（TLB Hit），转换在**一个时钟周期内**即可完成，无需访问内存中的页表。只有在TLB未命中（TLB Miss）时，才需要去走一遍查询页表的完整流程。

---

## 页表和段表

**1. 段表**：

段表是**分段式内存管理**的映射工具。它的设计思想是**按照程序的逻辑结构**来划分内存，比如代码段、数据段、堆栈段。每个段在段表中都有一个条目，记录了该段的**基地址（起始物理地址）、界限（长度）和访问权限（读、写、执行）**。

- **工作流程**：CPU使用段寄存器选择段，通过段表找到基址，加上指令中的偏移量得到物理地址。同时会检查偏移是否越界、操作是否违规，从而提供强大的内存保护。
- **优点**：直观，符合程序逻辑，易于实现共享和保护。
- **缺点**：容易产生**外部碎片**（内存中存在大量不连续的小空闲区），导致内存利用率降低。

**2. 页表**：

页表是**分页式内存管理**的映射工具。它的设计思想是将物理和虚拟内存都划分为固定大小的块（如4KB），虚拟内存的块叫**页**，物理内存的块叫**页框**。页表记录了每一个虚拟页到物理页框的映射关系。

- **工作流程**：CPU将虚拟地址拆解为**页号**和**页内偏移**。用页号作为索引查找页表，得到对应的物理页框号，最后将页框号和页内偏移组合成物理地址。
- **优点**：完美解决了外部碎片问题，内存分配效率高，是实现虚拟内存（如 swap in/out）的基础。
- **缺点**：可能产生**内部碎片**（最后一页未用满）；页表本身可能很大，需要多级页表或快表（TLB）来优化查找速度。

---

## 虚拟内存和物理内存

**虚拟内存**：是操作系统提供给每个运行中程序的一种地址空间，每个程序在运行时认为自己拥有的内存空间就是虚拟内存，其大小可以远远大于物理内存的大小。虚拟内存通过将程序的地址空间划分成若干个固定大小的页或段，并将这些页或者段映射到物理内存中的不同位置，从而使得程序在运行时可以更高效地利用物理内存。

**物理内存**：物理内存是计算机实际存在的内存，是计算机中的实际硬件部件。

---

## 分段机制、分页机制、段页机制

[操作系统常见面试题总结(下) | JavaGuide](https://javaguide.cn/cs-basics/operating-system/operating-system-basic-questions-02.html#分段机制)

## 其他

### 程序的内存布局

“一个程序在运行时，其内存布局从低地址到高地址大致排列如下：

1. **代码段**：也称为文本段。它存放的是**程序的机器指令**，是只读的，防止程序意外修改自身的指令。这块内存通常可以被多个进程实例共享。
2. **数据段**：它包含了**已初始化的全局变量和静态变量**。例如，在函数外声明的 `int global_var = 100;`就存储在这里。程序加载时，这些变量就从可执行文件中读取到了内存中。
3. **BSS 段**：存放**未初始化的全局变量和静态变量**。例如 `static int uninit_var;`。BSS段在程序开始运行时会被操作系统**自动初始化为零**。将已初始化和未初始化的数据分开，可以节省磁盘空间——可执行文件无需记录未初始化变量的大量零值，只需记录它们的大小即可。
4. **堆**：用于**动态内存分配**。当程序使用 `malloc()`, `calloc()`, `new`等函数时，内存就从这里分配。堆内存的**生命周期由程序员控制**（手动分配和释放），如果管理不善会导致内存泄漏。堆的地址空间是**向上增长**的。
5. **内存映射段**：这里通常映射了**共享库**（如C标准库 `libc.so`）以及用户通过 `mmap`系统调用映射的文件或匿名内存。
6. **栈**：用于存放**局部变量**、**函数参数**以及**函数调用的上下文**（如返回地址、寄存器保存值）。每次函数调用都会在栈上分配一个新的**栈帧**。栈的地址空间是**向下增长**的。它的分配和回收由编译器自动管理，速度极快。需要注意的是，栈空间通常是有限的，过度递归或分配大块局部变量会导致**栈溢出**。
7. **内核空间**：地址空间的最高部分（通常最顶部的1GB）是为**内核保留**的。它存放操作系统内核的代码、数据和每个进程的内核栈。用户程序无法直接访问，必须通过系统调用陷入内核模式才能访问。

---

###  堆和栈的区别

**分配方式**：堆是动态分配内存，由程序员手动申请和释放内存，通常用于存储动态数据结构和对象。栈是静态分配内存，由编译器自动分配和释放内存，用于存储函数的局部变量和函数调用信息。

**内存管理**：堆需要程序员手动管理内存的分配和释放，如果管理不当可能会导致内存泄漏或内存溢出。栈由编译器自动管理内存，遵循后进先出的原则，变量的生命周期由其作用域决定，函数调用时分配内存，函数返回时释放内存。

**大小和速度**：堆通常比栈大，内存空间较大，动态分配和释放内存需要时间开销。栈大小有限，通常比较小，内存分配和释放速度较快，因为是编译器自动管理。

---

### 操作系统内存不足的时候会发生什么？

当操作系统内存不足时，并不会立即导致程序崩溃或系统卡死。现代操作系统设计了一整套复杂而有效的机制来应对和管理这种情况，主要会发生以下几件事情：

**1. 触发页面交换（到Swap空间）**

这是最核心的应对机制。操作系统会识别出一部分最近不常用的**匿名内存页**（比如堆、栈中的数据），将它们从物理内存**换出**到磁盘上专门的**交换分区** 或**交换文件**中，从而腾出物理内存空间给急需的进程使用。这个过程对应用程序是透明的，但当应用程序之后访问被换出的页面时，会触发一个**缺页异常**，操作系统需要再把它从磁盘**换入**内存，这会导致明显的性能下降，我们能感觉到系统变‘卡’。

**2. 回收缓存和缓冲区**

Linux等系统会充分利用空闲内存来作为磁盘缓存（Page Cache）和缓冲区，以提升IO性能。当内存紧张时，操作系统会**优先回收这些缓存和缓冲区**的内存。因为回收这些只是可能降低IO速度，而不会影响应用程序的正确性。所以我们会看到系统的可用内存变多，但缓存减少。

**3. OOM Killer被触发（最后手段）**

如果即使进行了大量交换和缓存回收，系统依然面临严重的内存耗尽危机，Linux内核的**OOM Killer**机制就会被激活。它的职责是选择一个‘最佳’进程并将其杀死，从而立即释放它占用的所有内存资源，挽救整个系统。

OOM Killer的选择并非随机，它基于一个复杂的算法给所有进程打分（`oom_score`），主要考虑：

- **内存占用**：占用物理内存越多，分数越高。
- **进程价值**：root用户进程、运行时间长的进程、重要的守护进程分数会偏低。
- **子进程负担**：如果一个进程有很多子进程且都消耗大量内存，父进程的分数会增高。

**4. 系统层面的症状表现**

从用户和程序员的角度，会观察到：

- **系统响应极其缓慢**：由于频繁的页面交换（颠簸），硬盘灯常亮，CPU大部分时间在等待IO。
- **应用程序可能因分配不到内存而`malloc`失败**：返回`NULL`。
- **应用程序可能被强制终止**：如果你发现一个进程突然不见了，并且系统日志（`/var/log/messages`或`dmesg`）里有OOM Killer的记录，那就是它干的。

**总结来说，操作系统应对内存不足是一个渐进的过程：先是用性能换空间（交换和回收缓存），最后不得已才用稳定性换生存（杀死进程）。理解这个过程对于诊断线上服务器的内存问题至关重要。**

---

### 页面置换有哪些算法

页面置换算法是操作系统中虚拟内存管理的核心算法，当发生缺页异常且物理内存已满时，它负责选择一个‘牺牲’页面将其换出到磁盘，以便为新的页面腾出空间。常见的算法主要有以下几种：

**1. 最佳置换算法**

- **思想**：置换掉**在未来最长时间内不再被访问**的页面。这是一种理想化的算法，需要预知未来的页面访问序列。
- **优点**：理论上可以产生最低的缺页率，是衡量其他算法优劣的标准。
- **缺点**：**无法实现**，因为操作系统无法预知进程未来的访问情况。
- **意义**：仅作为理论参考（Oracle Algorithm）。

**2. 先进先出算法**

- **思想**：维护一个页面队列，总是选择**最早进入内存**的页面进行置换。
- **优点**：实现简单，开销小。
- **缺点**：性能差，因为它与页面的实际使用情况无关。可能会置换掉仍然频繁使用的‘老’页面。
- **现象**：可能会出现**Belady异常**，即分配的物理页框增多，缺页率反而上升的反常现象。

**3. 最近最久未使用算法**

- **思想**：基于**局部性原理**，认为最近一段时间没被使用的页面，在将来也很可能不会被使用。因此，它选择**最近最久未访问**的页面进行置换。
- **优点**：算法性能好，接近最佳置换算法，是实践中很有效的算法。
- **缺点**：需要硬件支持（记录每个页面的访问时间戳），实现开销较大。

**4. 时钟算法**

- **思想**：LRU算法的近似实现，是对FIFO算法的改进。它将所有页面组织成一个**环形链表**（类似钟面），并为每个页面设置一个**访问位**。当页面被访问时，硬件将其访问位置1。置换时，指针顺时针扫描，如果遇到访问位为1的页面就将其置0并跳过；遇到访问位为0的页面就选择它进行置换。
- **优点**：性能接近LRU，但实现开销远低于LRU，是**一种非常实用且高效的平衡方案**。
- **缺点**：不如真正的LRU算法精确。

**5. 最不经常使用算法**

- **思想**：置换掉**访问频率最低**的页面。它为每个页面设置一个计数器，每次访问时计数器加1。
- **缺点**：早期频繁访问但近期不再访问的页面，会因为计数器值很大而很难被置换出去。

**6. 最近未使用算法**

- **思想**：是NFU算法的近似，也是时钟算法的思想基础。它通过定期清零访问位来更加‘健忘’，更关注近期的访问情况。

**在实际系统中，Linux等现代操作系统采用的是一种更复杂的、基于LRU思想的改进算法（如双链策略），但时钟算法及其变种因其高效性而被广泛采用。**

----

### fork()

`fork()`是一个Unix/Linux系统调用，用于**创建一个新的进程**。这个新进程是调用进程（称为父进程）的一个**几乎完全相同的副本**。

fork 阶段会复制父进程的页表（虚拟内存）。fork 之后，如果发生了写时复制，就会复制物理内存。

---

### copy on write(写时复制)

**写时复制**是一种资源管理策略，其核心思想是：**多个进程最初可以共享同一份资源副本（如内存页），只有在某个进程试图修改这份资源时，系统才会真正地为该进程分配一个独立的私有副本，其余时候只是可读。**

这是一种**延迟拷贝**的优化技术，旨在避免不必要的资源复制，从而提高效率并节省资源。

**优点**

1. **高效创建进程**：`fork()`的速度变得极快，因为它几乎只需要复制页表等元数据，而无需拷贝庞大的实际数据。
2. **节省物理内存**：最大限度地减少了不必要的内存拷贝。父子进程之间可以共享所有不会改变的代码页和数据页。
3. **降低开销**：减少了内存复制带来的CPU开销和延迟。

**应用场景**

1. **`fork()`系统调用**：这是COW最经典、最广为人知的应用场景，如上所述。
2. **内存映射文件**：当使用 `mmap`映射一个文件时，多个进程可以映射同一个文件。COW允许它们共享相同的物理页缓存，直到某个进程尝试修改文件内容。
3. **容器技术**：Docker等容器技术在创建新容器时，其镜像层使用COW策略。多个容器可以共享同一个基础镜像层，只有当容器需要修改基础镜像中的文件时，才会在容器特定的可写层中进行复制。这极大地节省了磁盘空间和容器启动时间。
4. **某些编程语言的数据结构**：例如，PHP的某些类型在传递时采用COW策略，只有在需要修改时才进行复制，以减少内存占用。

---

# 文件系统

文件系统主要负责管理和组织计算机存储设备上的文件和目录。

## 功能

1. **存储管理**：将文件数据存储到物理存储介质中，并且管理空间分配，以确保每个文件都有足够的空间存储，并避免文件之间发生冲突。
2. **文件管理**：文件的创建、删除、移动、重命名、压缩、加密、共享等等。
3. **目录管理**：目录的创建、删除、移动、重命名等等。
4. **文件访问控制**：管理不同用户或进程对文件的访问权限，以确保用户只能访问其被授权访问的文件，以保证文件的安全性和保密性。

## 提高文件系统性能的方式

- **优化硬件**：使用高速硬件设备（如 SSD、NVMe）替代传统的机械硬盘，使用 RAID（Redundant Array of Inexpensive Disks）等技术提高磁盘性能。
- **选择合适的文件系统选型**：不同的文件系统具有不同的特性，对于不同的应用场景选择合适的文件系统可以提高系统性能。
- **运用缓存**：访问磁盘的效率比较低，可以运用缓存来减少磁盘的访问次数。不过，需要注意缓存命中率，缓存命中率过低的话，效果太差。
- **避免磁盘过度使用**：注意磁盘的使用率，避免将磁盘用满，尽量留一些剩余空间，以免对文件系统的性能产生负面影响。
- **对磁盘进行合理的分区**：合理的磁盘分区方案，能够使文件系统在不同的区域存储文件，从而减少文件碎片，提高文件读写性能。

## 常见的磁盘调度算法

**先来先服务（FCFS, First-Come First-Served）**
 按照请求到达的顺序依次处理，简单但可能导致大量磁头移动，效率较低。

**最短寻道时间优先（SSTF, Shortest Seek Time First）**
 优先处理距离当前磁头位置最近的请求，减少总磁头移动距离，但可能导致远处请求长时间得不到处理（“饥饿”）。

**扫描算法（SCAN，也称电梯算法）**
 磁头按一个方向移动，处理沿途请求，直到边界后再反向移动处理另一方向的请求，类似电梯运行。

**循环扫描算法（C-SCAN）**
 磁头只向一个方向处理请求，到达边界后直接返回起始端重新开始扫描，避免中间区域请求过度集中处理。

**LOOK 和 C-LOOK 算法**
 是对 SCAN 和 C-SCAN 的优化：磁头只扫描到最后一个请求的位置而不是固定边界，减少不必要移动。

## 硬链接和软连接

在 Linux 系统中，**硬链接和软连接**是两种常见的文件引用方式，用于实现多个路径指向同一个文件或资源。它们的本质区别在于链接的对象不同：硬链接是链接到**文件本身的 inode 节点**，而软连接是链接到**文件路径**。

**硬链接**本质上是为同一个文件创建了一个新的名字，两个文件名共享同一个 inode 和数据块。当其中一个被删除时，文件内容并不会立即消失，只有当所有硬链接都删除后，系统才会真正释放文件的磁盘空间。不过硬链接不能跨文件系统，也不能对目录创建硬链接（为防止循环结构）。

**软连接**也叫符号链接，是一个特殊的文件，它的内容是指向另一个文件路径的字符串。它更像是一个快捷方式，可以跨文件系统，也可以链接目录。缺点是如果目标文件被删除，软链接就会变成“悬挂”状态，无法使用。

**硬链接为什么不能跨文件系统**

硬链接是通过 inode 节点号建立连接的，而硬链接和源文件共享相同的 inode 节点号。

然而，每个文件系统都有自己的独立 inode 表，且每个 inode 表只维护该文件系统内的 inode。如果在不同的文件系统之间创建硬链接，可能会导致 inode 节点号冲突的问题，即目标文件的 inode 节点号已经在该文件系统中被使用。

---

# 中断

**CPU停下当前的工作任务，去处理其他事情，处理完后回来继续执行刚才的任务**，这一过程便是中断。

## 类型

中断是CPU响应外部事件的一种机制，它使得CPU可以暂停当前正在执行的程序，转去处理紧急事件，处理完后还能恢复原程序的执行。中断主要可以分为两大类：**外部中断**和**内部中断**。

------

#### 1. 外部中断（硬件中断）

这类中断由**CPU外部的硬件设备**发起，通过中断信号线通知CPU。它通常是**异步**的，意味着中断请求的到来与CPU正在执行的指令无关。

- **可屏蔽中断**：
  - **来源**：大部分由外部I/O设备产生，如网卡接收到数据包、硬盘完成数据读写、键盘被敲击、定时器到期等。
  - **特点**：CPU可以通过设置**中断屏蔽位**（如IF标志位）来暂时忽略这些中断请求。这用于保护重要的、不希望被打断的代码段（临界区）。
- **不可屏蔽中断**：
  - **来源**：通常用于处理非常紧急的硬件故障，如电源掉电、内存校验错误等。
  - **特点**：**CPU必须立即响应**，无法通过软件指令屏蔽。这是最高优先级的中断。

#### 2. 内部中断（软件中断）

这类中断由**CPU内部在执行指令时**根据代码执行情况自动触发，是**同步**的，即它的发生一定是由正在执行的某条指令导致的。

- **陷阱**：
  - **目的**：**有意**安排的，用于实现系统功能调用或调试。执行后，CPU会记录下一条指令的地址（以便返回）。
  - **例子**：应用程序调用 `printf`函数，最终会通过一条类似于 `int 0x80`或 `syscall`的指令陷入内核，这就是一种陷阱。调试时的断点也是陷阱。
- **故障**：
  - **目的**：是一种**可修复**的错误。CPU在执行指令**前**检测到异常条件，触发中断。处理完后，CPU会**重新执行**刚才那条出错的指令。
  - **例子**：**缺页异常**是最典型的故障。当访问的页面不在内存中时，CPU触发缺页中断；操作系统将页面从磁盘调入后，再让CPU重新执行那条访问内存的指令，这次就能成功了。
- **终止**：
  - **目的**：处理**不可修复**的严重错误。CPU在执行指令**后**检测到致命错误，无法恢复，通常只能强制终止当前程序。
  - **例子**：硬件故障、非法指令、系统数据结构被破坏（如Linux中的 Kernel Panic）。

---

## 流程

1. **中断请求**：外设或软件发出中断请求信号。
2. **中断检测**：处理器检测到中断信号。
3. **中断响应**：处理器保存当前执行状态（程序计数器、寄存器等），并跳转到中断向量表查找中断处理程序地址。
4. **执行中断处理程序**：处理器执行中断处理程序来处理特定的中断事件。
5. **中断完成**：中断处理程序执行完毕，处理器恢复之前保存的状态，继续执行被中断的任务。

---

## 作用

1. **实现CPU与I/O设备的并行工作（提高CPU利用率）**

   最重要的作用。让CPU不需要**轮询**来检查设备状态，提供了CPU利用率，使得CPU和I/O设备可以真正地并行工作，极大地提升了CPU的利用率和系统整体的吞吐量。

2. **处理异常事件，保证系统稳定运行**

   CPU在执行过程中会遇到各种无法预料的错误，如除零、非法指令、缺页等。中断机制为这些异常事件提供了统一的处理入口。当发生异常时，CPU会自动切换到操作系统内核预设的处理程序，从而可以优雅地报告错误、修复问题（如调入缺失的页面）或终止进程，避免了系统崩溃，保障了系统的稳定性和可靠性。

3. **提供用户程序与操作系统内核的接口（系统调用）**

   应用程序没有权限直接操作硬件或执行特权指令。它需要通过一种方式请求操作系统为其服务。**系统调用**就是通过触发一个软中断（例如Linux的`int 0x80`或`syscall`指令）来实现的。这使CPU从用户态切换到内核态，由操作系统内核完成请求后，再返回用户态。中断机制是实现操作系统的**保护性**和**隔离性**的关键。

4. **满足实时处理需求**

   对于需要及时响应外部事件的系统（如工业控制、嵌入式设备），中断提供了一种**异步**的响应机制。高优先级的事件可以随时打断当前任务，得到CPU的立即处理，从而满足严格的实时性要求。

---

# 网络IO

## IO模型有哪些

I/O模型主要分为五种，它们的核心区别在于应用程序在**等待数据就绪**和**数据拷贝**这两个阶段的行为不同。

1. **阻塞I/O**：最传统的方式。应用程序调用I/O操作后，线程会一直挂起等待，直到数据完全准备好并从内核拷贝到用户空间。**简单，但性能差**，一个线程只能处理一个连接。
2. **非阻塞I/O**：应用程序调用I/O操作后，如果数据没准备好，会立刻返回一个错误。线程需要通过**不断轮询**来检查数据是否就绪，在拷贝数据时依然会阻塞。**避免了线程挂起，但轮询消耗大量CPU**。
3. **I/O多路复用**：这是**高并发编程的基石**。应用程序将多个I/O请求注册到一个多路复用器（如`select`, `epoll`），然后阻塞在这个复用器上。当任何一个请求的数据就绪时，复用器返回通知，应用程序再逐个处理。**核心优势是一个线程可以高效地管理成千上万个连接**。
4. **信号驱动I/O**：应用程序在发起I/O请求后就可以继续执行。当数据就绪时，内核会发送一个信号来通知应用程序，随后应用程序再进行数据拷贝（该阶段阻塞）。**通知机制是异步的，但拷贝仍是同步的**，实践中较少使用。
5. **异步I/O**：**真正的异步模型**。应用程序发起I/O请求后立即返回，内核会负责完成从等待数据到数据拷贝的所有工作。完成后，内核通过回调等方式通知应用程序。**应用程序在两个阶段都不会被阻塞**。

---

前四种模型（阻塞、非阻塞、多路复用、信号驱动）都属于**同步I/O**，因为真正的I/O读写操作都会在某个时间点阻塞进程。只有最后一种**异步I/O**才是真正的异步。目前，**I/O多路复用**是Linux系统下实现高并发网络应用最主流、最高效的模型。

---

## 服务器处理并发请求有哪几种方式？

#### 1. 多进程模型

- **方式**：主进程（监听者）负责接受新连接。每当有一个新的客户端连接到来时，主进程就调用 `fork()`创建一个新的子进程，由这个子进程专门负责处理该连接的所有请求。处理完毕后，子进程退出。
- **优点**：
  - **稳定性高**：进程间地址空间完全隔离，一个进程崩溃不会影响其他进程。
- **缺点**：
  - **资源开销大**：创建进程、进程间上下文切换的成本很高。
  - **进程间通信复杂**：需要借助IPC（管道、消息队列等）来共享数据，比较复杂。
- **典型代表**：早期的Apache服务器（prefork模式）。

#### 2. 多线程模型

- **方式**：主线程负责接受新连接。当新连接到来时，创建一个新的工作线程来处理该连接，主线程继续监听。
- **优点**：
  - **轻量高效**：创建线程和线程间上下文切换的开销远小于进程。
  - **数据共享简单**：线程间共享进程的全局变量和内存，通信非常方便。
- **缺点**：
  - **编程复杂**：需要处理复杂的线程同步问题（锁、竞态条件），容易出错。
  - **稳定性风险**：一个线程的不当操作（如野指针）可能导致整个进程崩溃，波及所有连接。
- **典型代表**：Apache服务器（worker模式）、Java Tomcat。

#### 3. I/O多路复用模型（事件驱动模型）

- **方式**：这是**现代高并发服务器的绝对主流**。只有一个主进程/线程，它使用 `select`, `poll`, `epoll`(Linux), `kqueue`(BSD) 等系统调用，**同时监听和管理成百上千个连接**。当某个连接有数据可读或可写时， multiplexer 就通知应用程序，应用程序再来处理这个连接的请求。
- **优点**：
  - **超高并发**：一个线程就能处理所有连接，资源占用极少，可以轻松应对C10K甚至C10M问题。
  - **无上下文切换开销**：避免了多进程/多线程模型频繁切换带来的性能损耗。
- **缺点**：
  - **编程复杂度高**：程序逻辑是异步、事件驱动的，开发难度较大。
  - **无法利用多核**：单一主线程无法充分利用多核CPU。通常通过启动多个进程实例（绑定不同CPU核心）或使用线程池（混合模型）来解决。
- **典型代表**：**Nginx**、**Redis**、**Node.js**。

---

**现代高性能服务器的常见混合模式**：

实际上，很多服务器会采用混合模式，例如：

- **Nginx**：使用 **多进程 + I/O多路复用**。启动一个Master进程和多个Worker进程，每个Worker进程都是一个独立的I/O多路复用实例，从而充分利用多核CPU。
- **Java Netty**：使用 **线程池 + I/O多路复用**。由一个BOSS线程组负责接受连接，由WORKER线程池（基于NIO）负责处理已建立的连接。

---

## select、poll、epoll

`select`、`poll`和 `epoll`都是 Linux 下实现 I/O 多路复用的核心机制，但它们的设计和性能有着代际般的差异。

**首先是最基础的 `select`。** 它的工作方式是轮询，每次调用都需要将整个需要监听的文件描述符集合从用户态拷贝到内核态，然后由内核线性扫描所有描述符来判断是否就绪。它的主要问题是性能会随着连接数的增加而线性下降，并且有 1024 这个连接数的硬性限制。

**然后是 `poll`。** 它改进了 `select`的一些缺陷，用动态的 pollfd 结构数组替代了固定的位图，从而解除了连接数的限制。但它的本质依然是轮询，内核依然需要线性扫描所有被监视的描述符，所以性能瓶颈依然存在。

**最后是现代高性能的 `epoll`。** 它完全采用了事件驱动的设计。我们通过 `epoll_ctl`预先将描述符注册到内核，内核会通过回调机制来管理事件就绪的通知。当调用 `epoll_wait`时，它只是从内核的一个就绪事件链表中取出结果并返回，而无需遍历整个集合。这使得它的性能不会随着连接数的增加而下降，只与活跃连接的数量正相关，因此能够轻松应对数万甚至数十万的并发连接。

**总结来说，三者的演进路径是从低效的轮询（select/poll）走向了高效的事件通知（epoll）。** `select`和 `poll`适用于跨平台或连接数极少的场景，而 `epoll`则是 Linux 下构建高性能网络服务的绝对首选和基石，像 Nginx 和 Redis 都深度依赖它。

---

## epoll 的 边缘触发和水平触发有什么区别

“`epoll`的**边缘触发**和**水平触发**是两种非常重要的事件通知模式，它们的区别核心在于**内核通知应用程序文件描述符就绪的时机和条件**。

**1. 水平触发**

- **工作方式**：只要文件描述符对应的读或写缓冲区**处于**“非空”或“非满”的状态（即可读或可写），`epoll`就会持续通知应用程序。
- **行为类比**：这就像把一个开关**按住**不放，只要条件满足，灯就会一直亮着。
- **影响**：在这种模式下，应用程序在收到一次可读通知后，**即使没有一次性读完所有数据**，下次调用 `epoll_wait`时，`epoll`会再次通知这个描述符可读，直到缓冲区被读空。写入同理。
- **优点**：对程序员更友好，不容易遗漏事件，编码更简单。
- **缺点**：可能会导致不必要的重复通知，如果应用程序不想处理，需要自己记录状态。

**2. 边缘触发**

- **工作方式**：只有当文件描述符对应的缓冲区状态**发生变化时**（例如从不可读变为可读，或从不可写变为可写），`epoll`才会通知一次应用程序。
- **行为类比**：这就像是一个开关的**上升沿**，只有在**按下开关的瞬间**灯会亮一下，之后无论你按着不放还是松开，它都不会再持续亮着。
- **影响**：在这种模式下，应用程序在收到一次可读通知后，**必须一次性将缓冲区内的数据全部读完**，直到产生 `EAGAIN`或 `EWOULDBLOCK`错误为止。因为即使缓冲区里还有数据，只要没有**新的数据到来**（即状态没有再次发生变化），`epoll`就**不会再通知**。
- **优点**：减少了重复通知，性能更高，尤其适合需要精细控制I/O行为的场景。
- **缺点**：编程复杂度高，应用程序必须一次处理完所有数据，否则会丢失事件。通常需要搭配**非阻塞I/O**来循环读/写，直到出现 `EAGAIN`。

---

## redis，nginx，netty 是依赖什么做的这么高性能

“Redis、Nginx 和 Netty 虽然属于不同领域的软件，但它们能达到极高的性能，主要依赖于一套共通的、经过验证的高性能架构模式和技术选型。我可以将它们依赖的核心技术总结为以下四个层面：

**第一，也是最核心的：它们都采用了 I/O 多路复用模型，而且是 Linux 平台下性能最高的 `epoll`。**

传统的多线程/多进程模型为每个连接创建一个线程，上下文切换和内存开销巨大。而它们使用**单个或少量线程**（Nginx 的 Worker 进程，Redis 的主线程，Netty 的 Boss/Worker 事件循环组）通过 `epoll`就能管理**数万个连接**。这极大地降低了资源消耗，将 CPU 从繁重的线程调度中解放出来，专注于处理真正的 I/O 事件。

**第二，它们都遵循了事件驱动的 Reactor 模式。**

这个模式与 I/O 多路复用是完美搭档。整个系统是一个**事件循环**，核心工作流程是：`收集事件（epoll_wait）-> 分发事件 -> 处理事件`。这种异步、非阻塞的处理方式避免了线程的等待和阻塞，让有限的线程资源得到最大程度的利用，实现了高吞吐量。

**第三，在内存和数据处理上，它们都追求极致的效率。**

- **Redis**：1. 将数据完全存储在内存中，避免了磁盘 I/O 的瓶颈。2. 使用了精心设计的自定义数据结构（如 SDS、跳跃表、压缩列表），在时间和空间上做了极致的优化。
- **Nginx**：1. 采用了高效的内存池管理，减少频繁的内存分配和释放带来的开销和碎片。2. 设计了零拷贝技术，在发送文件数据时，数据无需从内核空间拷贝到用户空间，直接在内核中完成传输，极大提升了静态文件服务的性能。
- **Netty**：1. 提供了零拷贝的 `ByteBuf`机制，减少了数据在 JVM 堆内存和本地内存之间的拷贝。2. 使用对象池和内存池化技术，避免频繁创建和销毁对象，减轻 GC 压力。

**第四，采用单线程或特定多线程模型，避免锁竞争。**

- **Redis**：其网络 I/O 和数据操作的核心模块是**单线程**的。这虽然无法利用多核，但完美避免了多线程环境下复杂的锁竞争和上下文切换问题，保证了原子性和极高的执行效率。对于耗时的操作（持久化），会 fork 出子进程去执行。
- **Nginx**：采用**多进程 + 单线程**模型。多个 Worker 进程是平等的，各自独立运行一个事件循环，充分利用多核CPU，且进程间相互隔离，稳定性极高。
- **Netty**：采用**主从 Reactor 多线程**模型。Boss 线程组负责接收连接，Worker 线程组负责处理 I/O。通过精心设计，将连接合理地分配到不同的 Worker，确保了每个事件循环中所处理的连接是独立的，极大地减少了并发冲突。

**总结一下，** 它们高性能的共性在于：**基于 `epoll`的事件驱动架构 + 非阻塞 I/O + 极致的资源管理（内存、CPU）+ 避免锁竞争的精巧并发模型**。这套技术栈是现代高性能网络服务的标准答案。”

---

## 零拷贝

零拷贝是一种用于提升I/O性能的关键技术，它的核心目标是**减少甚至完全避免数据在内存中的不必要的拷贝次数**，从而降低CPU开销和上下文切换，显著提升吞吐量。

**1. 传统方式的瓶颈：**

以‘服务器发送文件’这个经典场景为例。传统方式下，数据需要经历：

- `read`调用：数据从**磁盘**->**内核缓冲区**->**用户缓冲区**（1次拷贝）。

- `write`调用：数据从**用户缓冲区**->**套接字缓冲区**（第2次拷贝）。

  最后再从**套接字缓冲区**送到网卡。

  这个过程涉及**4次上下文切换**和**2次CPU数据拷贝**，效率很低。

**2. 零拷贝的解决方案：**

Linux主要通过 `sendfile`系统调用实现零拷贝。它允许数据直接在**内核缓冲区**和**套接字缓冲区**之间传输，**完全绕过了用户空间**。这样就将拷贝次数从2次减少到了1次（仅内核内拷贝）。

**3. 真正的‘零’拷贝：**

在支持**Scatter-Gather DMA**的硬件上，可以做到真正的零拷贝。`sendfile`调用时，内核不再拷贝数据本身，而是将数据在内存中的**地址和长度信息**（描述符）直接发给网卡。之后，网卡的DMA引擎会**根据这些描述符，直接从内核缓冲区读取数据并发送**。整个过程**完全不需要CPU参与数据搬运**。

**它的巨大价值在于**：将CPU从繁重的数据拷贝工作中解放出来，使其能更专注于业务逻辑计算。这正是Nginx、Kafka等高性能中间件能够实现极高吞吐量的核心技术之一。







